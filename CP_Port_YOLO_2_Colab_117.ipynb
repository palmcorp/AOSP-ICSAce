{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP16iqgEk6GjSqJHfdqMROb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/palmcorp/AOSP-ICSAce/blob/master/CP_Port_YOLO_2_Colab_117.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fTD0htV1TfRj",
        "outputId": "57823af9-1b4f-489f-e160-a8c1afcbbf21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "version:  2.2  \n",
            " M I  S S S O N  Port of workstation CP Yolov8_np to Colab to gnerte Yolo_np\n",
            " and estblish check points\n"
          ]
        }
      ],
      "source": [
        "VERSION = \"2.2\"\n",
        "MISSION = \" Port of workstation CP Yolov8_np to Colab to gnerte Yolo_np\"\n",
        "MISSION+= \"\\n and estblish check points\"\n",
        "print (\"version: \", VERSION, \" \\n M I  S S S O N\", MISSION)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print (\"stage I; import python modules\")\n",
        "!pip install ultralytics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_nEIRy5UGHw",
        "outputId": "fb105a12-cc52-45f3-e5f1-4d219a1500b1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "stage I; import python modules\n",
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.10/dist-packages (8.1.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.22.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.23.5)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.8.0.76)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.31.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.11.4)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.1.0+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.16.0+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: thop>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.1.1.post2209072238)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.5.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.47.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (23.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2023.3.post1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2023.11.17)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print (\"need GPU\")\n",
        "!invidia-smi\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DGHffDLpnTmp",
        "outputId": "be6c394f-88e7-4796-a175-1ab5f7b4cee2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "need GPU\n",
            "/bin/bash: line 1: invidia-smi: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!Runtime -> Change run time type -> GPU,TPU\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CGzXQ1Iqo4ga",
        "outputId": "e821171c-05b6-4159-9fbc-d37c4fbc8fd9"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: Runtime: command not found\n",
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print (\"Add libraries\")\n",
        "from ultralytics import SAM\n",
        "from ultralytics import YOLO\n",
        "from ultralytics.utils.plotting import Annotator\n",
        "import numpy as np\n",
        "import datetime\n",
        "import cv2\n",
        "import os, pdb\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVqGSdCWUWPM",
        "outputId": "711639ac-a782-4dfb-8b65-b4e0ea0cebfa"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Add libraries\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print (\"Creating all directories JUST FOR COLA\")\n",
        "DIRS=(\"MODEL\", \"WEIGHTS\",\"STORE\",'VIDEOS',\"FRAMES\", \"RESULTS\", \"LIBS\", \"TRIAGE\",\"CHECK_POINTS\",\"REPORTS\", \"BLIND_STUDY\")\n",
        "ROOT=os.path.join (\"/content/\")\n",
        "print (\"ROOT IS \", ROOT)\n",
        "def MDIRS (ROOT, TUPL):\n",
        "  for D in TUPL:\n",
        "    fp=os.path.join (ROOT, D)\n",
        "    print (\"creating 1st level dir: from\", ROOT, D)\n",
        "    os.makedirs(fp, exist_ok=True)\n",
        "  print (\"done with dirs\")\n",
        "  return True\n",
        "# call from main?\n",
        "ok= MDIRS (ROOT, DIRS)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W1yzBnIYUcEn",
        "outputId": "12f8b6ef-3912-4e7c-d6c1-4b70e064dfe5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating all directories JUST FOR COLA\n",
            "ROOT IS  /content/\n",
            "creating 1st level dir: from /content/ MODEL\n",
            "creating 1st level dir: from /content/ WEIGHTS\n",
            "creating 1st level dir: from /content/ STORE\n",
            "creating 1st level dir: from /content/ VIDEOS\n",
            "creating 1st level dir: from /content/ FRAMES\n",
            "creating 1st level dir: from /content/ RESULTS\n",
            "creating 1st level dir: from /content/ LIBS\n",
            "creating 1st level dir: from /content/ TRIAGE\n",
            "creating 1st level dir: from /content/ CHECK_POINTS\n",
            "creating 1st level dir: from /content/ REPORTS\n",
            "creating 1st level dir: from /content/ BLIND_STUDY\n",
            "done with dirs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def CHECK_IT (PATH, NAME):\n",
        "  que=\"Upload \"+str(NAME)+ \" to\"+str(PATH)\n",
        "  xx= input (que)\n",
        "  if xx==\"\": return True\n",
        "  print (\"you typed \", xx)\n",
        "  return False"
      ],
      "metadata": {
        "id": "eAVGYw8IIpRh"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (\"migrate code to colab\")\n",
        "xx=input (\"upload best.pt to weights then cr\")\n",
        "if xx==\"\": print (\"next\")\n",
        "xx= (\"upload libs to LIBS\")\n",
        "if xx==\"\": print (\"next\")\n",
        "xx=input (\"upload 60+ videos to VIDEOS\")\n",
        "if xx==\"\":print (\"next\")\n",
        "xx=input(\"load libs into LIBS\")\n",
        "if xx==\"\":print (\"next\")\n",
        "xx=input (\"upload 3 to TRIAGE\"+str(\"TRIAGE/CARDIAC_TRIAGE0.220230824-110623.pkl and ALL_MASTER_TRIAGE_071223_v01.csv\"))\n",
        "if xx==\"\": print (\"next\")\n",
        "xx=input (\"upload to STORE: Cardic_Patterns_Video_Lib_02_20240113-143422.pkl\")\n",
        "if xx==\"\": print (\"next\")\n",
        "ok = CHECK_IT (\"/content/BLIND_STUDY/\",\"Blind_Study_consolidation_MASTER_1205223v03.csv\")\n"
      ],
      "metadata": {
        "id": "3htIcX3SWaTw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7accd86c-7407-4ccc-e85b-bee6fe0057a8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "migrate code to colab\n",
            "upload best.pt to weights then cr\n",
            "next\n",
            "upload 60+ videos to VIDEOS\n",
            "next\n",
            "load libs into LIBS\n",
            "next\n",
            "upload 3 to TRIAGETRIAGE/CARDIAC_TRIAGE0.220230824-110623.pkl and ALL_MASTER_TRIAGE_071223_v01.csv\n",
            "next\n",
            "upload to STORE: Cardic_Patterns_Video_Lib_02_20240113-143422.pkl\n",
            "next\n",
            "Upload Blind_Study_consolidation_MASTER_1205223v03.csv to/content/BLIND_STUDY/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# HEADER\n",
        "CODE_BASE=\"blind_rpt v262  from 1/18/24\"\n",
        "print (\" HEADER from\" , CODE_BASE)\n",
        "print (\" setCHDIR TO  lib root\")\n",
        "LIB_ROOT=os.path.join (\"/content/LIBS\")\n",
        "NOW=os.getcwd() # whree are we now\n",
        "os.chdir(LIB_ROOT)\n",
        "\n",
        "from CardiacLIB import Report\n",
        "from  CardiacRESLib import RESULT, TAG_FROM_VID, FRAME_NO\n",
        "from CardiacTriage  import PROCESS_TRIAGE\n",
        "from CardiacUtilLIB import CHECK_UP, PATH_UP, PICK_ONE,PICK_ONEX,_TRACK, TAG_FROM_PATH\n",
        "from CardiacGTLIB import F_1\n",
        "from CardiacBlindLIB import BLIND_STUDY\n",
        "from CardiacValues  import cm_plot_labels\n",
        "import time\n",
        "####\n",
        "\n",
        "\n",
        "from CardiacYOLOlib import YOLOV8\n",
        "from CardiacVIDlib  import VIDEO\n",
        "\n",
        "from datetime import date\n",
        "import datetime\n",
        "# update\n",
        "import os, pdb\n",
        "\n",
        "#CONFIGUGION PARAMETER\n",
        "global MARGIN\n",
        "global TK  # for tracking\n",
        "xNOW=os.getcwd() # whree are we now\n",
        "NOW=os.path.join (\"/content\")\n",
        "print ('CHANGED CWD BACK TO', NOW, \"FROM \",xNOW)\n",
        "pdb.set_trace()\n",
        "os.chdir(NOW)\n",
        "##########################################\n",
        "##  CARDIAC PATTERNS,INC.               ##\n",
        "##                                      ##\n",
        "## BLIND Study  REPORT GENRRATOR        ##\n",
        "##\n",
        "##  p petronelli                        ##cm_plot_labels\n",
        "##  11/20/23                            ##\n",
        "##                                      ##\n",
        "##  Contents:                           ##\n",
        "#      uses SCI-KIT LEARN               ##\n",
        "##     uses Read Ground truth from  lib ##\n",
        "##  THis code creates the final summay rpt ##\n",
        "##                                      ##\n",
        "##                                      ##\n",
        "#######(c) Crdiac Patterns     , Inc.   #######\n",
        "########2020-2024  All rightes reserved.#######\n",
        "##########################################\n",
        "##  UPDATES\n",
        "##  Ver   Date   Isseue                        Eng\n",
        "## 38    11/25/23\n",
        "## 40    11/2723    Add summry epotrt generation plp\n",
        "##50     1/6/24   plp  Convert AI from YOLO8\n",
        "## 260   1/17/24  plp  Added pickel save and load\n",
        "##       1/16/24  plp  testing on Colab\n",
        "########################"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2u8imav_ZyZP",
        "outputId": "eb169022-44ce-4161-af2e-09da8cff2146"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " HEADER from blind_rpt v262  from 1/18/24\n",
            " setCHDIR TO  lib root\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "PYDEV DEBUGGER WARNING:\n",
            "sys.settrace() should not be used when the debugger is being used.\n",
            "This may cause the debugger to stop working correctly.\n",
            "If this is needed, please check: \n",
            "http://pydev.blogspot.com/2007/06/why-cant-pydev-debugger-work-with.html\n",
            "to see how to restore the debug tracing back correctly.\n",
            "Call Location:\n",
            "  File \"/usr/lib/python3.10/bdb.py\", line 336, in set_trace\n",
            "    sys.settrace(self.trace_dispatch)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CHANGED CWD BACK TO /content FROM  /content/LIBS\n",
            "--Return--\n",
            "None\n",
            "> \u001b[0;32m<ipython-input-7-38f771c53461>\u001b[0m(34)\u001b[0;36m<cell line: 34>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m     32 \u001b[0;31m\u001b[0mNOW\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"/content\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m     33 \u001b[0;31m\u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'CHANGED CWD BACK TO'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNOW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"FROM \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mxNOW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m---> 34 \u001b[0;31m\u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m     35 \u001b[0;31m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNOW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m     36 \u001b[0;31m\u001b[0;31m##########################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\n",
            "ipdb> c\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "PYDEV DEBUGGER WARNING:\n",
            "sys.settrace() should not be used when the debugger is being used.\n",
            "This may cause the debugger to stop working correctly.\n",
            "If this is needed, please check: \n",
            "http://pydev.blogspot.com/2007/06/why-cant-pydev-debugger-work-with.html\n",
            "to see how to restore the debug tracing back correctly.\n",
            "Call Location:\n",
            "  File \"/usr/lib/python3.10/bdb.py\", line 347, in set_continue\n",
            "    sys.settrace(None)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xx=input (\"unzdip vids from VIDEOS.zip at CHECK_POINTS= cr\")\n",
        "if xx==\"\":\n",
        "  #!unzip CHECK_POINTS\\VIDEOS.zip\n",
        "\n",
        "  ZIP_NAME = \"VIDEOS.zip\"\n",
        "  ZIP_PATH = os.path.join (\"/content/CHECK_POINTS\", ZIP_NAME)\n",
        "  ZIP_END_POINT = os.path.join (\"/content/VIDEOS\")\n",
        "  print (\"unzipping from \", ZIP_PATH, \" to \", ZIP_END_POINT)\n",
        "  if not os.path.isfile(ZIP_PATH):\n",
        "    print (ZIP_PATH, \" not a file\")\n",
        "  if not os.path.exists (ZIP_END_POINT):\n",
        "    print (\"not exist \", ZIP_END_POINT)\n",
        "  !unzip /content/CHECK_POINTS/VIDEOS.zip  -d /content/VIDEOS\n",
        "  LISTV=os.listdir(ZIP_END_POINT)\n",
        "  print (\"stored \", len(LISTV), \" videos\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eHGYCHGa98bN",
        "outputId": "5ae6a45a-a78c-4ccc-bc73-11309db9137e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "unzdip vids from VIDEOS.zip at CHECK_POINTS= crno\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PART TWO - U T I L I T I E S\n",
        "print (\"Part Two U T I L I T I E S\")\n",
        "# fclass = F_1(OPTIONS)\n",
        "# To procress F_1.Load_CSV_Ground_Truth (self, CSV_PATH, CSV_NAME)\n",
        "   # from CP-yolo_detect_and_count-v0115.py\n",
        "def LOAD_TRIAGE_PKL (TRIAGE_MASTER_REPORT_NAME, TRIAGE_MASTER_REPORT_DIR, AVI_PATH):\n",
        "         OK=True\n",
        "         ECHO = True\n",
        "         TEST=False # at v61\n",
        "         if ECHO: print (\" LOAD TRIAGE WITH: \",TRIAGE_MASTER_REPORT_NAME, TRIAGE_MASTER_REPORT_DIR, AVI_PATH)\n",
        "         if TEST: pdb.set_trace()\n",
        "         try:\n",
        "             PTC = PROCESS_TRIAGE(TRIAGE_MASTER_REPORT_NAME, TRIAGE_MASTER_REPORT_DIR, AVI_PATH)\n",
        "\n",
        "             PTC._set_test(False)\n",
        "             PTC._set_ECHO((True))\n",
        "             #HISTORICAL_PATH = PL=os.path.join (\"C:\\\\\",\"DEV4\",\"PROCESS_TRIAG\n",
        "             PL = TRIAGE_MASTER_REPORT_DIR # use current not hisgorical conv\n",
        "             HISTORICAL_PATH =PL\n",
        "             PKL_LIST = os.listdir(PL)\n",
        "             np,pick= PICK_ONEX (PKL_LIST, \"pkl\")\n",
        "\n",
        "             PKL_NAME= \"CARDIAC_TRIAGE0.220230824-110623.pkl\"\n",
        "             if pick == PKL_NAME:\n",
        "                 print (\"OK\")\n",
        "             else:\n",
        "                 xx= input (\"Aare you sure? not stanard\")\n",
        "                 pdb.set_trace()\n",
        "             MODE = \"load\"\n",
        "             PICKEL_NAME =LAST_PICKEL_NAME = PKL_NAME\n",
        "             LAST_PICKEL_PATH = HISTORICAL_PATH  #conv\n",
        "             LAST_PICKEL_PATH= os.path.join (PL)   # must NOt be full pagh\n",
        "             PTC._set_test(False)\n",
        "             #pdb.set_trace()\n",
        "             PTC._set_last_pickel_data (LAST_PICKEL_NAME, LAST_PICKEL_PATH)\n",
        "             OK,TRIAGE_ARRAY_NP = PTC._pickel_(PICKEL_NAME, MODE)\n",
        "         except Exception as EX:\n",
        "             print (\" Exception in Load triage; \", EX)\n",
        "             pdb.set_trace()\n",
        "             OK = False\n",
        "\n",
        "         return OK,PTC\n",
        "\n",
        "def GET_TRIAGE (TRIAGE_DIR,VID_DIR):\n",
        "          # set up irectgories\n",
        "          TRIAGE_MASTER_REPORT_NAME=\"ALL_MASTER_TRIAGE_071223_v01.csv\"\n",
        "          #TRIAGE_MASTER_REPORT_DIR=os.path.join (\"D:\\\\\",\"MASTER_RUN\") # conv\n",
        "          TRIAGE_MASTER_REPORT_DIR=TRIAGE_DIR\n",
        "          #AVI_PATH=os.path.join (\"C:\\\\\",\"AI\")\n",
        "          AVI_PATH= VID_DIR  # conv\n",
        "          OK,PTC= LOAD_TRIAGE_PKL (TRIAGE_MASTER_REPORT_NAME, TRIAGE_MASTER_REPORT_DIR, AVI_PATH)\n",
        "          if not OK:\n",
        "             print (\"problem getting array\")\n",
        "             pdb.set_trace()\n",
        "          return PTC  # return the class\n",
        "'''\n",
        "class Yolov8 :\n",
        "    def __init__(self) :\n",
        "      print (\"initializin yolo lass\" )\n",
        "    def GET_CLASS(self):\n",
        "        yolov8=\"\"\n",
        "        return yolov8\n",
        "\n",
        "def GET_YOLOV8_CLASS ():\n",
        "    YOLOV8_CLASS = Yolov8()\n",
        "    return YOLOV8_CLASS\n",
        " '''\n",
        "\n",
        "def Get_AI (TAG, TRIAGE_CLASS, YOLOV8_CLASS):\n",
        "    print (\"processing TAG: \", TAG)\n",
        "    pdb.set_trace()\n",
        "\n",
        "    ## UPdate with AI from Yoov8\n",
        "    return\n",
        "\n",
        "\n",
        "def list_vid(FP):\n",
        "    #=(FP):\n",
        "    lst=os.listdir(FP)\n",
        "    print (len(lst), \"v in\", FP)\n",
        "    return lst\n",
        "\n",
        "#def Read_csv (FP_IN):\n",
        "    # read in csv ground truth / blind annoations rom sharol\n",
        "\n",
        "def  Read_IN (FP_IN):\n",
        "    fp=open (FP_IN)\n",
        "    START=False\n",
        "    IN_LIST = [] #\n",
        "    nl = 0\n",
        "    with open (FP_IN) as fp:\n",
        "        for line in fp:\n",
        "            print (nl,\"  \", line)\n",
        "            nl+=1\n",
        "            if \"Sharol,\" in line:\n",
        "                 # skip\n",
        "                 print (\"skipping\", line) #break\n",
        "                 break\n",
        "            if not START:\n",
        "                    if \"Attachments\" in line: START=True\n",
        "            else:\n",
        "                # started, read 0X9DB79DF0A269227.mp4; 0X9E3D09429F6B852.mp4;\n",
        "                if \".mp4;\"in line:\n",
        "                    flds=line.split(\";\")\n",
        "                    print (flds)\n",
        "                    f1=flds[0]\n",
        "                    f2=flds[1]\n",
        "                    IN_LIST.append (f1)\n",
        "                    IN_LIST.append (f2)\n",
        "\n",
        "    print (\"end of in list of , \", len(IN_LIST))\n",
        "    return IN_LIST\n",
        "\n",
        "def _Get_TAG_values ( TAG, Triage_np):\n",
        "    # triage array\n",
        "    # assume data is clean\n",
        "\n",
        "    #FRAMES = np_row[1]\n",
        "\n",
        "  #  if TAG.islower():TAG.upper()\n",
        "   # TAG=self._clean_spaces(TAG)\n",
        "    TEST = False\n",
        "    #pdb.set_trace()\n",
        "    if TEST: pdb.set_trace()\n",
        "    print (\" fetching TAG:\", TAG)\n",
        "    FOUND = False\n",
        "    NP_data = Triage_np\n",
        "    lnp = len (NP_data)-1  # fim zero\n",
        "    print (\"lnp is \", lnp)\n",
        "    T1=20\n",
        "    TX=0\n",
        "    for i in range (lnp):\n",
        "        TX+=1\n",
        "        np_row = NP_data[i]\n",
        "        tag= np_row[2] # tags should alway be upper\n",
        "        T1-=1\n",
        "        INCREMENT = False\n",
        "        if INCREMENT:\n",
        "            if T1==0:\n",
        "                print (np_row)\n",
        "                x=input (\"GO or x, or new number\")\n",
        "                if x==\"x\":\n",
        "                    print (\"quitting at \", TX)\n",
        "                    pdb.set_trace(\"stop here\")\n",
        "                    return True, []    #self._get_row_values (np_row)\n",
        "                if x==\"\":\n",
        "                    T1=20\n",
        "                else :\n",
        "                    nn= int (x)\n",
        "                    if isinstance (x, int):\n",
        "                        T1=nn\n",
        "\n",
        "        if tag==TAG:\n",
        "            FOUND = True\n",
        "            NUM   = np_row[0]\n",
        "            FRAMES = np_row[1]\n",
        "            TAG= np_row[2] # tags should alway be upper\n",
        "            #if TAG.islower():TAG.upper()\n",
        "            # TAG=self._clean_spaces(TAG)\n",
        "            print (\"Found \", TAG, \"at \", TX, \" \\n \",np_row)\n",
        "\n",
        "            TPL = np_row  # []# self._get_row_values(np_row)\n",
        "            return FOUND,TPL\n",
        "    print (TAG, \"NOt found after \", TX)\n",
        "    return False,() # epmpty\n",
        "def SPELL_UP(LABEL):\n",
        "    ECHO=True\n",
        "    # check comon checkin erro\n",
        "    STD=cm_plot_labels  #cm_plot_labels = [\"Endocarditis\",\"Mild\",\"Non-Visible\",\"Normal\",\"Prosthetic\",\"Severe\"] #alphabetic\n",
        "    COMMON_SPELLUP=CU={'Mil':'Mild', \"Norml\":\"Normal\", \"Sever\":\"Severe\", \"Prothetic\":\"Prosthetic\", \"Prostetic\":\"Prosthetic\",\"Stenosed\":\"Stenosis\"} # dicionary\n",
        "    if LABEL==\"SPELL_DICT\":\n",
        "        return COMMON_SPELLUP\n",
        "    if LABEL in CU.keys():\n",
        "        NEW_LABEL = CU[LABEL]\n",
        "        if ECHO: print (\" updated \", LABEL, \" to \", NEW_LABEL)\n",
        "        return NEW_LABEL\n",
        "    else: return LABEL\n",
        "\n",
        "\n",
        "\n",
        "def READ_SHROL_EVAL (CONSOLIDATD_CSV_NAME, PATH):\n",
        "    #global TK\n",
        "    args = str(CONSOLIDATD_CSV_NAME)+ ' |'+ str (PATH)\n",
        "    print (args)\n",
        "    #TK.L (\"READ SHAOL EVAL\", args)\n",
        "    print (\" Read in prepare d echo ecaluations\")\n",
        "    TEST = False\n",
        "    CN=CONSOLIDATD_CSV_NAME\n",
        "    CP=PATH\n",
        "    MODULE = \"READ SHAROL EVAL\"\n",
        "    if TEST: pdb.set_trace()\n",
        "    # use read ground truth  raw data\n",
        "    # create class\n",
        "    OPTIONS = (False, False)  #   Track, Test\n",
        "    F1= F_1 (OPTIONS)\n",
        "    print (\"reading in consolicated csv file: \", CN, \" AT \", CP)\n",
        "    CSV_PATH = CP\n",
        "    CSV_NAME = CN\n",
        "    Echo_data = F1.Load_CSV_Ground_Truth (CSV_PATH, CSV_NAME)\n",
        "    if TEST: pdb.set_trace()\n",
        "    # returns a list of TAGs?\n",
        "    MT=False\n",
        "    if MT:\n",
        "        MILD_TAGS=MT=[('D4F5F','Severe'),('FB24F','Mild'),('58F10','Mild'),('ACFE8','Mild'), \\\n",
        "                      ('7CCE4','Mild'),('C5714','Mild'),('541A0','Mild'),('87BA6','Mild'), \\\n",
        "                          ('0D042','Mild'),('27D5C','Omit')]  # (TAG , AI)  THEE Ae HSOL RFS\n",
        "        return MT\n",
        "    print (\"Not fixed list retueinve list of TAG,SHAROL\")\n",
        "    SH_list =[]\n",
        "    for E in Echo_data:\n",
        "        tag = E[0]\n",
        "        sharol= E[2]\n",
        "        Qscore= E[4]\n",
        "        if \"omit\" in E:\n",
        "            print (\"found OMIT set Q to 1\")\n",
        "            Qscore = 1\n",
        "            if TEST: pdb.set_trace()\n",
        "        SH_list.append ((tag,sharol,Qscore))\n",
        "    args= str (len(SH_list))+ \" sharol cases foudn\"\n",
        "    #TK.T(args)\n",
        "    print (args)\n",
        "    return SH_list , Echo_data\n",
        "    #return Echo_data\n",
        "\n",
        "def BUILD_BLIND_REPORT ():\n",
        "    print ( \"creatint blind summary report\")\n",
        "    ##################\n",
        "    ## set up blind report ##  11/27\n",
        "    ##################\n",
        "    TODAY=datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "    COMMON_SUFFEX =CS=str(VERSION)+\"_\"+str(TODAY)+\".txt\"\n",
        "    BLND_NAME = \"Cardiac_Patterns_Blind_Study_Results_Report_\"+  CS\n",
        "    RPT_BASE  = os.path.join (\"D:\\\\\",\"CP_BLIND_STUDY\",\"PROCESSED_REPORTS\")\n",
        "   # d_list = os.listdir(DATE_BASE)\n",
        "   #print (\" pick a date\")\n",
        "    #nx,pick = PICK_ONE(d_list)\n",
        "    #RPT_DATE = pick\n",
        "    #RPT_NAME =\"Cardiac_Patterns_Blind_Study__\"+CS   #str(VERSION)+\"_\"+str(RPT_DATE)+\".txt\"\n",
        "   # SRT_NAME =\"Cardiac_Patterns_Blind_Score__\"+CS   #str(VERSION)+\"_\"+str(RPT_DATE)+\".txt\"\n",
        "    # do areports\n",
        "   # P_RPT_DIR =os.path.join (RPT_BASE,\"report\")\n",
        "   # S_RPT_DIR =os.path.join (RPT_BASE, \"score\")\n",
        "    B_RPT_DIR = os.path.join (RPT_BASE, \"summary\")  # this is the glind report\n",
        "\n",
        "    REPORT_NAME = RPT_NAME= BLND_NAME\n",
        "    P_RPT_DIR   = RPT_BASE\n",
        "    #RPTD  =BLIND_STUDY(P_RPT_DIR, REPORT_NAME)\n",
        "    #REPORT_NAME = SRT_NAME  # for score sheet\n",
        "    #SRTD  =BLIND_STUDY(S_RPT_DIR, REPORT_NAME)\n",
        "    BRPT = BLIND_STUDY(B_RPT_DIR, BLND_NAME)\n",
        "    return BRPT\n",
        "\n",
        "\n",
        "def CHECK_AGREEMENT (AI,CONF,LBL2, CONF2, SHAROL, TAG):\n",
        "    global TK\n",
        "    MODULE=\"Check _Ageement\"\n",
        "    print (\"checking agreemente begween sources\")\n",
        "    arg=\"TAG: \"+str(TAG)+\" AI:\"+str (AI)+ \" conf: \"+str (CONF)+\" LBL2\\CONF: \"+str(LBL2)+\"|\"+str(CONF2)+ \" Sharol: \"+str(SHAROL)\n",
        "    TK.L ( \"CHECK GREEMENT\", arg)\n",
        "    Equivocal =EQ= 0  # adjudiates in close calls\n",
        "    global MARGIN\n",
        "    # compare two strings using Case insenstitive\n",
        "    # remove white spaces\n",
        "    #if SHAROL == 'Stenosed':\n",
        "    ECHO= True\n",
        "    TEST=False\n",
        "    A=AI.strip()\n",
        "    S=SHAROL.strip()\n",
        "    S=SPELL_UP(S)\n",
        "    SHAROL=SPELL_UP(SHAROL) # check both\n",
        "    EQ_MARGIN = MARGIN *100  # percentagaes!#0.45  # WITHIN 10 % MEANS EQ# adjustd for v91\n",
        "    if  A.casefold()==S.casefold():\n",
        "       arg= \"found equivalents \"+str( AI)+ \"|\"+str( SHAROL)\n",
        "       TK.T(arg)\n",
        "       EQ=0\n",
        "       TK.T(\"\")\n",
        "       return True, EQ\n",
        "    elif  SHAROL == 'Stenosed' and AI==\"Severe\":\n",
        "        arg=\"found Stenosed == Severe\"\n",
        "        TK.T(arg)\n",
        "        return True, EQ\n",
        "    elif  SHAROL == 'Stenosis' and AI==\"Severe\":\n",
        "        arg=\"found Stenosis and Severe\"\n",
        "        TK.T(arg)\n",
        "        return True, EQ\n",
        "    elif SHAROL == \"Prosthetic\" and AI==\"Severe\":\n",
        "        arg=\"found Prosthetic and Severe \"\n",
        "        TK.T(arg)\n",
        "        EQ=0\n",
        "        return True, EQ\n",
        "        # consider AI at 45 and 23  with professional gees 2nd label\n",
        "    else:\n",
        "        B=LBL2.strip()\n",
        "        C=float(CONF.replace(\"%\",\"\"))\n",
        "        C2=float(CONF2.replace(\"%\",\"\"))\n",
        "        TOLERANCE=0  # to avoid probl\n",
        "        arg=\"In second test\"+str(C)+\"|\"+str(C2)\n",
        "        TK.T(arg)\n",
        "        if B.casefold()==S.casefold(): # TRY SECOND labl declare eq\n",
        "            # edge case\n",
        "            # a hit if conf2 within EQ_MARGINE of conf gthen ecalre EQ\n",
        "            #TOLERANCE = CONF-CONF2\n",
        "            TOLERANCE = (C-C2)/100 # normalized leady percentge\n",
        "            TOLERANCE = abs((C-C2)) # just in case\n",
        "            if TOLERANCE <=EQ_MARGIN :\n",
        "                EQ=1\n",
        "            if ECHO: print (\"boundaries : \",TOLERANCE )\n",
        "        if ECHO:\n",
        "            arg= \"Equivocal Case: LBL1, CON1\"+str( AI)+\"|\"+str(CONF)+\"  lbl2/conf2\"+str( LBL2)+\"|\"+str( CONF2)+\" SHAROL: \"+str( SHAROL)\n",
        "            arg+= \" Tolerance: \"+str( TOLERANCE)\n",
        "            TK.T(arg)\n",
        "        if TEST: pdb.set_trace()\n",
        "        if EQ==1:\n",
        "            arg=\"return TRUE \"+str(EQ)\n",
        "            TK.T(arg)\n",
        "            return True, EQ\n",
        "    if ECHO: print (\"No match on first or second for \", SHAROL, \" at \", TAG)\n",
        "    arg =\"No match on first or second for \"+str( SHAROL) + \" at \"+str( TAG)\n",
        "    TK.T(arg)\n",
        "    return False , EQ # no match on first or second\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l5_k0YVteAo9",
        "outputId": "625b98bd-deb1-446c-d9cd-ceedbdaecce8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Part Two U T I L I T I E S\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PART THREE M A I N\n",
        "print (\"PART THREE - M A I N\")\n",
        "VERSION = \"0.264\"\n",
        "MISSION = \" ADD AI EVALUATION TO REPORT & TRACKING & YOLOV8 predictions @ v 250\"\n",
        "MISSION+=\"\\n v260 is working!! c v 261 has sharol limit to shorten running\"\n",
        "MISSION+=\"\\n porting to colap and genrealize configurations\"\n",
        "NEW_MISSION= \" Read list of tag + ai + sharol as CSV  add Equivocal NOW SELEECT LIST\"\n",
        "\n",
        "def main (CONFIG):\n",
        "    global MARGIN\n",
        "    global TK\n",
        "    YOLO_FORMAT = True\n",
        "    print (\"using yolo format: \", YOLO_FORMAT)\n",
        "    CTEST=True  # conv\n",
        "    DPTH=os.path.join (os.getcwd())# default\n",
        "    # note VID_DIR in a config is root echos, my not work here\n",
        "    ROOT, TRIAGE_DIR, VID_DIR, LIBS,WEIGHTS, STORE, REPORTS, CHECK_POINT, BLIND_STUDY = UNPACK_CONFIG(CONFIG)\n",
        "    print (\"\\n CONFIGURATION:\",ROOT, TRIAGE_DIR, VID_DIR,LIBS, WEIGHTS, STORE, REPORTS,CHECK_POINT, BLIND_STUDY)\n",
        "    MARGIN = 0.45  # FROM ANALYSIS\n",
        "    if CTEST: pdb.set_trace()\n",
        "    TEST=False\n",
        "    CHECK=True  # CHEOCN AGREEMENT\n",
        "    MODULE = \"Main\"\n",
        "    print (\"\\n ENTERING M A I N with \", ROOT)\n",
        "    MISSING_TAGS=[] # list of missing TAGS\n",
        "    SPELL_DICT = SPELL_UP(\"SPELL_DICT\")\n",
        "    print (\"spelling corrections: \\n ITEM CORRECTION\\n\")\n",
        "    for k,v in SPELL_DICT.items():\n",
        "        print (k,\"\\t\",v)\n",
        "\n",
        "    xx=input (\"generated score report from email cr=no\")\n",
        "    if xx==\"\":\n",
        "        READ_DATA = False # check data to read\n",
        "    else:\n",
        "        READ_DATA = True\n",
        "    today = date.today()\n",
        "    # CHECK ON Q SCORE\n",
        "    print (\"\\nEqui-val Margin is \",MARGIN, \" \\n\" )\n",
        "    if READ_DATA:\n",
        "        SRPT_DIR = os.path.join (os.getcwd())\n",
        "        SNAME    = \"Cardiac_Patterns_Blind_ECHOS_\"+str(VERSION)+\"_\"+str(today)+\".txt\"\n",
        "        SHD = \" Evaluation Score Card_v\"+str(VERSION)\n",
        "        TT=\"\\t\"\n",
        "        SFLDS = \"NO\"+TT+\"TAG\"+TT+\"SHAROL\"+TT+\"FILE NAME\"+TT+\"DATE\\n\"\n",
        "        short_rpt= SRPT = Report(SRPT_DIR, SNAME,SHD, SFLDS)\n",
        "        IP= os.path.join (\"D:\\\\\",\"CP_BLIND_STUDY\",\"PROCESSED_REPORTS\")\n",
        "        IP= os.path.join (\"D:\\\\\",\"CP_BLIND_STUDY\",\"RE-ISSUE\",\"REPORT\")\n",
        "        IPN=\"Next_BLIND_study_incement.txt\"\n",
        "        IPN=\"sharol 12-5 _data.txt\"\n",
        "        LST = os.listdir(IP)\n",
        "        np,pick = PICK_ONEX(LST, \".txt\")\n",
        "        if pick != IPN:\n",
        "            print (\"wrong link? \", IPN, \" vs \", pick)\n",
        "            pdb.set_trace()\n",
        "        else:\n",
        "             IPN=pick\n",
        "             print (\"selecting \", pick)\n",
        "        FP_IN = os.path.join (IP, IPN)\n",
        "        IN_LIST = Read_IN (FP_IN)\n",
        "        print (\"\\n Contents of \", IPN)\n",
        "        SPACE = TT+str(today)+\"\\n\\n\"\n",
        "        for i in range (len(IN_LIST)):\n",
        "            print (\"[\",i,\"] \",IN_LIST[i])\n",
        "            LN=IN_LIST[i]\n",
        "            TAG=TAG_FROM_VID(LN)\n",
        "            line = TT+str(TAG)+TT+\"____________\"+TT+str(LN)+SPACE\n",
        "            SRPT.addL(line)\n",
        "        SRPT.endFile(\"End of list Nov 28\")\n",
        "        print (\"look in \", SRPT_DIR)\n",
        "        pdb.set_trace()\n",
        "    today = date.today()\n",
        "    if TEST:pdb.set_trace()  # conv\n",
        "    T_CLASS= T=   GET_TRIAGE (TRIAGE_DIR, VID_DIR)\n",
        "    Triage_np = T._get_Triage_np()\n",
        "    #pdb.set_trace()\n",
        "    TEST_TAGS = False\n",
        "    if TEST_TAGS:\n",
        "        print (\"TESTING TAG RETEAL\")\n",
        "        TEST_TAGS =TT= [('3368B','PROSTETIC'),('7E925','MILD'),('24933','MILD'),('2A231','NORMAL'),\\\n",
        "                     ('DC01C','STENOSED'),('EE3A2','NORMAL'),('5EA5B','NORMAL'), ('EOE45','STENOSED'),\\\n",
        "                         ('8F990','N0RMAL'),('2559F','STENOSED')]\n",
        "        MILD_TAGS=MT=[('D4F5F','Severe'),('FB24F','Mild'),('58F10','Mild'),('ACFE8','Mild'), \\\n",
        "                      ('7CCE4','Mild'),('C5714','Mild'),('541A0','Mild'),('87BA6','Mild'), \\\n",
        "                          ('0D042','Mild'),('27D5C','Omit')]  # (TAG , AI)  THEE Ae HSOL RFS\n",
        "        print (\" from 6/23 MILD study \", MT)\n",
        "        XT=TT+MT\n",
        "        for tl in XT:\n",
        "             TAG=tl[0]\n",
        "             LBL=tl[1]\n",
        "             OK, TPL = _Get_TAG_values (TAG, Triage_np) # use local function\n",
        "             if not OK:\n",
        "                 print ( 'problem at ', TAG)\n",
        "                 pdb.set_trace()\n",
        "             else:\n",
        "                 print (\" at \", TAG, \"sharol: \" , LBL,\"AI:\", TPL)\n",
        "        print (\"end of internal test on TAGS\")\n",
        "    #pdb.set_trace()\n",
        "    today = date.today()\n",
        "    DATE = today\n",
        "    ## dont need this\n",
        "    '''\n",
        "    FP = os.path.join (ROOT,\"videos\",\"28-November\")  # conv\n",
        "    L=list_vid(FP)\n",
        "    '''\n",
        "    STOP=False\n",
        "    if STOP: pdb.set_trace()\n",
        "    #self, DIR, NAME, HEADER, FIELDS,TYPE=0, ADD=False):\n",
        "    RPT_DIR = REPORTS # from config os.path.join (\"D:\\CP_BLIND_STUDY\\PROCESSED_REPORTS\")\n",
        "    NAME=\"Cardiac_Patterns_Consolidatd_Blind_Study_\"+str (DATE)+\"_\"+str(VERSION)+\".txt\"\n",
        "    HD = \"BLIND STUDY VIDEOS for\\t\"+str(VERSION)\n",
        "    TT=\"\\t\"\n",
        "    FLDS = \"No\"+TT+\"TAG\"+TT+\"AI\"+TT+\"CONF\" +TT+\"LABEL2\"+TT+\"CONF2\"+TT\n",
        "    FLDS+=\"SHAROL\"+TT+\"FILE_NAME\"+TT+\"AGREEMENT\"+TT+\"EQUIVOCAL\\n\"\n",
        "    RPT = Report(RPT_DIR, NAME,HD, FLDS)\n",
        "    print (\"reaport: \", NAME, \" at \", RPT_DIR)\n",
        "    LTEST=False  # local test\n",
        "    if LTEST:\n",
        "        FLIST = list_vid(FP)\n",
        "        FLIST =IN_LIST\n",
        "        print (\"processing \", FP_IN )\n",
        "    CSV_NAME=\"Blind_Study_consolidation_MASTER_112623v03.csv\"\n",
        "    #PATH   = os.path.join (\"C:\\\\\",\"Backup-OFFSITE\",\"0000CardiacPatterns\",\"F1-STUDY\",\"F-1Study\",\"F-1DATA\")\n",
        "    # updagte faor blind reporaat\n",
        "    #PATH  = os.path.join (\"C:\\\\\",\"Backup-OFFSITE\",\"0000CardiacPatterns\",\"BLIND_Study\",\"CONSOLIDATION\")\n",
        "    PATH   = BLIND_STUDY\n",
        "    if LTEST:pdb.set_trace() # temp\n",
        "    CSV_LIST = os.listdir (PATH)\n",
        "    print (\"pick consolidated source from \", PATH)\n",
        "    num, pick = PICK_ONEX(CSV_LIST, \".csv\")\n",
        "    if not isinstance (num, int):\n",
        "        print (\"cant\")\n",
        "        pdb.set_trace()\n",
        "    else:\n",
        "        CSV_NAME = pick\n",
        "    # whre is the READ CSV\n",
        "    SHAROL_LIST, Echo_data = READ_SHROL_EVAL(CSV_NAME, PATH)\n",
        "    # set up tracking\n",
        "    TRACK_FILE = \"Cardiac_Patterns_TRACK_RECORD_\"+str(VERSION)+\".txt\"\n",
        "    TRACK_DIR  = os.path.join (RPT_DIR,\"track\")\n",
        "    TK=_TRACK (TRACK_FILE,TRACK_DIR)\n",
        "    ARGS = \" Track recored from \"+str(today)+\" version: \"+str(VERSION)\n",
        "    TK.L(\"MAIN\", ARGS)\n",
        "\n",
        "    #for f in FLIST :\n",
        "    A_Count = 0# READ_SHROL_EVAL number of agreements\n",
        "    R_Count = 0 # number of records processes\n",
        "    X_Count = 0 # number of disagreements\n",
        "    M_Count = 0 # number of marginal deciions\n",
        "    N_Count = 0 # numer of NO AI\n",
        "    NValid  = 0 # count of valid cases\n",
        "    LTEST = False\n",
        "    TEST=False\n",
        "    #####\n",
        "    print (\"Engaging YOLOV8 with root:\", ROOT)\n",
        "    if TEST: pdb.set_trace()\n",
        "    #A#VI_DIR =VD= os.path.join (\"C:\\\\\", \"AI\", \"videos\"  )\n",
        "    AVI_DIR =VD= VID_DIR  # conv FROM COFIG\n",
        "    #PICKEL_DIR =PD=os.path.join (ROOT, \"STORE\")\n",
        "    PICKEL_DIR = PD=STORE\n",
        "\n",
        "    print (\"initializing video class & pickel dir:\\n\", VD,\"\\n :\", PD)\n",
        "    #VID_CLASS = V=VIDEO (AVI_DIR)\n",
        "    VID_CLASS = V = VIDEO (VID_DIR) # thi is active videos not ROOT vids which may not benecessary\n",
        "    V._set_TEST(True)\n",
        "    OK=V._get_vid_np_status()   #_get_vid_np_status\n",
        "    if OK:\n",
        "     VID_np=V._get_vid_np()\n",
        "    else: print (\"VID_NP Not initilized, creating new array [ may take a while], or request pickel\")\n",
        "    xx=input (\"cr = go with pickel\")\n",
        "    if xx!=\"\":\n",
        "        VID_STAT,VID_np=V._create_vid_np(VD)\n",
        "        if not VID_STAT:\n",
        "            print(\"couldn't create vid_np (empty)\")\n",
        "    ## seg up pickle\n",
        "\n",
        "        if not os.path.exists (PD):\n",
        "            os.makedirs(PD)\n",
        "            print (\"creating \", PD)\n",
        "        print ( \"pickel version of video is at \",PD)\n",
        "        V._set_pickel_dir(PD)  # this is OK\n",
        "        V._set_vid_dir (VID_DIR)  # neessary aftger convert\n",
        "        LAST_PICKEL_PATH = \"unconfigured\"\n",
        "        LAST_PICKEL_NAME = \"unconfigured\"\n",
        "        LAST_PICKEL_DIR  = \"unconfigured\"\n",
        "        Plist = os.listdir(PD)  # list of pickeled vids\n",
        "        # check VID_STAT\n",
        "        #if not VID_STAT:# its neer oin to  be TRue\n",
        "        print (\"Initilizing Video NP array from pickle\")\n",
        "        PICKEL_NAME=\"Cardic_Patterns_Video_Lib_\"  # save fills in gthe rest\n",
        "        xx=input (\"vidstat:\"+\" create new pickenl only,vid np n,= cr=retrieve pickle\")\n",
        "        print (\"NOT IMPLEMEntD\")\n",
        "        pdb.set_trace()\n",
        "    if xx==\"n\":\n",
        "            print (\"FORCE create new pickel?\")\n",
        "            FORCE=True\n",
        "            nx=-1\n",
        "            VID_STAT,VID_np=V._create_video_np(VD)\n",
        "            if not VID_STAT:\n",
        "                print (\"still no vide_np etter quit\")\n",
        "                pdb.set_trace()\n",
        "            OK, FULL_PICKEL_PATH = V._pickel_(PICKEL_NAME, 'save',FORCE)\n",
        "            print (\"Full pickel path is: \", FULL_PICKEL_PATH)\n",
        "            if not OK:\n",
        "                print (\"some error\")\n",
        "                pdb.set_trace()\n",
        "            '''\n",
        "        elif xx==\"S\":\n",
        "            nx,pick = PICK_ONEX(Plist, \"pkl\")\n",
        "        else:\n",
        "            VID_DIR = os.path.join (AVI_DIR)\n",
        "            VID_NP=V._just_np( AVI_DIR)\n",
        "            pdb.set_trace()\n",
        "             '''\n",
        "    elif xx==\"\":\n",
        "    # SELECT ESxITING PICKEL\n",
        "        Plist=os.listdir(PICKEL_DIR)\n",
        "        if not os.path.exists (PICKEL_DIR):\n",
        "            print (\"doesnt exist: \", PD)\n",
        "            pdb.set_trace()\n",
        "        nx,pick = PICK_ONEX(Plist, \"pkl\")\n",
        "        if nx<0:  # not pick or none\n",
        "            print (\"No saved pickels or force new :create new pickle\")\n",
        "            FORCE=True\n",
        "            PICKEL_NAME=\"Cardic_Patterns_Video_Lib\"\n",
        "            V._set_ECHO(True)\n",
        "            V._set_TEST(True)\n",
        "\n",
        "            #PICKEL_DIR = PD=os.path.join (ROOT,\"STORE\") # alray\n",
        "            #V._set_pickel_dir(PD)\n",
        "            PPP=os.path.join (PD,PICKEL_NAME) # might be  problem if forced\n",
        "            #V._set_pickel_path(PPP)  # full path\n",
        "            '''\n",
        "            #VID_NP = V._create_vid_np(AVI_DIR)\n",
        "            if not V._set_pickel_data(PICKEL_NAME, PD):\n",
        "                print (\"pickel error\")\n",
        "                pdb.set_trace()\n",
        "                '''\n",
        "            OK, FULL_PICKEL_PATH = V._pickel_(PICKEL_NAME, 'load',FORCE)\n",
        "            print (\"Full pickel path is: \", FULL_PICKEL_PATH)\n",
        "            if not OK:\n",
        "                print (\"some error\")\n",
        "                pdb.set_trace()\n",
        "        else: # using existing pickel\n",
        "            print (\" exiting pkl, usng \",pick)\n",
        "            PICKEL_NAME = pick\n",
        "            PICKEL_PATH  =PP=os.path.join (PICKEL_DIR, pick)\n",
        "            V._set_pickel_dir(PICKEL_DIR)\n",
        "            V._set_pickel_path (PICKEL_PATH)  # FULLL PATH\n",
        "            OK, VID_NP=V._pickel_(PICKEL_NAME, \"load\")\n",
        "            #OK,NVID= V._create_vid_np(AVI_DIR)  # hould alredy be there fro m pickle\n",
        "            if not V._get_VID_STATUS():\n",
        "                print (\"bad status after pickel load\")\n",
        "                pdb.set_trace()\n",
        "            XVID=V._just_np(AVI_DIR)\n",
        "            if not OK:\n",
        "                print (\"problem loading video np\") #VID_NP2 = V._get_vid_np()\n",
        "                pdb.set_trace()\n",
        "\n",
        "    print (\"status of vid: \", V._get_vid_np_status())\n",
        "\n",
        "    #VID_np =V._get_vid_np()  # shoul alreaey hqe it\n",
        "    OK,VID_np=V._create_vid_np(AVI_DIR)# conve.  creage vid np in curent en ieomn\n",
        "    if not OK:\n",
        "      print (\"error in re-ceating vid_np\")\n",
        "      pdb.set_trace()  # conv upate\n",
        "    VID_np=V._just_np(AVI_DIR)  # aove doesnt work\n",
        "    LTEST=False\n",
        "    if LTEST: pdb.set_trace()\n",
        "    yolov=Y=YOLOV8(ROOT)\n",
        "    Y._set_vid_dir(AVI_DIR)\n",
        "    Y._set_vid_class(V)\n",
        "    Y._set_TEST(False)\n",
        "    Y._set_ECHO(True)\n",
        "    Y._set_PICKEL_DIR (PD)\n",
        "    MODELS = (\"yolov8x.pt\", \"yolov8m.pt\", \"yolov8l.pt\", \"yolov8n.pt\", \"yolov8n.pt\") # just the size\n",
        "    MODEL_NAME=\"yolov8x.pt\"\n",
        "    #MODEL_NAME=\"yolov8l.pt\"  # try smaller model NO\n",
        "    WEIGHTS_NAME = \"best.pt\"\n",
        "    #W_FP = WEIGHTS_NAME=os.path.join (\"D:\\\\\",\"CP_BLIND_STUDY\",\"PROCESSED_REPORTS\",\"MODEL\", WEIGHTS_NAME)\n",
        "    W_FP = Weights_Full_path = os.path.join (WEIGHTS, WEIGHTS_NAME) # fixed for conv\n",
        "    OK, model= Y._load_yolo(MODEL_NAME, W_FP)\n",
        "    Y._set_TEST(False)\n",
        "    Ok=Y._create_np()\n",
        "    OK=Y._set_vid_dir(AVI_DIR)\n",
        "    XTEST=False\n",
        "    if not OK:\n",
        "        pdb.set_trace()\n",
        "    if XTEST: pdb.set_trace()\n",
        "    Y._set_TEST(False)\n",
        "    Yolo_np,OK=Y._get_yolo_np() # geg entrie arrayhoule be empty at this point\n",
        "    print (Y._config())\n",
        "    if LTEST:pdb.set_trace()\n",
        "    RESULT_PICKEL_PATH = RPD=os.path.join (ROOT, \"RESULT\")\n",
        "    os.makedirs (RPD, exist_ok=True)\n",
        "    Y._set_PICKEL_DIR(RPD)\n",
        "    xx=input (\"limit ground truth = number or cr = no\")\n",
        "    if xx==\"\":\n",
        "        print (\"dont limit\")\n",
        "        SHAROL_LIMIT = False\n",
        "        NSHAROL      = 10000 # EFECTIELYINFINITE\n",
        "    else:\n",
        "        try:\n",
        "            nshrol= int (xx)\n",
        "            SHAROL_LIMIT = True\n",
        "            NSHAROL=nshrol\n",
        "        except Exception as EX:\n",
        "            print (\"some problem: \", EX)\n",
        "            pdb.set_trace()\n",
        "    Nsharol=0\n",
        "    V._set_TEST(False) # so not too manuy igerruptions\n",
        "    for S in SHAROL_LIST :\n",
        "        # SHROL LISTtag,sharol,Qscore\n",
        "        if SHAROL_LIMIT :print (\"working on sharol no. \",Nsharol, \" of \",NSHAROL)\n",
        "        TAG=S[0]\n",
        "        if TAG==\"TESTX\": continue\n",
        "        DIAG=S[1]\n",
        "        Qscore=S[2]\n",
        "        if Y._exists(TAG):\n",
        "            #Y._set_TEST(True)\n",
        "            YOLO_NP_ONE_ROW= Y._get_tag_values (TAG) # TAG VALUES =([\" \",\" \",0.1,\"\",0.2,0,\"X\"])\n",
        "        else:\n",
        "            Y._set_TEST(False)  #check out conversion to colab\n",
        "            OK =Y._add_tag(TAG)  #= DO ONE TAG, il el RUN THE MODEL\n",
        "        Nsharol+=1\n",
        "        if SHAROL_LIMIT:\n",
        "          if Nsharol>=NSHAROL: break\n",
        "\n",
        "        #OK=Y._do_one_tag(TAG)\n",
        "     # what's in YOLOV_NP?\n",
        "    print (\"end of sharol list  saving Results in pickle\")\n",
        "    print (\"HERE IS ERROR CHECK PICKEL STORE!!\")\n",
        "    # shrol list format: (<TAG>, <GROUND TRUTH>,<QCO.)\n",
        "    #                       0        1           2\n",
        "    if LTEST:pdb.set_trace() # TRaCE FROM HERE\n",
        "    #Yolo_np, OK=Y._get_np()\n",
        "    Y._set_TEST(False)  # conv gtesting\n",
        "    Yolo_np, OK =Y._get_yolo_np()\n",
        "    if not OK: pdb.set_trace()\n",
        "\n",
        "        ########################\n",
        "        ### YOLO NP IS now ready\n",
        "        ### with TAG, AI-LABBE , ai_conf1, etc.\n",
        "        #   Set up checkpoint save\n",
        "        #######################\n",
        "    CHECK_DIR = CHECK_POINT  # set by config really CHECKPOINTS\n",
        "    TEST=False\n",
        "    print (Y._config() )\n",
        "    if TEST: pdb.set_trace()\n",
        "    Y._set_TEST(True)\n",
        "    #YOLO_PICKEL_DIR = YPD=os.path.join (ROOT, \"STORE\")\n",
        "    YOLO_PICKEL_DIR = YPD=os.path.join (CHECK_POINT)\n",
        "    print (\"Setting check point dir to \", YPD)\n",
        "    Y._set_PICKEL_DIR ( YPD)\n",
        "    PICKLE_NAME = \"CP_YOLOV8 \"+str(VERSION)  # module adds time stmp\n",
        "    Y._pickel_result (Yolo_np, PICKLE_NAME, MODE=\"save\")  #NOT NOWbYES\n",
        "    if LTEST:pdb.set_trace()\n",
        "    Nsharol=0\n",
        "    # SHAROL LIST FORMAT:\n",
        "    for S in SHAROL_LIST:\n",
        "        # get fp from TRIAGE\n",
        "        #fp=os.path.join (FP,f)\n",
        "        #TAG=TAG_FROM_VID (fp)\n",
        "        TAG = S[0]\n",
        "        if LTEST: pdb.set_trace()\n",
        "        Qscore = S[2] ##from zerro\n",
        "        if '\"' in TAG:\n",
        "            if LTEST: print ('removing quote from ', TAG)\n",
        "            TAG.replace('\"','')\n",
        "        line = TT+TAG\n",
        "        # get AI diagnosis\n",
        "        #OK, TPL = Y._get_tag_values (TAG) # do we need this?\n",
        "        if TAG ==\"TESTX\" : continue\n",
        "        OK, YPL =Y._Get_YOLO_Values( TAG)  # returs AILABEL, AICONF, AI2LABEL, AI2ONF\n",
        "        if not OK:\n",
        "          print (TAG, \" does not exist in Yolo_np skipping\")\n",
        "          continue\n",
        "        XTAG, Y_LABEL1, Y_CONF1, Y_LABEL2, Y_CONF2, Y_QSCORE,X = YPL\n",
        "        # NOTE: YPL = ['4BC345' ,'Mild','0.9','Severe' ,'0.0' ,'0', '']\n",
        "        # one row=one_row(TAG, L1, C1, L2, C2, Q, X)\n",
        "        # NOTEE YOLO FORMAT HAs changed from erlier\n",
        "        # NO fILE name in yolo format\n",
        "\n",
        "\n",
        "        if LTEST : pdb.set_trace()\n",
        "        NO_AI = False\n",
        "        if not OK:\n",
        "            FILE_NAME = \"unk\"\n",
        "            CONF      = 0\n",
        "        else:\n",
        "          # note in YOLO NO file name.\n",
        "          if YOLO_FORMAT:\n",
        "            #FILE_NAME = TPL[3]\n",
        "            FILE_NAME  = \"Unspecified\"\n",
        "            #CONF      = TPL[6]\n",
        "            CONF      = YPL[2] # conv go YOLO\n",
        "          else:\n",
        "            CONF      = TPL[6]\n",
        "            FILE_NAME = TPL[3]\n",
        "        if not OK:\n",
        "            print (\"cant get ai for \", TAG)\n",
        "            AI=\"__________\"\n",
        "            NO_AI = True\n",
        "            print (\"ommitting \", TAG, ' no ai')\n",
        "            MISSING_TAGS.append (TAG)\n",
        "            N_Count +=1\n",
        "            continue\n",
        "        else:\n",
        "          if YOLO_FORMAT:\n",
        "            AI=YPL[1]  # conv\n",
        "            CONF=YPL[2] # conv updage\n",
        "          else:\n",
        "            AI = TPL[5]\n",
        "        if CHECK:\n",
        "            #pdb.set_trace()\n",
        "            if YOLO_FORMAT:\n",
        "              label2=YPL[3]\n",
        "              conf2 = YPL[4]\n",
        "            else: # must be non yolo\n",
        "              label2=TPL[7]\n",
        "              conf2 = TPL[8]\n",
        "            NValid+=1  # total valid cases\n",
        "            SHAROL = S[1]\n",
        "            AGR, EQ= CHECK_AGREEMENT (AI, CONF,label2, conf2,SHAROL, TAG)\n",
        "            if EQ==1: M_Count+=1\n",
        "            R_Count +=1  # add up total recoreds\n",
        "            if AGR:\n",
        "                A_Count +=1\n",
        "                CC=\"1\"\n",
        "                if EQ==1:\n",
        "                    CC=\"Equivocal\"\n",
        "            else:\n",
        "                CC=\"0\"\n",
        "                X_Count+=1  # Disagreements\n",
        "\n",
        "        line+=TT+str(AI)+TT+str(CONF)+TT+str(label2)+TT+str(conf2)\n",
        "        line+=TT+str(SHAROL)+TT+str(FILE_NAME)\n",
        "        line+=TT+str(CC)#+\"\\n\"\n",
        "        # add yolo line\n",
        "        Yline=\"YOLOV8_\"+str(TAG)+TT+Y_LABEL1+TT+ Y_CONF1+TT+ Y_LABEL2+TT+ Y_CONF2+TT+Y_QSCORE\n",
        "        TK.T(line)\n",
        "        TK.T(Yline)\n",
        "        RPT.addL(line)\n",
        "        RPT.addL(Yline)\n",
        "        # hek limit\n",
        "        Nsharol+=1\n",
        "\n",
        "        if SHAROL_LIMIT:\n",
        "            if Nsharol==NSHAROL:\n",
        "                print (\"sharol limit of \", NSHAROL, \" reached\")\n",
        "                break\n",
        "\n",
        "    arg=\"calculating summary,look in\"+str(RPT_DIR)\n",
        "    print (arg)\n",
        "    TK.T(arg)\n",
        "    XTEST=False\n",
        "    if XTEST: pdb.set_trace()\n",
        "    sumL=\"SUMMARY \\n\\t TOTAL RECORDS\"+TT+ \"VALID CASES\"+TT+\"TOTAL AGREEMENTS \"+TT+\"DISAGREE\"+TT+\"RATIO\"+TT+\"EQUIVOCAl\"+TT+\"NO AI \\n\"\n",
        "    sumL+=str(R_Count)+ TT+str(NValid)+TT+str(A_Count)+TT+str(X_Count)+TT\n",
        "    if NValid==0:\n",
        "      NValid = 1\n",
        "      print (\"cant calculate percentae [DIV zero]\")\n",
        "      R=0\n",
        "    else:\n",
        "      R=f\"{int(A_Count)/int(NValid):.2%}\"\n",
        "    sumL+=str (R)+TT\n",
        "    sumL+=str(M_Count)+TT+str(N_Count)\n",
        "    TK.T (sumL)\n",
        "    RPT.addL(sumL)\n",
        "    marginL =\"\\n\\n \"+\"Equivocal Margine is \"+str(MARGIN)\n",
        "    RPT.addL(marginL)\n",
        "    TK.T(marginL)\n",
        "    print (\"\\n\\n MISSING TAGS: \", MISSING_TAGS)\n",
        "    mline =\"\\n Missing \"+str (len(MISSING_TAGS))+\" TAGs  for v\"+str(VERSION)+ \" as of \"+ str(today)    +\"\\n\"\n",
        "    RPT.addL(mline)\n",
        "    TK.T(mline)\n",
        "    ETEST = False # check numbers f or v129\n",
        "    if ETEST: pdb.set_trace()\n",
        "    line = \"\"\n",
        "    for i in range (len(MISSING_TAGS)) :    line+=str(MISSING_TAGS[i])  +\",  \"\n",
        "    RPT.addL(line)\n",
        "    TK.T(line)\n",
        "    arg=\"end of report at \"+str(RPT_DIR)\n",
        "    print (arg)\n",
        "    TK.T(arg)\n",
        "    RPT.endFile(\"END OF BLIND LIST\")\n",
        "    TK.E()\n",
        "    if LTEST: pdb.set_trace()\n",
        "    return"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xvNIhn5YeiyP",
        "outputId": "06b10f09-e929-4ee4-b771-3c4058cb9487"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PART THREE - M A I N\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print (\"settting up configurations\")\n",
        "C_CONFIG={\"ROOT\":os.path.join (\"/content/\")}\n",
        "C_CONFIG[\"LIBS\"]=os.path.join (\"/content/LIBS\")\n",
        "C_CONFIG[\"WEIGHTS\"]=os.path.join (\"/content/WEIGHTS\")\n",
        "C_CONFIG[\"STORE\"]=os.path.join (\"/content/STORE\")\n",
        "C_CONFIG[\"VIDEOS\"]=os.path.join (\"/content/VIDEOS\")\n",
        "C_CONFIG[\"REPORTS\"]=os.path.join (\"/content/REPORTS\")\n",
        "C_CONFIG[\"TRIAGE\"]=os.path.join (\"/content/TRIAGE\")\n",
        "C_CONFIG[\"CHECK_POINT\"]=os.path.join (\"/content/CHECK_POINTS\")\n",
        "C_CONFIG[\"BLIND_STUDY\"]=os.path.join (\"/content/BLIND_STUDY\")\n",
        "#pdb.set_trace()\n",
        "'''\n",
        "print (C_CONFIG)\n",
        "ROOT=C_CONFIG[\"ROOT\"]\n",
        "LIBS=C_CONFIG[\"LIBS\"]\n",
        "VIDEOS=C_CONFIG[\"VIDEOS\"]\n",
        "print (ROOT,\"\\n\", LIBS, VIDEOS)\n",
        "'''\n",
        "ROOT=os.path.join (\"D:\\\\\",\"CP_BLIND_STUDY\",'PROCESSED_REPORTS')\n",
        "A_CONFIG={\"ROOT\":ROOT}\n",
        "A_CONFIG[\"LIBS\"]=os.path.join (ROOT,\"LIBS\")\n",
        "A_CONFIG[\"WEIGHTS\"]=os.path.join (ROOT,\"WEIGHTS\")\n",
        "A_CONFIG[\"STORE\"]=os.path.join (ROOT,\"STORE\")\n",
        "A_CONFIG[\"VIDEOS\"]=os.path.join (\"C:\\\\\",\"AI\")# NOT OFF OF ROOT\n",
        "A_CONFIG['REPORTS']=os.path.join (ROOT,'report' )\n",
        "A_CONFIG['TRIAGE']=os.path.join (\"D:\\\\\",\"MASTER_RUN\" )# FROM DIFFERENT PROJECT\n",
        "A_CONFIG['CHECK_POINT']=os.path.join (ROOT,\"CHECK_POINTS\" )\n",
        "A_CONFIG['BLIND_STUDY']=os.path.join (ROOT,\"BLIND_STUDY\" )\n",
        "BROOT=os.path.join (\"E:\\\\\",\"BLIND_STUDY\")\n",
        "B_CONFIG={\"ROOT\":BROOT}\n",
        "B_CONFIG[\"LIBS\"]=os.path.join (BROOT,\"LIBS\")\n",
        "B_CONFIG[\"WEIGHTS\"]=os.path.join (BROOT,\"WEIGHTS\")\n",
        "B_CONFIG[\"STORE\"]=os.path.join (BROOT,\"STORE\")\n",
        "B_CONFIG[\"VIDEOS\"]=os.path.join (BROOT,\"VIDEOS\")\n",
        "B_CONFIG[\"VIDEOS\"]=os.path.join (BROOT,\"VIDEOS\")\n",
        "B_CONFIG[\"CHECK_POINT\"]=os.path.join (BROOT,\"CHECK_POINTS\")\n",
        "B_CONFIG[\"BLIND_STUDY\"]=os.path.join (BROOT,\"BLIND_STUDY\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EXCAFPfyv_Ze",
        "outputId": "2da0e681-8fcd-452a-bc92-e9bf03c6c9c3"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "settting up configurations\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SYSTEM_A='a'\n",
        "SYSTEM_B='b'\n",
        "SYSTEM_C='c' # colab\n",
        "PLATFORM=\"unknown\"\n",
        "def SELECT_PLATFORM():\n",
        "  xx=input (\"select platform a, b, or c =colab\")\n",
        "  O=xx.lower()\n",
        "  if O=='a':\n",
        "    PLATFORM = SYSTEM_A\n",
        "    return A_CONFIG\n",
        "  elif O=='b':\n",
        "    PLATFORM=SYSTEM_B\n",
        "    return PLATFORM\n",
        "  elif O=='c':\n",
        "   PLATFORM=SYSTEM_C\n",
        "   PLATFORM=\"Colab\"\n",
        "   print (\"P L A T F O R M=\",PLATFORM)\n",
        "   return C_CONFIG\n",
        "  else:\n",
        "    print (\"unknown configuration, you typed\", xx)\n",
        "  return None\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "D0YjYqMB05ZD"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (\"STARTING\")\n",
        "CONFIG=SELECT_PLATFORM()\n",
        "print (\"you selected for\",PLATFORM, \" with \", CONFIG)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzJY-j1R-IJ-",
        "outputId": "77e73bf8-57b3-4286-ef50-cc79c2090fc6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "STARTING\n",
            "select platform a, b, or c =colabc\n",
            "P L A T F O R M= Colab\n",
            "you selected for unknown  with  {'ROOT': '/content/', 'LIBS': '/content/LIBS', 'WEIGHTS': '/content/WEIGHTS', 'STORE': '/content/STORE', 'VIDEOS': '/content/VIDEOS', 'REPORTS': '/content/REPORTS', 'TRIAGE': '/content/TRIAGE', 'CHECK_POINT': '/content/CHECK_POINTS', 'BLIND_STUDY': '/content/BLIND_STUDY'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def UNPACK_CONFIG(CONFIG):\n",
        "  #pdb.set_trace()\n",
        "  ROOT=CONFIG[\"ROOT\"]\n",
        "  VID_DIR=CONFIG[\"VIDEOS\"]\n",
        "  LIB_DIR=CONFIG[\"LIBS\"]\n",
        "  BEST_DIR=CONFIG[\"WEIGHTS\"] # =  best.pt\n",
        "  STORE   =CONFIG[\"STORE\"]\n",
        "  RPT_DIR =CONFIG[\"REPORTS\"]\n",
        "  TRIAGE_DIR=CONFIG[\"TRIAGE\"]\n",
        "  CHECK_POINT=CONFIG[\"CHECK_POINT\"]\n",
        "  BLIND_STUDY=CONFIG[\"BLIND_STUDY\"]\n",
        "  return ROOT, TRIAGE_DIR, VID_DIR, LIB_DIR,BEST_DIR, STORE, RPT_DIR,CHECK_POINT,BLIND_STUDY"
      ],
      "metadata": {
        "id": "W_wVSkmRBT_t"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# parT four start\n",
        "if __name__=='__main__':\n",
        "          print (\" from \", os.getcwd(), \" VERSION\", VERSION, \" \\n MISSION: \", MISSION)\n",
        "          #pdb.set_trace()\n",
        "          PROJ=  os.getcwd()  # We are here\n",
        "          #CONFIG=ROOT, VID_DIR, LIB_DIR,BEST_DIR, STORE =SELECT_PLATFORM\n",
        "          print (\"ECHO CONFIG\")\n",
        "          print (CONFIG)\n",
        "          main (CONFIG)\n",
        "          print (\"end of processing\")\n",
        "          pdb.set_trace()"
      ],
      "metadata": {
        "id": "_IXHx7Uxfq83",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58b03fe1-2c3c-43e6-e9cd-52ddd4578112"
      },
      "execution_count": 17,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " from  /content  VERSION 0.264  \n",
            " MISSION:   ADD AI EVALUATION TO REPORT & TRACKING & YOLOV8 predictions @ v 250\n",
            " v260 is working!! c v 261 has sharol limit to shorten running\n",
            " porting to colap and genrealize configurations\n",
            "ECHO CONFIG\n",
            "{'ROOT': '/content/', 'LIBS': '/content/LIBS', 'WEIGHTS': '/content/WEIGHTS', 'STORE': '/content/STORE', 'VIDEOS': '/content/VIDEOS', 'REPORTS': '/content/REPORTS', 'TRIAGE': '/content/TRIAGE', 'CHECK_POINT': '/content/CHECK_POINTS', 'BLIND_STUDY': '/content/BLIND_STUDY'}\n",
            "using yolo format:  True\n",
            "\n",
            " CONFIGURATION: /content/ /content/TRIAGE /content/VIDEOS /content/LIBS /content/WEIGHTS /content/STORE /content/REPORTS /content/CHECK_POINTS /content/BLIND_STUDY\n",
            "> \u001b[0;32m<ipython-input-16-d5844e1508b7>\u001b[0m(21)\u001b[0;36mmain\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m     19 \u001b[0;31m    \u001b[0mMARGIN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.45\u001b[0m  \u001b[0;31m# FROM ANALYSIS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m     20 \u001b[0;31m    \u001b[0;32mif\u001b[0m \u001b[0mCTEST\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m---> 21 \u001b[0;31m    \u001b[0mTEST\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m     22 \u001b[0;31m    \u001b[0mCHECK\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m  \u001b[0;31m# CHEOCN AGREEMENT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m     23 \u001b[0;31m    \u001b[0mMODULE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Main\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\n",
            "ipdb> c\n",
            "\n",
            " ENTERING M A I N with  /content/\n",
            "spelling corrections: \n",
            " ITEM CORRECTION\n",
            "\n",
            "Mil \t Mild\n",
            "Norml \t Normal\n",
            "Sever \t Severe\n",
            "Prothetic \t Prosthetic\n",
            "Prostetic \t Prosthetic\n",
            "Stenosed \t Stenosis\n",
            "generated score report from email cr=no\n",
            "\n",
            "Equi-val Margin is  0.45  \n",
            "\n",
            " LOAD TRIAGE WITH:  ALL_MASTER_TRIAGE_071223_v01.csv /content/TRIAGE /content/VIDEOS\n",
            "TRIAGE TEST is :  False\n",
            "F-1 EHO ia:  True\n",
            "[ 0 ]= CARDIAC_TRIAGE0.220230824-110623.pkl\n",
            "PIck from list by number: 0\n",
            "OK\n",
            "TRIAGE TEST is :  False\n",
            "PICKEL process for triage as  CARDIAC_TRIAGE0.220230824-110623.pkl  MODE:  load\n",
            "reaport:  Cardiac_Patterns_Consolidatd_Blind_Study_2024-01-22_0.264.txt  at  /content/REPORTS\n",
            "pick consolidated source from  /content/BLIND_STUDY\n",
            "[ 0 ]= Blind_Study_consolidation_MASTER_1205223v03.csv\n",
            "PIck from list by number: 0\n",
            "Blind_Study_consolidation_MASTER_1205223v03.csv |/content/BLIND_STUDY\n",
            " Read in prepare d echo ecaluations\n",
            "CLASS F_1 Called with  (False, False)\n",
            "reading in consolicated csv file:  Blind_Study_consolidation_MASTER_1205223v03.csv  AT  /content/BLIND_STUDY\n",
            "F_1-Load_CSV_Ground_Truth Called with  Blind_Study_consolidation_MASTER_1205223v03.csv / /content/BLIND_STUDY\n",
            "skipping row:  ['TAG' 'AI' 'DIAG' 'COMPL' 'Q-Score' 'COMMENT' 'DATE']\n",
            "[ 0 ]  is blank, skipping ['' '' '' '' '' '' '']\n",
            "[ 0 ]  is blank, skipping ['' '' '' '' '' '' '9-Oct']\n",
            "[ 30 ]  is blank, skipping ['' '' '' '' '' '' '']\n",
            "[ 30 ]  is blank, skipping ['' '' '' '' '' '' '5-Dec']\n",
            "[ 30 ]  is blank, skipping ['' '' '' '' '' '' '']\n",
            "removed space from numpy char string:  A87A3\n",
            "NOT FIXED  prosthetic np str and NOT ndarray and NOT python str so exiting clean label\n",
            "removed space from numpy char string:  FAEA7\n",
            "removed space from numpy char string:  72DA9\n",
            "removed space from numpy char string:  88C16\n",
            "removed space from numpy char string:  7E12F\n",
            "removed space from numpy char string:  B7CF9\n",
            "removed space from numpy char string:  D2C10\n",
            "removed space from numpy char string:  0A7BE\n",
            "removed space from numpy char string:  3BFFE\n",
            "removed space from numpy char string:  67C53\n",
            "removed space from numpy char string:  D72F9\n",
            "removed space from numpy char string:  520B8\n",
            "removed space from numpy char string:  F2429\n",
            "removed space from numpy char string:  AAFF1\n",
            "removed space from numpy char string:  BC5E0\n",
            "removed space from numpy char string:  5BB16\n",
            "removed space from numpy char string:  8D7F2\n",
            "removed space from numpy char string:  7D596\n",
            "removed space from numpy char string:  C9715\n",
            "removed space from numpy char string:  66AB9\n",
            "removed space from numpy char string:  9A280\n",
            "removed space from numpy char string:  87BA6\n",
            "removed space from numpy char string:  E0D41\n",
            "removed space from numpy char string:  BCBD9\n",
            "removed space from numpy char string:  6E313\n",
            "removed space from numpy char string:  3A124\n",
            "removed space from numpy char string:  988F0\n",
            "removed space from numpy char string:  FF143\n",
            "removed space from numpy char string:  6BEEF\n",
            "removed space from numpy char string:  84BDD\n",
            "removed space from numpy char string:  DF1B2\n",
            "removed space from numpy char string:  5D1D7\n",
            "removed space from numpy char string:  F1679\n",
            "removed space from numpy char string:  C6290\n",
            "removed space from numpy char string:  476D3\n",
            "removed space from numpy char string:  A8EFA\n",
            "NOT FIXED  Non-Visible np str and NOT ndarray and NOT python str so exiting clean label\n",
            "NOT FIXED  1 np str and NOT ndarray and NOT python str so exiting clean label\n",
            "Quality failure on  6EDA8 Non-Visible  1  skipping\n",
            "removed space from numpy char string:  4912D\n",
            "removed space from numpy char string:  74B4A\n",
            "removed space from numpy char string:  A329B\n",
            "removed space from numpy char string:  DF986\n",
            "removed space from numpy char string:  NORMAL\n",
            "removed space from numpy char string:  2F188\n",
            "[ 90 ]  is blank, skipping ['' '' '' '' '' '' '']\n",
            "[ 90 ]  is blank, skipping ['' '' '' '' '' '' '']\n",
            "[ 90 ]  is blank, skipping ['' '' '' '' '' '' '']\n",
            "[ 90 ]  is blank, skipping ['' '' '' '' '' '' '']\n",
            "[ 90 ]  is blank, skipping ['' '' '' '' '' '' '']\n",
            "[ 90 ]  is blank, skipping ['' '' '' '' '' '' '']\n",
            "[ 90 ]  is blank, skipping ['' '' '' '' '' '' '']\n",
            "[ 90 ]  is blank, skipping ['' '' '' '' '' '' '']\n",
            "NOT FIXED  Severe np str and NOT ndarray and NOT python str so exiting clean label\n",
            "NOT FIXED  1 np str and NOT ndarray and NOT python str so exiting clean label\n",
            "Quality failure on  51C53 Severe NON VISABLE 1  ( REMOVER FROM STUDY) skipping\n",
            "NOT FIXED  Severe np str and NOT ndarray and NOT python str so exiting clean label\n",
            "NOT FIXED  Severe np str and NOT ndarray and NOT python str so exiting clean label\n",
            "NOT FIXED  Severe np str and NOT ndarray and NOT python str so exiting clean label\n",
            "NOT FIXED  Severe np str and NOT ndarray and NOT python str so exiting clean label\n",
            "NOT FIXED  Severe np str and NOT ndarray and NOT python str so exiting clean label\n",
            "removed space from numpy char string:  NONVISABLE(REMOVERFROMSTUDY)\n",
            "NOT FIXED  Severe np str and NOT ndarray and NOT python str so exiting clean label\n",
            "NOT FIXED  Severe np str and NOT ndarray and NOT python str so exiting clean label\n",
            "NOT FIXED  Severe np str and NOT ndarray and NOT python str so exiting clean label\n",
            "NOT FIXED  Severe np str and NOT ndarray and NOT python str so exiting clean label\n",
            "NOT FIXED  Severe np str and NOT ndarray and NOT python str so exiting clean label\n",
            "NOT FIXED  Severe np str and NOT ndarray and NOT python str so exiting clean label\n",
            "NOT FIXED  Severe np str and NOT ndarray and NOT python str so exiting clean label\n",
            "NOT FIXED  Severe np str and NOT ndarray and NOT python str so exiting clean label\n",
            "NOT FIXED   np str and NOT ndarray and NOT python str so exiting clean label\n",
            "NOT FIXED   np str and NOT ndarray and NOT python str so exiting clean label\n",
            "[ 149 ]  is blank, skipping ['' '' '' '' '' '' '']\n",
            "[ 149 ]  is blank, skipping ['' '' '' '' '8-Nov' '' '']\n",
            "[ 149 ]  is blank, skipping ['' '' '' '' '' '' '']\n",
            "removed space from numpy char string:  NON-VISABLE\n",
            "removed space from numpy char string:  MILD(IMAGEHASLOSTOFARTIFACTPERHAPSOMITIMAGE)\n",
            "removed space from numpy char string:  NONVISABLE(OMITIMIAGE)\n",
            "Not fixed list retueinve list of TAG,SHAROL\n",
            "210 sharol cases foudn\n",
            "USAGE _X=_T (File, dir) \n",
            "-X.L('finction', 'args')\n",
            "_X.E(), \n",
            "just trace_X.T(args)\n",
            "Engaging YOLOV8 with root: /content/\n",
            "initializing video class & pickel dir:\n",
            " /content/VIDEOS \n",
            " : /content/STORE\n",
            "VID_NP Not initilized, creating new array [ may take a while], or request pickel\n",
            "cr = go with pickel\n",
            "[ 0 ]= Cardic_Patterns_Video_Lib_02_20240113-143422.pkl\n",
            "PIck from list by number: 0\n",
            " exiting pkl, usng  Cardic_Patterns_Video_Lib_02_20240113-143422.pkl\n",
            "> \u001b[0;32m/content/LIBS/CardiacVIDlib.py\u001b[0m(259)\u001b[0;36m_pickel_\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m    257 \u001b[0;31m        \u001b[0;31m#SAVE_NAME = PICKEL_NAME +str(self.AVI_PATH) # What isavi path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m    258 \u001b[0;31m        \u001b[0;31m#date=datetime()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m--> 259 \u001b[0;31m        \u001b[0mtimestr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%Y%m%d-%H%M%S\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m    260 \u001b[0;31m        \u001b[0;31m#if self.TEST: pdb.set_trace()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m    261 \u001b[0;31m        \u001b[0;31m# sample output: 20120515-155045\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\n",
            "ipdb> c\n",
            "status of vid:  True\n",
            "> \u001b[0;32m/content/LIBS/CardiacVIDlib.py\u001b[0m(137)\u001b[0;36m_create_vid_np\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m    135 \u001b[0;31m    \u001b[0;32mdef\u001b[0m \u001b[0m_create_vid_np\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVIDEO_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m    136 \u001b[0;31m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTEST\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m--> 137 \u001b[0;31m        \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mVIDEO_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m    138 \u001b[0;31m            \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" not existing dir \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVIDEO_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m    139 \u001b[0;31m            \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSHAPE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\n",
            "ipdb> VIDEO_DIR\n",
            "'/content/VIDEOS'\n",
            "ipdb> b 139\n",
            "Breakpoint 1 at /content/LIBS/CardiacVIDlib.py:139\n",
            "ipdb> l\n",
            "\u001b[1;32m    132 \u001b[0m            \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"UNINITILIZED\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m    133 \u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mRET\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVIDEO_NP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m    134 \u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m    135 \u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m_create_vid_np\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVIDEO_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m    136 \u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTEST\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m--> 137 \u001b[0;31m        \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mVIDEO_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[1;32m    138 \u001b[0m            \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" not existing dir \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVIDEO_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;31m1\u001b[1;32m   139 \u001b[0m            \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSHAPE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m    140 \u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVIDEO_DIR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVIDEO_DIR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m    141 \u001b[0m        \u001b[0mvid_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVIDEO_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m    142 \u001b[0m        \u001b[0mOK\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\n",
            "ipdb> b 140\n",
            "Breakpoint 2 at /content/LIBS/CardiacVIDlib.py:140\n",
            "ipdb> c\n",
            "> \u001b[0;32m/content/LIBS/CardiacVIDlib.py\u001b[0m(140)\u001b[0;36m_create_vid_np\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m    138 \u001b[0;31m            \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" not existing dir \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVIDEO_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[1;31m1\u001b[0;32m   139 \u001b[0;31m            \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSHAPE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[1;31m2\u001b[0;32m-> 140 \u001b[0;31m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVIDEO_DIR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVIDEO_DIR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m    141 \u001b[0;31m        \u001b[0mvid_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVIDEO_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m    142 \u001b[0;31m        \u001b[0mOK\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\n",
            "ipdb> c\n",
            "> \u001b[0;32m/content/LIBS/CardiacVIDlib.py\u001b[0m(130)\u001b[0;36m_get_vid_np\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m    128 \u001b[0;31m        \u001b[0mRET\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m    129 \u001b[0;31m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTEST\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m--> 130 \u001b[0;31m        \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVIDEO_STATUS\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m    131 \u001b[0;31m            \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"VIDEO_NP not initialized _1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m    132 \u001b[0;31m            \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"UNINITILIZED\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\n",
            "ipdb> c\n",
            "\n",
            " YOLOV8 class: \n",
            " ROOT DIR: /content/\n",
            " Sub dir structue: \n",
            "  WEIGHTS (pretrined weights)\n",
            "  W_DIR (weights directory) \n",
            "  MODEL\n",
            " MODEL: yolov8x.pt  model status: True\n",
            " Created 22-January\n",
            " AVI DIR: /content/VIDEOS\n",
            " ECHO: True  TEST: False\n",
            " Format of yolo_np: [TAG, Y_LABEL1, Y_CONF1, Y_LABEL2, Y_CONF2, Y_QSCORE,yx]- NEEDS UPDATING\n",
            " PICKLE STATUS data pickel: undefined date undefined\n",
            "limit ground truth = number or cr = no\n",
            "dont limit\n",
            "no values\n",
            "cant find  4BC0A\n",
            "no values\n",
            "cant find  AA094\n",
            "no values\n",
            "cant find  114DB\n",
            "no values\n",
            "cant find  93FED\n",
            "no values\n",
            "cant find  B4030\n",
            "found  8F990  at location  216\n",
            "WARNING  Environment does not support cv2.imshow() or PIL Image.show()\n",
            "\n",
            "\n",
            "\n",
            "WARNING  inference results will accumulate in RAM unless `stream=True` is passed, causing potential out-of-memory\n",
            "errors for large sources or long-running streams and videos. See https://docs.ultralytics.com/modes/predict/ for help.\n",
            "\n",
            "Example:\n",
            "    results = model(source=..., stream=True)  # generator of Results objects\n",
            "    for r in results:\n",
            "        boxes = r.boxes  # Boxes object for bbox outputs\n",
            "        masks = r.masks  # Masks object for segment masks outputs\n",
            "        probs = r.probs  # Class probabilities for classification outputs\n",
            "\n",
            "video 1/1 (1/187) /content/VIDEOS/0X5DEFDC9DAEB29CB.mp4: 1024x1024 1 Mild, 1 Normal, 13593.2ms\n",
            "video 1/1 (2/187) /content/VIDEOS/0X5DEFDC9DAEB29CB.mp4: 1024x1024 1 Mild, 1 Normal, 13212.5ms\n",
            "video 1/1 (3/187) /content/VIDEOS/0X5DEFDC9DAEB29CB.mp4: 1024x1024 1 Mild, 1 Normal, 13012.9ms\n",
            "\n",
            "Program interrupted. (Use 'cont' to resume).\n",
            "--Call--\n",
            "> \u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/debugger.py\u001b[0m(397)\u001b[0;36mset_trace\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m    395 \u001b[0;31m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstyle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscheme\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m    396 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m--> 397 \u001b[0;31m    \u001b[0;32mdef\u001b[0m \u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m    398 \u001b[0;31m        \u001b[0;32mif\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m    399 \u001b[0;31m            \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_back\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\n",
            "ipdb> q\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "HKyWitQiuQim"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}