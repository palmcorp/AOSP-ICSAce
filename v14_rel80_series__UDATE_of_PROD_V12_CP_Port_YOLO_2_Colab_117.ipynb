{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/palmcorp/AOSP-ICSAce/blob/master/v14_rel80_series__UDATE_of_PROD_V12_CP_Port_YOLO_2_Colab_117.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "fTD0htV1TfRj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26ea8892-0020-4467-e6fb-26de76da3893"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "permit rejections to count\n",
            "version:  14.0  \n",
            " M I  S S S O N  Port of workstation CP Yolov8_np to Colab to generte Yolo_np\n",
            " and estblish check points\n",
            " test NO data inerts\n",
            " Test RUN Evlutor\n",
            " recognize Q-Score\n",
            " evaluating Cycle Detector\n",
            " Reconstructd after lost code\n",
            " includes video check points for investor demo\n",
            " CardiacYOLOLIB is local to permit access to TK\n"
          ]
        }
      ],
      "source": [
        "VERSION = \"14.0\"\n",
        "RELEASE=\"88\"\n",
        "MISSION = \" Port of workstation CP Yolov8_np to Colab to generte Yolo_np\"\n",
        "MISSION+= \"\\n and estblish check points\"\n",
        "MISSION+=\"\\n test NO data inerts\"\n",
        "MISSION+=\"\\n Test RUN Evlutor\"\n",
        "MISSION+=\"\\n recognize Q-Score\"\n",
        "MISSION+=\"\\n evaluating Cycle Detector\"\n",
        "MISSION+=\"\\n Reconstructd after lost code\"\n",
        "MISSION+=\"\\n includes video check points for investor demo\"\n",
        "LOCAL_LIB= True # if ylol lib is in line\n",
        "if LOCAL_LIB: MISSION +=\"\\n CardiacYOLOLIB is local to permit access to TK\"\n",
        "OMIT=True  # omit enable\n",
        "if OMIT: print ( \"permit rejections to count\")\n",
        "else: print (\"not permitting OMITS\")\n",
        "CHECK =True  # check certin echos\n",
        "CHECK_TAGS ={'6E313':'Prosthetic', 'DF986':'Stenosis', 'B29CB':'Severe'}\n",
        "print (\"version: \", VERSION, \" \\n M I  S S S O N\", MISSION)\n",
        "USE_MASTER = True # use ai/videos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aliJPHcaN4R4",
        "outputId": "06acd149-a423-41df-ded3-4ef59f5e3ee8"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mount GOOGLE  Drive\n",
            "/content/drive/MyDrive/CardiacEchos/Videos  exists, skipping\n",
            "go to Mydrive/CardiacEchos/Videos    \n",
            "10029  videos identifid\n",
            "MAPPING TO MASTER \n",
            "Starting copy to AI\n",
            "\n",
            " DONE COPYING\n",
            "10029  videos copied\n"
          ]
        }
      ],
      "source": [
        "import os, pdb\n",
        "print (\"Mount GOOGLE  Drive\")\n",
        "from google.colab import drive\n",
        "DRIV=os.path.join (\"/content/drive/MyDrive/CardiacEchos/Videos\")\n",
        "if os.path.exists (DRIV):\n",
        "  print (DRIV, \" exists, skipping\")\n",
        "  AI=os.path.join (\"/content/AI/Videos\")\n",
        "  os.makedirs(AI, exist_ok=True) # just in case\n",
        "else:\n",
        "  drive.mount('/content/drive')\n",
        "print (\"go to Mydrive/CardiacEchos/Videos    \")\n",
        "big_vid=os.path.join (\"/content/drive/MyDrive/CardiacEchos/Videos\")\n",
        "LST_VIDS=os.listdir(big_vid)\n",
        "print (len (LST_VIDS), \" videos identifid\")\n",
        "print (\"MAPPING TO MASTER \")\n",
        "from distutils.dir_util import copy_tree\n",
        "AI_VID_PATH=AP=os.path.join (\"/content/AI/Videos\")\n",
        "os.makedirs(AP, exist_ok=True)\n",
        "if not os.path.exists(AP):\n",
        "  print (\" some problem\", AP, \" does not exist -CHECK\")\n",
        "  pdb.set_trace()\n",
        "L_now =os.listdir(\"/content/AI/Videos\")\n",
        "if len (L_now)==10029:\n",
        "    print (\"already have \", len (L_now),\"videos , skippig copy\")\n",
        "else:\n",
        "  print (\"Starting copy to AI\")\n",
        "  copy_tree(\"/content/drive/MyDrive/CardiacEchos/Videos\", \"/content/AI/Videos\")\n",
        "print (\"\\n DONE COPYING\")\n",
        "master_vid= os.path.join (\"/content/AI/Videos\")\n",
        "LST_VIDS=os.listdir(master_vid)\n",
        "print (len (LST_VIDS), \" videos copied\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_nEIRy5UGHw",
        "outputId": "bde8817f-1876-471d-aada-b672b5c77eb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "stage I; import python modules\n",
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.1.11-py3-none-any.whl (709 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m709.5/709.5 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.22.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.23.5)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.8.0.76)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.31.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.11.4)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.1.0+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.16.0+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Collecting thop>=0.1.1 (from ultralytics)\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.5.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.48.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (23.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2023.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Installing collected packages: thop, ultralytics\n",
            "Successfully installed thop-0.1.1.post2209072238 ultralytics-8.1.11\n"
          ]
        }
      ],
      "source": [
        "print (\"stage I; import python modules\")\n",
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DGHffDLpnTmp",
        "outputId": "48b9cf8a-680c-4a43-dfa3-c4969bfc0302"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "need GPU\n",
            "/bin/bash: line 1: invidia-smi: command not found\n"
          ]
        }
      ],
      "source": [
        "print (\"need GPU\")\n",
        "!invidia-smi\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "0fgN0UKmV1Fy"
      },
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "# LOCAL LIBRARY\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Fri Jan  5 10:19:02 2024\n",
        "\n",
        "@author: palm\n",
        "\"\"\"\n",
        "\n",
        "# wokin colab class\n",
        "##########################################\n",
        "##  CARDIAC PATTENS, INC.               ##\n",
        "##                                      ##\n",
        "##  YOLOv8 From Colab                  ##\n",
        "##  p petronelli                        ##\n",
        "##  01/05/24                            ##\n",
        "##                                      ##\n",
        "##  Class to instantiate and work Yolov8\n",
        "##  for echos   DEMO\n",
        "##                                      ##\n",
        "##                                      ##\n",
        "#######(c) Cardiac Patterns, Inc.  #######\n",
        "########2023-2024  All rightes reserved.#######\n",
        "##########################################\n",
        "## change history\n",
        "## ver   date    eng    action\n",
        "## 00   01/05/24  plp    based on working colab\n",
        "## 03   01/24/24plp      added no data inseets\n",
        "## 04   02/01/24  plp    Added Z_Flag clculations\n",
        "##\n",
        "###########################################\n",
        "from ultralytics import SAM\n",
        "from ultralytics import YOLO\n",
        "from ultralytics.utils.plotting import Annotator\n",
        "import numpy as np\n",
        "import datetime\n",
        "#import cv2\n",
        "import os, pdb\n",
        "import pickle as pkl\n",
        "import time\n",
        "###\n",
        "\n",
        "class YOLOV8 :\n",
        "    def __init__(self, ROOT_DIR):\n",
        "        self.VERSION = \"21\"  # included zero data entries Special edition\n",
        "        self.FROM = \"https://docs.ultralytics.com/models/yolov8/\"\n",
        "        self.BibTeX=\"@software {yolov8_ultralytics, url={https://github.comultralygtics/ultrlytics\"\n",
        "        now = datetime.datetime.now()\n",
        "        Stamp = now.strftime (\"%d-%B\")\n",
        "        self.CREATED = Stamp\n",
        "        self.ECHO = False\n",
        "        self.TEST = False\n",
        "        self.YOLO_STATUS = False\n",
        "        self.MODEL = None\n",
        "        self.MODEL_NAME=\"yolov8x.pt\" # stanard\n",
        "        self.W_DIR =\"\" # none\n",
        "        self.ROOT = ROOT_DIR # eerython falls from this\n",
        "        WFP = os.path.join (ROOT_DIR, \"WEIGHTS\")\n",
        "        self.WEIGHTS=WFP\n",
        "        self.yolo_np =np.array([\" \",\" \",0.1,\"\",0.2,0,\"X\"]) # (TAG,L1,C1,L2, C2,Q, X)\n",
        "        self.yolo_np_default = np.array([\" \",\" \",0.1,\"\",0.2,0,\"X\"])\n",
        "        #DATA _STATUS (X)  0=uninitialized, 1= data intitialized (no AI ) 2=Current values (may iclude AI)\n",
        "        #=\n",
        "        self.SHAPE =self.yolo_np.shape\n",
        "        self.STD   =\"undefined\"\n",
        "        self.VID_DIR = self.STD\n",
        "        self.VID_NP  = self.STD\n",
        "        ## for saving results\n",
        "        self.PICKEL_DIR = self.STD\n",
        "        self.LAST_PICKEL_NAME =self.STD\n",
        "        self.YOLO_NP = self.STD   # forml oe\n",
        "        self.LAST_DATA_PICKLE_NAME=self.STD\n",
        "        self.DATA_PKL_DATE= self.STD\n",
        "        self.MISSION=\"special cola edition\"\n",
        "        self.CHANGE_THRESHOLD = 0.4 # dont change unless new lavel is more than this\n",
        "        self.CURRENT_RESULT = [] # hioricl last result\n",
        "\n",
        "\n",
        "    def _config (self):\n",
        "        cfg=\"\\n YOLOV8 class: V_\"+str (self.VERSION)+\"\\n ROOT DIR: \"+str(self.ROOT)\n",
        "        cfg+=\"\\n Sub dir structue: \\n  WEIGHTS (pretrined weights)\\n  W_DIR (weights directory) \\n  MODEL\"\n",
        "        cfg+=\"\\n MODEL: \"+str(self.MODEL_NAME) +\"  model status: \"+str(self.YOLO_STATUS)\n",
        "        cfg+=\"\\n HyperParameters: \"+\"imgsz=1024,show=False, show_labels=False, show_conf=False, save_conf=False,save_frames=False\"\n",
        "        cfg+=\"\\n DATA STATUS (X) VALUES \"+\"(0=uninitialized, 1= data intitialized (no AI ) 2=Current values (may iclude AI))\"\n",
        "        cfg+=\"\\n Created \"+str(self.CREATED)\n",
        "        cfg+=\"\\n AVI DIR: \"+str(self.VID_DIR)\n",
        "        cfg+=\"\\n ECHO: \" +str(self.ECHO)+\"  TEST: \"+str(self.TEST)\n",
        "        cfg+=\"\\n Format of yolo_np: [TAG, Y_LABEL1, Y_CONF1, Y_LABEL2, Y_CONF2, Y_QSCORE,yx]- NEEDS UPDATING\"\n",
        "        cfg+=\"\\n PICKLE STATUS data pickel: \" +str(self.LAST_DATA_PICKLE_NAME)+\" date \"+str(self.DATA_PKL_DATE)\n",
        "        cfg+=\"\\n CYCLE DATA: change threshold: \"+str(self.CHANGE_THRESHOLD)\n",
        "        cfg+=\"\\n Z_flag criteris label GT change threshold\"\n",
        "        return cfg\n",
        "\n",
        "    def _start_model (self):\n",
        "        if self.ECHO: print (\"stating model with model=YOLO(\", self.MODEL)\n",
        "        if self.TEST: pdb.set_trace()\n",
        "        model=YOLO(self.MODEL_NAME)\n",
        "        if self.ECHO: print (\"model=\", type (model))\n",
        "        self.MODEL= model # for later use\n",
        "        self.YOLO_STATUS=True\n",
        "        return True\n",
        "\n",
        "    def _set_model_name (self, MODEL_NAME):\n",
        "        if self.ECHO: print (\"changing model namde from \", self.MODEL, ' to ', MODEL_NAME)\n",
        "        self.MODEL_NAME = MODEL_NAME\n",
        "        return\n",
        "\n",
        "    def _set_TEST(self, VALUE):\n",
        "        if isinstance (VALUE, bool):\n",
        "            self.TEST = VALUE\n",
        "            return\n",
        "        else: print (\"Nota boolean \", VALUE)\n",
        "\n",
        "    def _set_ECHO (self, VALUE):\n",
        "            if isinstance (VALUE, bool):\n",
        "                self.ECHO = VALUE\n",
        "                return\n",
        "            else: print (\"Nota boolean \", VALUE)\n",
        "            return\n",
        "\n",
        "    def _get_empty_YOLOv8_np(self):\n",
        "        if self.ECHO: print (\"creting empty yyolv8\")\n",
        "        yolo_np = self.yolo_np # this is sthe efault\n",
        "        return yolo_np\n",
        "\n",
        "\n",
        "    def _create_np(self):\n",
        "        if self.TEST: pdb.set_trace()\n",
        "        TAG=\"ABC345\"\n",
        "        DIAG1=\"Mild\"\n",
        "        CONF1= 0.0\n",
        "        DIAG2=\"Severe\"\n",
        "        CONF2=0.0\n",
        "        Q=0\n",
        "        YX=\"\"\n",
        "        TPL = (TAG, DIAG1,CONF1,DIAG2,CONF2,Q,YX)\n",
        "        self.yolo_np =  np.array([TPL])  # null first element\n",
        "        return True\n",
        "\n",
        "    def _set_vid_dir (self, VID_DIR):\n",
        "        if self.TEST: pdb.set_trace()\n",
        "        if not os.path.exists (VID_DIR):\n",
        "            print (VID_DIR, \" does not eist\")\n",
        "            return False\n",
        "        self.VID_DIR = VID_DIR\n",
        "        return True\n",
        "\n",
        "    def _set_threshold (self, NEW_THRESHOLD):\n",
        "        if self.ECHO: print (\"setting new threaholcd from\", self.CHANGE_THRESHOLD, \" to \", NEW_THRESHOLD)\n",
        "        NT=NEW_THRESHOLD\n",
        "        if not isinstance(NT, float):\n",
        "            print (\"must be float: \", NT)\n",
        "            return\n",
        "        self.CHANGE_THRESHOLD=NT\n",
        "        if self.ECHO: print (\" change threshold set to \", NT)\n",
        "        return\n",
        "\n",
        "    def _get_RESULT (self):\n",
        "        return self.CURRENT_RESULT\n",
        "\n",
        "\n",
        "    def _set_vid_class(self, VID_CLASS):\n",
        "        if self.ECHO: print (\"setting vid clas in Yolo class\")\n",
        "        self.VID_CLASS = V=VID_CLASS\n",
        "        #vid_np = V._get_vid_,np(self.VID_DIR)\n",
        "        _,vid_np = V._get_vid_np()\n",
        "        self.VID_NP = vid_np\n",
        "        return\n",
        "\n",
        "    def _get_yolo_np (self):\n",
        "        if self.TEST:pdb.set_trace()\n",
        "        return self.yolo_np, True\n",
        "\n",
        "    def _one_row (self, TAG,L1,C1,L2,C2,Q,X):\n",
        "        #format  [TAG, Y_LABEL1, Y_CONF1, Y_LABEL2, Y_CONF2, Y_QSCORE,yx]\"\n",
        "        #print (\"ONE ROW not implemented\")\n",
        "        if self.TEST:pdb.set_trace()\n",
        "        one = np.array([TAG, L1,C1,L2, C2, Q, X])\n",
        "        return one\n",
        "\n",
        "    def _exists(self, TAG):\n",
        "        if self.TEST: pdb.set_trace()\n",
        "        ntags = len (self.yolo_np)\n",
        "        if ntags ==0: return False\n",
        "        else:\n",
        "            if ntags==1: return False\n",
        "            for row in range (ntags-1):\n",
        "                one_row =self.yolo_np[row]\n",
        "                tg= one_row[0]\n",
        "                if tg==TAG:\n",
        "                    return True\n",
        "        return False\n",
        "\n",
        "    def _get_tag_values (self, TAG):\n",
        "        if self.TEST: pdb.set_trace()\n",
        "        ntags = len (self.yolo_np)\n",
        "        if ntags ==0: return False\n",
        "        else:\n",
        "            for row in range (ntags-1):\n",
        "                one_row =self.yolo_np[row]\n",
        "                tg= one_row[0]\n",
        "                if tg==TAG:\n",
        "                    return True, one_row\n",
        "            return False, np.empty (self.SHAPE)\n",
        "\n",
        "    def _add_tag(self,TAG  ):\n",
        "        return self._do_one_tag(TAG) # reurns OK + yolo_np\n",
        "\n",
        "    # return values from Yolo_np\n",
        "    def _Get_YOLO_Values (self,TAG):\n",
        "        print (\"retrieving \", TAG, \"from yolo_np\")\n",
        "        OK,YOLO_ROW = self._get_tag_values (TAG)# reurns one row\n",
        "        if not OK:\n",
        "            if self.ECHO :print(\"some error in _Get_YOLO_Values\")\n",
        "            if self. TEST: pdb.set_trace()\n",
        "            return False , ()   # tmpey\n",
        "\n",
        "        #format  [TAG, Y_LABEL1, Y_CONF1, Y_LABEL2, Y_CONF2, Y_QSCORE,yx]\"\n",
        "        TAG, Y_LABEL1, Y_CONF1, Y_LABEL2, Y_CONF2, Y_QSCORE,yx =YOLO_ROW # up=npck\n",
        "        TPL=(TAG,Y_LABEL1, Y_CONF1, Y_LABEL2, Y_CONF2, Y_QSCORE, yx)\n",
        "        if self.ECHO: print (\"YPL VALUES: \",TPL)\n",
        "        return True, TPL\n",
        "\n",
        "    def _do_one_tag(self,TAG):\n",
        "        if self.TEST: pdb.set_trace()\n",
        "        #get vid path from TAG\n",
        "        OK,TUPL=self.VID_CLASS._get_tag_values (TAG)\n",
        "        if not OK:\n",
        "            print (\"cant find \",  TAG)\n",
        "            return False\n",
        "        TagNo,TAG,VID_NAME, VID_FULL_PATH, X = TUPL\n",
        "        #TAG_FP = os.path.join (self.AVI_DIR, TAG)\n",
        "        VID_FP = VID_FULL_PATH\n",
        "        if not os.path.exists (VID_FP):\n",
        "            print (VID_FP, \"not exists\")\n",
        "            return False\n",
        "        if not self.YOLO_STATUS:\n",
        "            print  (\"model not initilizd ERROR\")\n",
        "            return False\n",
        "\n",
        "        model=self.MODEL\n",
        "        Xresult=model.predict (VID_FP,save=False, imgsz=1024,show=False, show_labels=False, show_conf=False, save_conf=False,save_frames=False)  # seve frames!\n",
        "        nR= len(Xresult)\n",
        "        self.CURRENT_RESULT=Xresult # for history\n",
        "        #find highest conf\n",
        "        # conf = SUM(occurances * conf)/occurances\n",
        "        # from   Imgsz for predicg is only one numbr from:https://stackoverflow.com/questions/76739392/yolov8-imgsz-in-predict\n",
        "        SAVE_NAME = str(TAG)+\"_\"+\"Result\"+str(self.VERSION) #each sve ha TAG\n",
        "        self._pickel_result ( Xresult, SAVE_NAME, MODE=\"save\")\n",
        "\n",
        "        TPLS=()\n",
        "        SCORE_DICT=self._unpack_results(Xresult)\n",
        "        #TPL = (TAG,CLASS1,CONF1, CLASS2,CONF2, NAME,NAME2,N_FRAME, BX,PROBS)\n",
        "        SD=SCORE_DICT\n",
        "        #dict INCLUDES results!\n",
        "        # TPL = (TAG,CLASS1,CONF1, CLASS2,CONF2, NAME,NAME2,N_FRAME, BX,PROBS) # omit result\n",
        "        # add to np\n",
        "        #self.yolo_np\n",
        "        # make one row\n",
        "        # add to existing\n",
        "        #unpack SD\n",
        "        # for ONE TAG\n",
        "        L1,C1, L2, C2 = self._calculate_w_ave (SD)  # SD are the totls or all frmes in the VID\n",
        "        #one reult FOR EACH frame !\n",
        "        Q=0\n",
        "        X=\"\"\n",
        "        one_np = self._one_row(TAG, L1, C1, L2, C2, Q, X)  # ON ROE\n",
        "        if self.TEST:pdb.set_trace()\n",
        "        #yolo_np=np.vstack([[self.yolo_np],[one_np]])\n",
        "        X=self.yolo_np\n",
        "        Y=one_np\n",
        "        yolo_np=np.vstack([X,Y])\n",
        "\n",
        "        ''' skip\n",
        "        add = np.array ([])\n",
        "        for X in Xresult:\n",
        "            conf1=X.conf\n",
        "            lbl1 = X.label\n",
        "            TPL=(lbl1,conf1)\n",
        "            L1=\"\"\n",
        "            C1=0.0\n",
        "            L2=\"\"\n",
        "            C2=0.0\n",
        "            Q=0\n",
        "            X=\"X\"\n",
        "            one_np = self._one_row(TAG, L1, C1, L2, C2, Q, X)\n",
        "            yolo_np=np.vstack(self.yolo_np,one_np)\n",
        "            '''\n",
        "        if self.ECHO:print (\"Done with video: \", TAG)\n",
        "\n",
        "        if self.TEST:pdb.set_trace()\n",
        "        self.YOLO_NP= yolo_np\n",
        "        self.yolo_np = yolo_np\n",
        "        return True\n",
        "\n",
        "    def _set_PICKEL_DIR (self, PD):\n",
        "        if not os.path.exists (PD):\n",
        "            print (PD, \" doesnt exist\")\n",
        "            pdb.set_trace()\n",
        "        self.PICKEL_DIR=PD\n",
        "        return\n",
        "    ## save results in a pickel for later analysis\n",
        "    def _pickel_result (self, Result, PICKLE_NAME, MODE):\n",
        "        if self.PICKEL_DIR == self.STD:\n",
        "            print (\" pickel dir NOT initialized, pleae call _set_PICKEL_dir\")\n",
        "            return\n",
        "        if MODE==\"save\":\n",
        "            now = datetime.datetime.now()\n",
        "            Stamp = now.strftime (\"%d-%B\")\n",
        "            PD= self.PICKEL_DIR\n",
        "            RESULT_PKL_NAME = PICKLE_NAME+\"_\"+str(Stamp)+\".pkl\"\n",
        "            self.LAST_PICKLE_NAME = RESULT_PKL_NAME\n",
        "            # check paths\n",
        "            OK = True\n",
        "            FPP= os.path.join (self.PICKEL_DIR, RESULT_PKL_NAME)\n",
        "            if self.ECHO: print (\"REsult pickel saved at\", FPP)\n",
        "            try:\n",
        "                pkl.dump (Result, open (FPP, \"wb\"), protocol=pkl.HIGHEST_PROTOCOL)\n",
        "                '''\n",
        "                self.LAST_PICKEL_NAME = SAVE_NAME # only save if valid\n",
        "                self.LAST_PICKEL_PATH = FPP\n",
        "                self.VIDEO_STATUS = True\n",
        "                self.VIDEO_NP_STATUS=True  # bogh re gtrue\n",
        "                '''\n",
        "            except Exception as EX:\n",
        "                print (\"Exce[topm \", EX)\n",
        "                pdb.set_trace()\n",
        "                OK=False\n",
        "            return\n",
        "        if MODE==\"load\":\n",
        "            #print (\"not iplemented\")\n",
        "        #if MODE==\"load\":\n",
        "            try:\n",
        "                if not os.path.isfile (self.PICKEL_DIR):\n",
        "                    print (self.PICKEL_DIR, \" not a valid pth to file - call _set_pickl_dir\")\n",
        "                    return False, ()\n",
        "                RESTORE_PICKEL_NAME=PICKLE_NAME\n",
        "                #FULL_PATH = os.path.join (self.LAST_CSV_FILE_PATH, self.LAST_PICKEL_NAME)\n",
        "                #fileobject =  open (FULL_PATH, \"rb\")\n",
        "                FULL_PICKLE_PATH =os.path.join (self.PICLEL_DIR, RESTORE_PICKEL_NAME)\n",
        "                if self.ECHO:print (\"retrieving pickle \", FULL_PICKLE_PATH)\n",
        "                fileobject =  open (FULL_PICKLE_PATH , \"rb\") # NOTE FULL PATH\n",
        "                #triage_array=pkl.load(fileobject)\n",
        "                Result   = pkl.load(fileobject)  # must be same name as saved# must be same as saved\n",
        "                fileobject.close ()\n",
        "                #self.VIDEO_NP = VIDEO_NP# save\n",
        "                #self.video_np = VIDEO_NP\n",
        "                timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
        "                self.PICKLE_LOAD_TIME = timestr\n",
        "                #self.Triage_np = self.triage_array\n",
        "                #self.video_np = VIDEO_NP # as loaded\n",
        "               # self.VIDEO_NP = video_np\n",
        "                #return True,triage_array\n",
        "                #self.VIDEO_NP_STATUS= True # usable\n",
        "               #self.VIDEO_STATUS = True\n",
        "                self.LAST_PICKEL_NAME=RESTORE_PICKEL_NAME\n",
        "                return True, Result  # not self as loaded\n",
        "            except Exception as EX:\n",
        "               print (\"Error loading \",FULL_PICKLE_PATH ,\"exception: \", EX)\n",
        "               return False,() # empty ara\n",
        "\n",
        "            return OK, Result\n",
        "\n",
        "    def _load_PKL_results(self, PICKLE_NAME):\n",
        "        Result=None  # at loagd\n",
        "        XResult =self. _pickel_result (Result, PICKLE_NAME, MODE=\"load\")\n",
        "\n",
        "        return XResult\n",
        "\n",
        "    def _test_Xresult (self, Xresult):\n",
        "        for result in Xresult:\n",
        "           SD=self._unpack_results (result)\n",
        "           #TPL = (TAG,CLASS1,CONF1, CLASS2,CONF2, NAME,NAME2,N_FRAME, BX,PROBS,result) # mighgt all be ZEORO ddin a;; result\n",
        "         # HERE\n",
        "           TAG=\"FE!F5\"\n",
        "           LABEL1=\"Mild\"\n",
        "           CONF1= 0.8\n",
        "           LABEL2=\"Severe\"\n",
        "           CONF2= 0.\n",
        "           Q=0\n",
        "           X=\"expansion\"\n",
        "           SPL = (TAG, LABEL1, CONF1, LABEL2, CONF2,Q, X)\n",
        "        return SPL\n",
        "\n",
        "    def _calculate_w_ave (self,SD):\n",
        "        nrow = len (SD)\n",
        "        # sum by label\n",
        "        ST={}  # empty dit\n",
        "        LD=cm_plot_labels = [\"Endocarditis\",\"Mild\",\"Non-Visible\",\"Normal\",\"Prosthetic\",\"Severe\"]\n",
        "        # # TPL = (TAG,CLASS1,CONF1, CLASS2,CONF2, NAME,NAME2,N_FRAME, BX,PROBS) # omit result\n",
        "        for i in range (len(LD)):  # initialize\n",
        "            ST[LD[[1]]]=0\n",
        "        ALLCONF=0\n",
        "        for row in range (nrow-1):\n",
        "            Class1=row[1]\n",
        "            conf1 = row[2]\n",
        "            NAME1=row[5]\n",
        "            x=ST[NAME1]\n",
        "            nx = x + conf1\n",
        "            ST[NAME1]=nx  # new x\n",
        "            ALLCONF+=conf1\n",
        "        # normalize\n",
        "        if ALLCONF ==0:\n",
        "          print (\"zero total, exiting\")\n",
        "          LABEL=LABEL2=\"UNKWN\"\n",
        "          CONF= CONF2=0.0\n",
        "          return LABEL, CONF, LABEL2,CONF2\n",
        "\n",
        "        for i in len(ST):\n",
        "            This= ST[LD[i]]\n",
        "            newthis = This/ALLCONF  # normalized\n",
        "            ST[LD[i]]=newthis\n",
        "        print (ST)\n",
        "        MAX = max(ST, key=ST.get)\n",
        "        key=ST.get(max(ST, key=ST.get))\n",
        "        CONF = ST.value[key]\n",
        "        LABEL = LD[key]\n",
        "        LABEL2=\"\"\n",
        "        CONF2=0\n",
        "\n",
        "        return LABEL, CONF, LABEL2,CONF2\n",
        "\n",
        "\n",
        "    def _get_model_arch (self):\n",
        "        if not self.YOLO_STATUS :\n",
        "            print (\"Model NOT initialized\")\n",
        "            return \"uninicialized\"\n",
        "        return str(self.MODEL)\n",
        "\n",
        "    def PrepImage (self, IMMAGE_NAME, IMAGE_DIR):\n",
        "        #make larger\n",
        "\n",
        "        print (\"prep Iag NOT Implemented\")\n",
        "        if self.TEST:pdb.set_trace()\n",
        "        return\n",
        "\n",
        "    def _load_yolo (self, MODEL_PT , WEIGHTS_FULL_PATH):\n",
        "        if self.TEST: pdb.set_trace()\n",
        "        OK=True\n",
        "        MODELS = (\"yolov8x.pt\", \"yolov8m.pt\", \"yolov8l.pt\", \"yolov8n.pt\", \"yolov8n.pt\") # just the size\n",
        "        if not MODEL_PT in MODELS :\n",
        "            print (\" Unrcognized YOLO Model : \", MODEL_PT)\n",
        "            OK = False\n",
        "        WFPP = WEIGHTS_FULL_PATH\n",
        "        model=YOLO(MODEL_PT)\n",
        "        self.MODEL_NAME = MODEL_PT  # pretrine model\n",
        "\n",
        "\n",
        "        if not  os.path.exists (WFPP):\n",
        "            print (\"weights not a path:\", WFPP)\n",
        "            OK=False\n",
        "        model = YOLO (WFPP)  # Normally 'yolovx.pt  # add weighgts\n",
        "        self.YOLO_STATUS = True # can use the model\n",
        "        self.MODEL = model\n",
        "        self.WEIGHTS=WFPP  # note overrides automatic\n",
        "\n",
        "        return OK,model\n",
        "\n",
        "   # def Load_Pretrained (self, PRE_TRAIN):\n",
        "    #   # load retraine into model\n",
        "    # MOVED TO COLAB\n",
        "    # for v15 LOCAL LIB USES TK directly\n",
        "    # Z_flag critgeria.  Label must show > change confidence\n",
        "    def _unpack_results (self, RESULTS):\n",
        "        global TK\n",
        "        if self.TEST: pdb.set_trace()\n",
        "        if self.ECHO:\n",
        "            L_OUT = True\n",
        "            TK.L (\"_unpack_results\", \"X\")\n",
        "        else :L_OUT=False\n",
        "        SCORE_DICT =SD={}   #indexed y class\n",
        "        N_FRAME=0 # identify this frame\n",
        "        XN=\"Undef\"\n",
        "        KEEP=\"UNDEF\"  # label to keep\n",
        "        for result in RESULTS:\n",
        "            # set defaulgts\n",
        "            CONF2=0\n",
        "            NAME2=XN\n",
        "            CLASS2=XN\n",
        "            CLASS1=XN\n",
        "            CONF1=0\n",
        "            NAME1=XN\n",
        "            ANY=0\n",
        "            Z_Flag = 0  #  Z_Flag designates degree to which the graphic can be eliminatd\n",
        "            #              0 = Not eligible\n",
        "            #              1-5  higher is more eligibl\n",
        "            #XN=\"Undef\"\n",
        "            BX=result.boxes.xywhn  # box with xywh format but normalized, (N, 4)\n",
        "            if len(BX)==0: BX=0\n",
        "            else:\n",
        "                ANY+=1\n",
        "                BX=BX.tolist()\n",
        "\n",
        "            CONF=result.boxes.conf   # confidence score, (N, 1)\n",
        "            if len(CONF)==0: CONF1=0\n",
        "            else:\n",
        "                ANY+=1\n",
        "                nconf=len(CONF)\n",
        "                #CONF=CONF.item()\n",
        "                if nconf==1:\n",
        "                    CONF1=CONF.item()\n",
        "                    CONF2=0\n",
        "                else:\n",
        "                    CONF=CONF.tolist()\n",
        "                    CONF2=CONF[1]  # HERE\n",
        "                    CONF1=CONF[0]   # just the first\n",
        "\n",
        "\n",
        "            CLASS=result.boxes.cls    # cls, (N, 1)\n",
        "            if len(CLASS)==0:CLASS1=XN\n",
        "            else:\n",
        "                ANY+=1\n",
        "                if len (CLASS )==1:\n",
        "                    CLASS1=CLASS.item()\n",
        "                    NAME1 =result.names[CLASS1]\n",
        "                else:\n",
        "                    CLASS=CLASS.tolist()\n",
        "                    if self.TEST:pdb.set_trace()\n",
        "                    #print (\"picking first class\")\n",
        "                    NAME1 = result.names [CLASS[0]]#jut th highest\n",
        "                    R=result\n",
        "                    nclass=len(CLASS)\n",
        "                    #print (R.names[int(CLASS[0])])# R.names[int(CLASS[1])])\n",
        "                    #print (CONF[0], CONF[1])\n",
        "                    rec=\"For \"+str(R.names[int(CLASS[0])])+ \" conf: \"+str(CONF[0])+ \"/\"+str(CONF[1])\n",
        "                    print (rec) # put this in TRACK\n",
        "                    CLASS1= CLASS[0]  # keep the first\n",
        "                    if nclass>1:\n",
        "                        CLASS2=CLASS[1]\n",
        "                        NAME2=result.names [CLASS[1]]\n",
        "                        print (R.names[int(CLASS[1])])\n",
        "                    else:\n",
        "                        CLASS2=XN\n",
        "                        NAME2=XN\n",
        "\n",
        "\n",
        "\n",
        "            PROBS=result.probs     # cls prob, (num_class, )\n",
        "            if PROBS==None: PROBS = 0\n",
        "            else:\n",
        "                ANY+=1\n",
        "                PROBS=PROBS.tolist()\n",
        "\n",
        "            if ANY==0:\n",
        "                    # didnt find any\n",
        "                    if L_OUT: print (\"couldnt find any for \", N_FRAME, \" keeping: \",  KEEP)\n",
        "                    N_FRAME+=1\n",
        "                    continue\n",
        "            else:\n",
        "                TAG=self._tag_from_path(result.path)\n",
        "                #TPL = (TAG,CLASS1,CONF1, CLASS2,CONF2, NAME,NAME2,N_FRAME, BX,PROBS,result) # mighgt all be ZEORO ddin a;; result\n",
        "                ###################Z_FLAG EVALUATION ##\n",
        "                R_CHANGE = 0 # no label chang\n",
        "                if L_OUT:\n",
        "                    if KEEP!= NAME1:\n",
        "                        if CONF1<self.CHANGE_THRESHOLD:\n",
        "                            arg=\"Keeping laael, \"+str(CONF1)+ \" less than \"+str(self.CHANGE_THRESHOLD)\n",
        "                            TK.T(arg)\n",
        "                        else:\n",
        "                            arg=\"changing KEEP from: \"+str(KEEP)+\" to \" +str(NAME1)+\" with conf: \"+str(CONF1)\n",
        "                            print (arg)\n",
        "                            TK.T(arg)\n",
        "                            KEEP=NAME1\n",
        "                            R_CHANGE = 1 # recent change\n",
        "                    STPL = (TAG,CLASS1,CONF1, CLASS2,CONF2, NAME1,NAME2,N_FRAME)\n",
        "                    print (STPL)\n",
        "                    TK.T(str(STPL))\n",
        "                # set up call to Z_Flag desitnator\n",
        "                GND_TRUTH = \"undef\" # from Sharol array\n",
        "                AI_label1=NAME1\n",
        "                AI_label2=NAME2\n",
        "                AI_conf1 = CONF1\n",
        "                AI_conf2 = CONF2\n",
        "                Z_TUPL = (TAG, N_FRAME, GND_TRUTH, AI_label1, AI_conf1, AI_label2, AI_conf2,R_CHANGE )\n",
        "                Z_FLAG = self._set_Z_Flag(Z_TUPL)\n",
        "\n",
        "                TPL = (TAG,CLASS1,CONF1, CLASS2,CONF2, NAME1,NAME2,N_FRAME, BX,PROBS,Z_Flag) # omit result\n",
        "                SD[N_FRAME]=TPL  # add to dict.  KEY is FRAME #\n",
        "                N_FRAME+=1\n",
        "                '''\n",
        "                if L_OUT:\n",
        "                    if KEEP!= NAME1:\n",
        "                        if CONF1<self.CHANGE_THRESHOLD:\n",
        "                            arg=\"Keeping laael, \"+str(CONF1)+ \" less than \"+str(self.CHANGE_THRESHOLD)\n",
        "                            TK.T(arg)\n",
        "                        else:\n",
        "                            arg=\"changing KEEP from: \"+str(KEEP)+\" to \" +str(NAME1)+\" with conf: \"+str(CONF1)\n",
        "                            print (arg)\n",
        "                            TK.T(arg)\n",
        "                            KEEP=NAME1\n",
        "                    STPL = (TAG,CLASS1,CONF1, CLASS2,CONF2, NAME1,NAME2,N_FRAME)\n",
        "                    print (STPL)\n",
        "                    TK.T(str(STPL))\n",
        "                ''' #Moved up\n",
        "\n",
        "        nCONF=3\n",
        "        print (\"number of frames : \", N_FRAME, \" for this video\")\n",
        "        if self.TEST: pdb.set_trace()\n",
        "        # AD RESULT TO DICT\n",
        "        return SD\n",
        "    # Format of Z_tuPL: TAG,N_FRAME,GND_TRUTH, AI_label1, AI_conf1, AI_label2,AI_conf2\n",
        "    def _set_Z_Flag (self, Z_TUPL):\n",
        "        # unpack ZTUPL\n",
        "        LD=cm_plot_labels = [\"Endocarditis\",\"Mild\",\"Non-Visible\",\"Normal\",\"Prosthetic\",\"Severe\"]\n",
        "        TAG,N_FRAME,GND_TRUTH, AI_label1, AI_conf1, AI_label2,AI_conf2, R_CHANGE = Z_TUPL\n",
        "        # check for z labels\n",
        "        TK.L (\"_set_Z_flag\", str(TAG))\n",
        "        Z_Flag =0\n",
        "        if AI_label1 == LD[2] :# non viible\n",
        "            arg=\"found \"+str(LD[2]) +\" at \"+str(TAG)+ \" and frame \"+str( N_FRAME)\n",
        "            TK.T(arg)\n",
        "            if self.ECHO: print   (arg)\n",
        "            Z_Flag = 3\n",
        "            return Z_Flag\n",
        "        if AI_label1 == \"(no detections)\":\n",
        "            arg=\"found \"+\" No detections\" +\" at \"+str(TAG)+ \" and frame \"+str( N_FRAME)\n",
        "            TK.T(arg)\n",
        "            if self.ECHO: print   (arg)\n",
        "            Z_Flag = 2\n",
        "            return Z_Flag\n",
        "        if GND_TRUTH ==\"OMIT\":\n",
        "            return Z_Flag # no action\n",
        "        if R_CHANGE ==1:  # REcent change\n",
        "            arg=\"found R_change\"\n",
        "            TK.T(arg)\n",
        "            return Z_Flag  # no action\n",
        "        arg= \"No action ncecsary for  TAG\"+str(TAG)+  \" and Frame: \"+str(N_FRAME)\n",
        "        TK.T(arg)\n",
        "        if self.ECHO: print (arg)\n",
        "        return Z_Flag\n",
        "\n",
        "\n",
        "\n",
        "    def _tag_from_path(self, PATH) :\n",
        "        if self.ECHO: print (\"\")\n",
        "        P=PATH\n",
        "        dot = P.find(\".\")\n",
        "        TAG = P[dot-5:dot]\n",
        "        return TAG\n",
        "\n",
        "\n",
        "         ### updatged form colab\n",
        "         ##TPL = (TAG,CLASS1,CONF1, CLASS2,CONF2, NAME,NAME2,N_FRAME, BX,PROBS,result)\n",
        "\n",
        "    def _calculate_w_ave (self,SD):\n",
        "        LTEST=False\n",
        "        nrow = len (SD)\n",
        "        # sum by label\n",
        "        ST={}  # empty dict for STATISTICS\n",
        "        LD=cm_plot_labels = [\"Endocarditis\",\"Mild\",\"Non-Visible\",\"Normal\",\"Prosthetic\",\"Severe\"]\n",
        "        # # TPL = (TAG,CLASS1,CONF1, CLASS2,CONF2, NAME,NAME2,N_FRAME, BX,PROBS) # omit result\n",
        "        for i in range (len(LD)):  # initialize\n",
        "            IND=LD[i]\n",
        "            ST[IND]=0\n",
        "        #pdb.set_trace()\n",
        "        ALLCONF=0\n",
        "        if LTEST: pdb.set_trace()\n",
        "        for Xrow in  range (nrow-1):# ffix\n",
        "          # check if key exists\n",
        "            if not Xrow in SD:continue\n",
        "            row=SD[Xrow]\n",
        "            TAG=row[0]\n",
        "            Class1=row[1]\n",
        "            conf1 = row[2]\n",
        "            NAME1=row[5]\n",
        "            x=ST[NAME1]\n",
        "            nx = x + conf1\n",
        "            ST[NAME1]=nx  # new x\n",
        "            ALLCONF+=conf1\n",
        "        # normalize\n",
        "        if self.ECHO: print (\"Total cnf is \", ALLCONF)\n",
        "        for i in range(len(ST)):\n",
        "            This= ST[LD[i]]\n",
        "            if ALLCONF==0:\n",
        "              print (\"Avoiding div zero set  ALLCONF =1\")\n",
        "              ALLCONF=1\n",
        "            newthis = This/ALLCONF  # normalized\n",
        "            ST[LD[i]]=newthis\n",
        "\n",
        "        V,K =max(ST.items(), key=lambda k: k[1])\n",
        "        #pdb.set_trace()\n",
        "        CONF = K  #ST.value[key]\n",
        "        LABEL = V  #LD[key]\n",
        "        #pdb.set_trace()\n",
        "        LB=sorted (ST, key = ST.get)[-2]\n",
        "\n",
        "        CONF2=ST[LB]\n",
        "        LABEL2=LB\n",
        "        #CONF2=0\n",
        "\n",
        "        return LABEL, CONF, LABEL2,CONF2\n",
        "\n",
        "\n",
        "\n",
        "    def Predict1 (self, IMAGE, IMAGE_DIR):\n",
        "        IFP=os.path.join (IMAGE_DIR, IMAGE)\n",
        "        if not os.path.isfile(IFP):\n",
        "            print (IFP, \"not an exiting  fiels\")\n",
        "            return False\n",
        "        if not self.YOLO_STATUS :\n",
        "            print (\"Model NOT INITIALIZED\")\n",
        "            return False\n",
        "\n",
        "        ## do prediction\n",
        "        model = self.MODEL\n",
        "        results = model(IFP)\n",
        "\n",
        "        return\n",
        "\n",
        "    def PredictALl (self, SOURCE_DIR):\n",
        "        S=SOURCE_DIR\n",
        "        model=self.MODEL\n",
        "        OK=True\n",
        "        if not os.path.exists (S):\n",
        "            print (S, \" doesnt exist\")\n",
        "            OK = False\n",
        "        nS = len (os.listdir(S))\n",
        "        print (nS, \"images found\")\n",
        "        results = R=model(S)\n",
        "        nR=len(R)\n",
        "        print (nR, \" rsutulst\")\n",
        "        return OK, R\n",
        "\n",
        "    def PredictVID(self,VID_DIR):\n",
        "        V=VID_DIR\n",
        "        OK=True\n",
        "        model = self.MODEL\n",
        "        if not os.path.exists (V):\n",
        "            print (V, \" does not xist\")\n",
        "            OK = False\n",
        "            return OK\n",
        "        results=R=model (V)\n",
        "        nR=len (R)\n",
        "        print (nR, \" reults found\")\n",
        "        return OK, R\n",
        "\n",
        "    def _set_W_dir (self,TEMP_DIR):\n",
        "        T=TEMP_DIR\n",
        "        print (\"using \", T, \" as working  frame dir\")\n",
        "\n",
        "        if not os.path.exists (T):\n",
        "           print (T, \" does not exist\")\n",
        "           return False\n",
        "        self.W__DIR =T\n",
        "        return True\n",
        "\n",
        "    def _DUMP_R (self, RESULTS):\n",
        "          R=RESULTS\n",
        "          LABELS=[]\n",
        "          LBEL_TXT=\"\"\n",
        "          boxes = R.boxes\n",
        "          for box in boxes:\n",
        "            c = box.cls\n",
        "            lbl=R.names[int(c)]\n",
        "            if lbl !=\"\":\n",
        "              LABEL=lbl\n",
        "              LABELS.append(lbl)\n",
        "              LBEL_TXT+=str(lbl)+\", \"\n",
        "          rLBLS=LBEL_TXT\n",
        "        # exgacg fields\n",
        "          rIM=str(R.orig_img)+\"\\n\"  #raw ddata , skip\n",
        "          rK=str(R._keys)+\"\\n\"\n",
        "          rB=str(R.boxes)+\"\\n\"\n",
        "          rKP=str(R.keypoints)+\"\\n\"\n",
        "          rMK=str(R.masks)+\"\\n\"\n",
        "          rN =str(R.names)+\"\\n\"\n",
        "          rO=str(R.obb)+\"\\n\"\n",
        "          rPBS=str(R.probs)+\"\\n\"\n",
        "          rSD=str(R.save_dir)+\"\\n\"\n",
        "\n",
        "\n",
        "          conf=R.boxes.conf\n",
        "          if len(conf)==0: # cantmake to a scalar\n",
        "              xconf=0\n",
        "          else:\n",
        "              xconf=conf.item() # get actual value of this tensor\n",
        "          #confidence = conf.item()\n",
        "          line2=\"\\n\"\n",
        "          conf=R.boxes.conf\n",
        "          #confidence = conf.item()\n",
        "          confidence = conf # dont conver to alar if im ==\n",
        "          rCF=\"conf=\"+str(conf)+\"\\n\"\n",
        "\n",
        "          if len(conf)==0: # cantmake to a scalar\n",
        "             xconf=0\n",
        "          else:\n",
        "              xconf=conf.item() # get actual value of this tensor\n",
        "\n",
        "          rCF=\"conf=\"+str(conf)+\"\\n\"\n",
        "          # FN = file name\n",
        "          line2+=\"LABEL:\"+str(LABEL)+\" conf: \"+str (xconf)\n",
        "          if self.ECHO : print (line2)\n",
        "\n",
        "\n",
        "\n",
        "          SEP=\"===\"\n",
        "          line=\"\\n\"+SEP+rK+rB+rKP+rMK+rO+rPBS+rN+rLBLS+\"\\n\"+rSD+rCF+line2+SEP\n",
        "\n",
        "          return LABEL, xconf, line\n",
        "    # pickles a data area in the pickel dir\n",
        "    def _pickel_YOLO_NP (self, DATA, PICKLE_NAME, MODE):\n",
        "     if self.PICKEL_DIR == self.STD:\n",
        "         print (\" pickel dir NOT initialized, pleae call _set_PICKEL_dir\")\n",
        "         return\n",
        "     if MODE==\"save\":\n",
        "         now = datetime.datetime.now()\n",
        "         Stamp = now.strftime (\"%d-%B\")\n",
        "         PD= self.PICKEL_DIR\n",
        "         DATA_PKL_NAME = PICKLE_NAME+\"_\"+str(Stamp)+\".pkl\"\n",
        "         self.LAST_DATA_PICKLE_NAME = DATA_PKL_NAME\n",
        "         # check paths\n",
        "         OK = True\n",
        "         FPD= os.path.join (self.PICKEL_DIR, DATA_PKL_NAME)\n",
        "         if self.ECHO: print (\"REsult pickel saved at\", FPD)\n",
        "         DATA=self.YOLO_NP\n",
        "         if self.ECHO:print (\"savind YOLO_NP\")\n",
        "         try:\n",
        "             pkl.dump (DATA, open (FPD, \"wb\"), protocol=pkl.HIGHEST_PROTOCOL)\n",
        "             self.DATA_PKL_STATUS = True\n",
        "             self.DATA_PKL_DATE   = Stamp\n",
        "         except Exception as EX:\n",
        "             print (\"Exce[topm \", EX)\n",
        "             pdb.set_trace()\n",
        "             OK=False\n",
        "         return  True\n",
        "     if MODE==\"load\":\n",
        "         #print (\"not iplemented\")\n",
        "     #if MODE==\"load\":\n",
        "         try:\n",
        "             PICK_FP=os.path.join (self.PICKEL_DIR, PICKLE_NAME)\n",
        "             if not os.path.isfile (PICK_FP):\n",
        "                 print (self.PICKEL_DIR, \" not a valid pth to file - call _set_PICKLE_DIR\")\n",
        "                 return False, ()\n",
        "             RESTORE_DATA_NAME=PICKLE_NAME\n",
        "             #FULL_PATH = os.path.join (self.LAST_CSV_FILE_PATH, self.LAST_PICKEL_NAME)\n",
        "             #fileobject =  open (FULL_PATH, \"rb\")\n",
        "             FULL_PICKLE_PATH =os.path.join (self.PICKEL_DIR,  RESTORE_DATA_NAME)\n",
        "             if self.ECHO:print (\"retrieving pickle \", FULL_PICKLE_PATH)\n",
        "             fileobject =  open (FULL_PICKLE_PATH , \"rb\") # NOTE FULL PATH\n",
        "             #triage_array=pkl.load(fileobject)\n",
        "             Data   = pkl.load(fileobject)  # must be same name as saved# must be same as saved\n",
        "             fileobject.close ()\n",
        "             #self.VIDEO_NP = VIDEO_NP# save\n",
        "             #self.video_np = VIDEO_NP\n",
        "             timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
        "             self.DATA_PKL_DATE = timestr\n",
        "             self.YOLO_NP = Data\n",
        "             self.yolo_np = Data\n",
        "             self.DATA_PKL_NAME=PICKLE_NAME\n",
        "             return True, Data  # not self as loaded\n",
        "         except Exception as EX:\n",
        "            print (\"Error loading \",FULL_PICKLE_PATH ,\"exception: \", EX)\n",
        "            return False,() # empty ara\n",
        "\n",
        "         return OK, Data\n",
        "     ##########################3\n",
        "     ## Null data updates (v10)#\n",
        "     ###########################\n",
        "    def _add_data_row (self, TUPL):\n",
        "       if self.TEST: pdb.set_trace()\n",
        "       print (\"NOT IPLEMENTED\")\n",
        "       # adds a ne row o Yolo_NP  with default data\n",
        "       pdb.set_trace()\n",
        "\n",
        "    def _update_row (self, TAG, **kwags):\n",
        "        print (\"updage field in a row\")\n",
        "        pdb.set_trace()\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kPEgteN4cHoe"
      },
      "outputs": [],
      "source": [
        "# from https://stackoverflow.com/questions/73362781/qt-qpa-xcb-could-not-connect-to-display-when-using-yolov4-custom-functions\n",
        "if False:\n",
        "  print (\"create virtual wiindos for colab\")\n",
        "  !apt-get install -y xvfb # Install X Virtual Frame Buffer\n",
        "  import os\n",
        "  os.system('Xvfb :1 -screen 0 1600x1200x16  &')    # create virtual display with size 1600x1200 and 16 bit color. Color can be changed to 24 or 8\n",
        "  os.environ['DISPLAY']=':1.0'    # tell X clients to use our virtual DISPLAY :1.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CGzXQ1Iqo4ga",
        "outputId": "0218f04b-05cc-46ba-9956-deae35cfad64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: Runtime: command not found\n",
            "/bin/bash: line 1: nvidia-smi: command not found\n",
            "Your runtime has 54.8 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ],
      "source": [
        "!Runtime -> Change run time type -> GPU,TPU\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)\n",
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bVqGSdCWUWPM"
      },
      "outputs": [],
      "source": [
        "print (\"Add libraries\")\n",
        "from ultralytics import SAM\n",
        "from ultralytics import YOLO\n",
        "from ultralytics.utils.plotting import Annotator\n",
        "import numpy as np\n",
        "import datetime\n",
        "import cv2\n",
        "import os, pdb\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W1yzBnIYUcEn"
      },
      "outputs": [],
      "source": [
        "print (\"Creating all directories JUST FOR COLAB\")\n",
        "DIRS=(\"MODEL\", \"WEIGHTS\",\"STORE\",'VIDEOS',\"FRAMES\", \"RESULTS\", \"LIBS\", \"TRIAGE\",\"CHECK_POINTS\",\"REPORTS\", \"BLIND_STUDY\")\n",
        "ROOT=os.path.join (\"/content/\")\n",
        "print (\"ROOT IS \", ROOT)\n",
        "def MDIRS (ROOT, TUPL):\n",
        "  for D in TUPL:\n",
        "    fp=os.path.join (ROOT, D)\n",
        "    print (\"creating 1st level dir: from\", ROOT, D)\n",
        "    os.makedirs(fp, exist_ok=True)\n",
        "  print (\"done with dirs\")\n",
        "  return True\n",
        "# call from main?\n",
        "ok= MDIRS (ROOT, DIRS)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eAVGYw8IIpRh"
      },
      "outputs": [],
      "source": [
        "def CHECK_IT (PATH, NAME):\n",
        "  que=\"Upload \"+str(NAME)+ \" to\"+str(PATH)\n",
        "  xx= input (que)\n",
        "  if xx==\"\": return True\n",
        "  print (\"you typed \", xx)\n",
        "  return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3htIcX3SWaTw",
        "outputId": "3ee30502-3d71-40ec-f2c1-6e18aa6bedbc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "migrate code to colab\n",
            "next\n",
            "upload 60+ videos to VIDEOS\n",
            "next\n",
            "next\n",
            "next\n"
          ]
        }
      ],
      "source": [
        "print (\"migrate code to colab\")\n",
        "xx=input (\"upload best.pt to weights then cr\")\n",
        "if xx==\"\": print (\"next\")\n",
        "xx= (\"upload libs to LIBS\")\n",
        "if xx==\"\": print (\"next\")\n",
        "xx=input (\"upload 60+ videos to VIDEOS\")\n",
        "if xx==\"\":print (\"next\")\n",
        "xx=input(\"load libs into LIBS\")\n",
        "if xx==\"\":print (\"next\")\n",
        "xx=input (\"upload 3 (three) to TRIAGE\"+str(\"TRIAGE/CARDIAC_TRIAGE0.220230824-110623.pkl and ALL_MASTER_TRIAGE_071223_v01.csv\"))\n",
        "if xx==\"\": print (\"next\")\n",
        "xx=input (\"upload to STORE: Cardic_Patterns_Video_Lib_02_20240113-143422.pkl\")\n",
        "if xx==\"\": print (\"next\")\n",
        "ok = CHECK_IT (\"/content/BLIND_STUDY/\",\"Blind_Study_consolidation_MASTER_1205223v03.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2u8imav_ZyZP"
      },
      "outputs": [],
      "source": [
        "# HEADER\n",
        "CODE_BASE=\"blind_rpt v262  from 1/18/24\"\n",
        "print (\" HEADER from\" , CODE_BASE)\n",
        "print (\" setCHDIR TO  lib root\")\n",
        "LIB_ROOT=os.path.join (\"/content/LIBS\")\n",
        "NOW=os.getcwd() # whree are we now\n",
        "os.chdir(LIB_ROOT)\n",
        "\n",
        "from CardiacLIB import Report\n",
        "from  CardiacRESLib import RESULT, TAG_FROM_VID, FRAME_NO\n",
        "from CardiacTriage  import PROCESS_TRIAGE\n",
        "from CardiacUtilLIB import CHECK_UP, PATH_UP, PICK_ONE,PICK_ONEX,_TRACK, TAG_FROM_PATH\n",
        "from CardiacGTLIB import F_1\n",
        "from CardiacBlindLIB import BLIND_STUDY\n",
        "from CardiacValues  import cm_plot_labels\n",
        "import time\n",
        "####\n",
        "\n",
        "\n",
        "if not LOCAL_LIB: from CardiacYOLOlib import YOLOV8\n",
        "from CardiacVIDlib  import VIDEO\n",
        "\n",
        "from datetime import date\n",
        "import datetime\n",
        "# update\n",
        "import os, pdb\n",
        "\n",
        "#CONFIGUGION PARAMETER\n",
        "global MARGIN\n",
        "global TK  # for tracking\n",
        "xNOW=os.getcwd() # whree are we now\n",
        "NOW=os.path.join (\"/content\")\n",
        "print ('CHANGED CWD BACK TO', NOW, \"FROM \",xNOW)\n",
        "pdb.set_trace()\n",
        "os.chdir(NOW)\n",
        "##########################################\n",
        "##  CARDIAC PATTERNS,INC.               ##\n",
        "##                                      ##\n",
        "## BLIND Study  REPORT GENRRATOR        ##\n",
        "##\n",
        "##  p petronelli                        ##cm_plot_labels\n",
        "##  11/20/23                            ##\n",
        "##                                      ##\n",
        "##  Contents:                           ##\n",
        "#      uses SCI-KIT LEARN               ##\n",
        "##     uses Read Ground truth from  lib ##\n",
        "##  THis code creates the final summay rpt ##\n",
        "##                                      ##\n",
        "##                                      ##\n",
        "#######(c) Crdiac Patterns     , Inc.   #######\n",
        "########2020-2024  All rightes reserved.#######\n",
        "##########################################\n",
        "##  UPDATES\n",
        "##  Ver   Date   Isseue                        Eng\n",
        "## 38    11/25/23\n",
        "## 40    11/2723    Add summry epotrt generation plp\n",
        "##50     1/6/24   plp  Convert AI from YOLO8\n",
        "## 260   1/17/24  plp  Added pickel save and load\n",
        "##       1/16/24  plp  testing on Colab\n",
        "########################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eHGYCHGa98bN"
      },
      "outputs": [],
      "source": [
        "xx=input (\"unzip vids from VIDEOS.zip at CHECK_POINTS= cr\")\n",
        "if xx==\"\":\n",
        "  #!unzip CHECK_POINTS\\VIDEOS.zip\n",
        "\n",
        "  ZIP_NAME = \"VIDEOS.zip\"\n",
        "  ZIP_PATH = os.path.join (\"/content/CHECK_POINTS\", ZIP_NAME)\n",
        "  ZIP_END_POINT = os.path.join (\"/content/VIDEOS\")\n",
        "  print (\"unzipping from \", ZIP_PATH, \" to \", ZIP_END_POINT)\n",
        "  if not os.path.isfile(ZIP_PATH):\n",
        "    print (ZIP_PATH, \" not a file\")\n",
        "  if not os.path.exists (ZIP_END_POINT):\n",
        "    print (\"not exist \", ZIP_END_POINT)\n",
        "  !unzip /content/CHECK_POINTS/VIDEOS.zip  -d /content/VIDEOS\n",
        "  LISTV=os.listdir(ZIP_END_POINT)\n",
        "  print (\"stored \", len(LISTV), \" videos\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-MAK8KwETbG7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l5_k0YVteAo9"
      },
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Fri Feb  2 14:31:00 2024\n",
        "\n",
        "@author: palm\n",
        "\"\"\"\n",
        "\n",
        "# PART TWO - U T I L I T I E S\n",
        "UTIL_RELEASE= \"2-9-24\"\n",
        "print (\"\\nPart Two U T I L I T I E S\", UTIL_RELEASE, \"\\n\")\n",
        "# fclass = F_1(OPTIONS)\n",
        "# To procress F_1.Load_CSV_Ground_Truth (self, CSV_PATH, CSV_NAME)\n",
        "   # from CP-yolo_detect_and_count-v0115.py\n",
        "def LOAD_TRIAGE_PKL (TRIAGE_MASTER_REPORT_NAME, TRIAGE_MASTER_REPORT_DIR, AVI_PATH):\n",
        "         OK=True\n",
        "         ECHO = True\n",
        "         TEST=False # at v61\n",
        "         if ECHO: print (\" LOAD TRIAGE WITH: \",TRIAGE_MASTER_REPORT_NAME, TRIAGE_MASTER_REPORT_DIR, AVI_PATH)\n",
        "         if TEST: pdb.set_trace()\n",
        "         try:\n",
        "             PTC = PROCESS_TRIAGE(TRIAGE_MASTER_REPORT_NAME, TRIAGE_MASTER_REPORT_DIR, AVI_PATH)\n",
        "\n",
        "             PTC._set_test(False)\n",
        "             PTC._set_ECHO((True))\n",
        "             #HISTORICAL_PATH = PL=os.path.join (\"C:\\\\\",\"DEV4\",\"PROCESS_TRIAG\n",
        "             PL = TRIAGE_MASTER_REPORT_DIR # use current not hisgorical conv\n",
        "             HISTORICAL_PATH =PL\n",
        "             PKL_LIST = os.listdir(PL)\n",
        "             np,pick= PICK_ONEX (PKL_LIST, \"pkl\")\n",
        "\n",
        "             PKL_NAME= \"CARDIAC_TRIAGE0.220230824-110623.pkl\"\n",
        "             if pick == PKL_NAME:\n",
        "                 print (\"OK\")\n",
        "             else:\n",
        "                 xx= input (\"Aare you sure? not stanard\")\n",
        "                 pdb.set_trace()\n",
        "             MODE = \"load\"\n",
        "             PICKEL_NAME =LAST_PICKEL_NAME = PKL_NAME\n",
        "             LAST_PICKEL_PATH = HISTORICAL_PATH  #conv\n",
        "             LAST_PICKEL_PATH= os.path.join (PL)   # must NOt be full pagh\n",
        "             PTC._set_test(False)\n",
        "             #pdb.set_trace()\n",
        "             PTC._set_last_pickel_data (LAST_PICKEL_NAME, LAST_PICKEL_PATH)\n",
        "             OK,TRIAGE_ARRAY_NP = PTC._pickel_(PICKEL_NAME, MODE)\n",
        "         except Exception as EX:\n",
        "             print (\" Exception in Load triage; \", EX)\n",
        "             pdb.set_trace()\n",
        "             OK = False\n",
        "\n",
        "         return OK,PTC\n",
        "\n",
        "def GET_TRIAGE (TRIAGE_DIR,VID_DIR):\n",
        "          # set up irectgories\n",
        "          TRIAGE_MASTER_REPORT_NAME=\"ALL_MASTER_TRIAGE_071223_v01.csv\"\n",
        "          #TRIAGE_MASTER_REPORT_DIR=os.path.join (\"D:\\\\\",\"MASTER_RUN\") # conv\n",
        "          TRIAGE_MASTER_REPORT_DIR=TRIAGE_DIR\n",
        "          #AVI_PATH=os.path.join (\"C:\\\\\",\"AI\")\n",
        "          AVI_PATH= VID_DIR  # conv\n",
        "          OK,PTC= LOAD_TRIAGE_PKL (TRIAGE_MASTER_REPORT_NAME, TRIAGE_MASTER_REPORT_DIR, AVI_PATH)\n",
        "          if not OK:\n",
        "             print (\"problem getting array\")\n",
        "             pdb.set_trace()\n",
        "          return PTC  # return the class\n",
        "'''\n",
        "class Yolov8 :\n",
        "    def __init__(self) :\n",
        "      print (\"initializin yolo lass\" )\n",
        "    def GET_CLASS(self):\n",
        "        yolov8=\"\"\n",
        "        return yolov8\n",
        "\n",
        "def GET_YOLOV8_CLASS ():\n",
        "    YOLOV8_CLASS = Yolov8()\n",
        "    return YOLOV8_CLASS\n",
        " '''\n",
        "\n",
        "def Get_AI (TAG, TRIAGE_CLASS, YOLOV8_CLASS):\n",
        "    print (\"processing TAG: \", TAG)\n",
        "    pdb.set_trace()\n",
        "\n",
        "    ## UPdate with AI from Yoov8\n",
        "    return\n",
        "\n",
        "def list_vid(FP):\n",
        "    #=(FP):\n",
        "    lst=os.listdir(FP)\n",
        "    print (len(lst), \"v in\", FP)\n",
        "    return lst\n",
        "\n",
        "#def Read_csv (FP_IN):\n",
        "    # read in csv ground truth / blind annoations rom sharol\n",
        "\n",
        "def  Read_IN (FP_IN):\n",
        "    fp=open (FP_IN)\n",
        "    START=False\n",
        "    IN_LIST = [] #\n",
        "    nl = 0\n",
        "    with open (FP_IN) as fp:\n",
        "        for line in fp:\n",
        "            print (nl,\"  \", line)\n",
        "            nl+=1\n",
        "            if \"Sharol,\" in line:\n",
        "                 # skip\n",
        "                 print (\"skipping\", line) #break\n",
        "                 break\n",
        "            if not START:\n",
        "                    if \"Attachments\" in line: START=True\n",
        "            else:\n",
        "                # started, read 0X9DB79DF0A269227.mp4; 0X9E3D09429F6B852.mp4;\n",
        "                if \".mp4;\"in line:\n",
        "                    flds=line.split(\";\")\n",
        "                    print (flds)\n",
        "                    f1=flds[0]\n",
        "                    f2=flds[1]\n",
        "                    IN_LIST.append (f1)\n",
        "                    IN_LIST.append (f2)\n",
        "\n",
        "    print (\"end of in list of , \", len(IN_LIST))\n",
        "    return IN_LIST\n",
        "\n",
        "def _Get_TAG_values ( TAG, Triage_np):\n",
        "    # triage array\n",
        "    # assume data is clean\n",
        "\n",
        "    #FRAMES = np_row[1]\n",
        "\n",
        "  #  if TAG.islower():TAG.upper()\n",
        "   # TAG=self._clean_spaces(TAG)\n",
        "    TEST = False\n",
        "    #pdb.set_trace()\n",
        "    if TEST: pdb.set_trace()\n",
        "    print (\" fetching TAG:\", TAG)\n",
        "    FOUND = False\n",
        "    NP_data = Triage_np\n",
        "    lnp = len (NP_data)-1  # fim zero\n",
        "    print (\"lnp is \", lnp)\n",
        "    T1=20\n",
        "    TX=0\n",
        "    for i in range (lnp):\n",
        "        TX+=1\n",
        "        np_row = NP_data[i]\n",
        "        tag= np_row[2] # tags should alway be upper\n",
        "        T1-=1\n",
        "        INCREMENT = False\n",
        "        if INCREMENT:\n",
        "            if T1==0:\n",
        "                print (np_row)\n",
        "                x=input (\"GO or x, or new number\")\n",
        "                if x==\"x\":\n",
        "                    print (\"quitting at \", TX)\n",
        "                    pdb.set_trace(\"stop here\")\n",
        "                    return True, []    #self._get_row_values (np_row)\n",
        "                if x==\"\":\n",
        "                    T1=20\n",
        "                else :\n",
        "                    nn= int (x)\n",
        "                    if isinstance (x, int):\n",
        "                        T1=nn\n",
        "\n",
        "        if tag==TAG:\n",
        "            FOUND = True\n",
        "            NUM   = np_row[0]\n",
        "            FRAMES = np_row[1]\n",
        "            TAG= np_row[2] # tags should alway be upper\n",
        "            #if TAG.islower():TAG.upper()\n",
        "            # TAG=self._clean_spaces(TAG)\n",
        "            print (\"Found \", TAG, \"at \", TX, \" \\n \",np_row)\n",
        "\n",
        "            TPL = np_row  # []# self._get_row_values(np_row)\n",
        "            return FOUND,TPL\n",
        "    print (TAG, \"NOt found after \", TX)\n",
        "    return False,() # epmpty\n",
        "def SPELL_UP(LABEL):\n",
        "    ECHO=True\n",
        "    SHORT=True # show time tracker\n",
        "    TEST=True\n",
        "    #global TK\n",
        "    #TK.L (\"Spell up\", str(LABEL))\n",
        "    # check comon checkin erro\n",
        "    Short_dir =os.path.join (\"/content/REPORTS/track/\")\n",
        "    Short_fp  = os.path.join (Short_dir,\"short_\"+str(RELEASE)+\"_.txt\")\n",
        "    if not os.path.exists (Short_dir):\n",
        "      os.makedirs(Short_dir, exist_ok=True)\n",
        "    STD=cm_plot_labels  #cm_plot_labels = [\"Endocarditis\",\"Mild\",\"Non-Visible\",\"Normal\",\"Prosthetic\",\"Severe\"] #alphabetic\n",
        "    COMMON_SPELLUP=CU={'Stenosed':\"Severe\",'Stenosis':\"Severe\",'Tenosis':'Severe','Mil':'Mild', \"Norml\":\"Normal\", \"Sever\":\"Severe\", \"Prothetic\":\"Prosthetic\", \"Prostetic\":\"Prosthetic\",\"Stenosed\":\"Stenosis\"} # dicionary\n",
        "    CU.update({\"Non-Visible\":\"NonVisible\"}) # for release 80 series\n",
        "    if LABEL==\"SPELL_DICT\":\n",
        "        return COMMON_SPELLUP\n",
        "    if LABEL in CU.keys():\n",
        "        NEW_LABEL = CU[LABEL]\n",
        "        if TEST:pdb.set_trace()\n",
        "        if ECHO: print (\" updated \", LABEL, \" to \", NEW_LABEL)\n",
        "        arg=\"\\n updated \"+str( LABEL)+  \" to \"+str(NEW_LABEL)\n",
        "        #K.T(arg)\n",
        "        if SHORT:\n",
        "          f=open(Short_fp,\"a\")\n",
        "          f.write (arg)\n",
        "          f.close()\n",
        "        return NEW_LABEL\n",
        "    else: return LABEL\n",
        "\n",
        "\n",
        "def READ_SHROL_EVAL (CONSOLIDATD_CSV_NAME, PATH):\n",
        "    #global TK\n",
        "    args = str(CONSOLIDATD_CSV_NAME)+ ' |'+ str (PATH)\n",
        "    print (args)\n",
        "    #TK.L (\"READ SHAOL EVAL\", args)\n",
        "    print (\" Read in prepare d echo ecaluations\")\n",
        "    TEST = False\n",
        "    CN=CONSOLIDATD_CSV_NAME\n",
        "    CP=PATH\n",
        "    MODULE = \"READ SHAROL EVAL\"\n",
        "    if TEST: pdb.set_trace()\n",
        "    # use read ground truth  raw data\n",
        "    # create class\n",
        "    OPTIONS = (False, False)  #   Track, Test\n",
        "    F1= F_1 (OPTIONS)\n",
        "    print (\"reading in consolicated csv file: \", CN, \" AT \", CP)\n",
        "    CSV_PATH = CP\n",
        "    CSV_NAME = CN\n",
        "    Echo_data = F1.Load_CSV_Ground_Truth (CSV_PATH, CSV_NAME)\n",
        "    if TEST: pdb.set_trace()\n",
        "    # returns a list of TAGs?\n",
        "    MT=False\n",
        "    if MT:\n",
        "        MILD_TAGS=MT=[('D4F5F','Severe'),('FB24F','Mild'),('58F10','Mild'),('ACFE8','Mild'), \\\n",
        "                      ('7CCE4','Mild'),('C5714','Mild'),('541A0','Mild'),('87BA6','Mild'), \\\n",
        "                          ('0D042','Mild'),('27D5C','Omit')]  # (TAG , AI)  THEE Ae HSOL RFS\n",
        "        return MT\n",
        "    print (\"Not fixed list retueinve list of TAG,SHAROL\")\n",
        "    SH_list =[]\n",
        "    for E in Echo_data:\n",
        "        tag = E[0]\n",
        "        sharol= E[2]\n",
        "        sharol=SPELL_UP(sharol) # release 2-9-24\n",
        "        Qscore= E[4]\n",
        "        if \"omit\" in E:\n",
        "            print (\"found OMIT set Q to 1\")\n",
        "            Qscore = 1\n",
        "            if TEST: pdb.set_trace()\n",
        "        SH_list.append ((tag,sharol,Qscore))\n",
        "    args= str (len(SH_list))+ \" sharol cases foudn\"\n",
        "    #TK.T(args)\n",
        "    print (args)\n",
        "    return SH_list , Echo_data\n",
        "    #return Echo_data\n",
        "\n",
        "def BUILD_BLIND_REPORT ():\n",
        "    print ( \"creatint blind summary report\")\n",
        "    ##################\n",
        "    ## set up blind report ##  11/27\n",
        "    ##################\n",
        "    TODAY=datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "    COMMON_SUFFEX =CS=str(VERSION)+\"_\"+str(TODAY)+\".txt\"\n",
        "    BLND_NAME = \"Cardiac_Patterns_Blind_Study_Results_Report_\"+  CS\n",
        "    RPT_BASE  = os.path.join (\"D:\\\\\",\"CP_BLIND_STUDY\",\"PROCESSED_REPORTS\")\n",
        "   # d_list = os.listdir(DATE_BASE)\n",
        "   #print (\" pick a date\")\n",
        "    #nx,pick = PICK_ONE(d_list)\n",
        "    #RPT_DATE = pick\n",
        "    #RPT_NAME =\"Cardiac_Patterns_Blind_Study__\"+CS   #str(VERSION)+\"_\"+str(RPT_DATE)+\".txt\"\n",
        "   # SRT_NAME =\"Cardiac_Patterns_Blind_Score__\"+CS   #str(VERSION)+\"_\"+str(RPT_DATE)+\".txt\"\n",
        "    # do areports\n",
        "   # P_RPT_DIR =os.path.join (RPT_BASE,\"report\")\n",
        "   # S_RPT_DIR =os.path.join (RPT_BASE, \"score\")\n",
        "    B_RPT_DIR = os.path.join (RPT_BASE, \"summary\")  # this is the glind report\n",
        "\n",
        "    REPORT_NAME = RPT_NAME= BLND_NAME\n",
        "    P_RPT_DIR   = RPT_BASE\n",
        "    #RPTD  =BLIND_STUDY(P_RPT_DIR, REPORT_NAME)\n",
        "    #REPORT_NAME = SRT_NAME  # for score sheet\n",
        "    #SRTD  =BLIND_STUDY(S_RPT_DIR, REPORT_NAME)\n",
        "    BRPT = BLIND_STUDY(B_RPT_DIR, BLND_NAME)\n",
        "    return BRPT\n",
        "\n",
        "def CHECK_AGREEMENT (AI,CONF,LBL2, CONF2, SHAROL, TAG):\n",
        "    global TK\n",
        "    TEST=False\n",
        "    MODULE=\"Check _Ageement\"\n",
        "    print (\"checking agreemente begween sources\")\n",
        "    arg=\"TAG: \"+str(TAG)+\" AI:\"+str (AI)+ \" conf: \"+str (CONF)+\" LBL2\\CONF: \"+str(LBL2)+\"|\"+str(CONF2)+ \" Sharol: \"+str(SHAROL)\n",
        "    TK.L ( \"CHECK GREEMENT\", arg)\n",
        "    Equivocal =EQ= 0  # adjudiates in close calls\n",
        "    global MARGIN\n",
        "    # compare two strings using Case insenstitive\n",
        "    # remove white spaces\n",
        "    #if SHAROL == 'Stenosed':\n",
        "    ECHO= True\n",
        "    TEST=False\n",
        "    A=AI.strip()\n",
        "    S=SHAROL.strip()\n",
        "    S=SPELL_UP(S)\n",
        "    SHAROL=SPELL_UP(SHAROL) # check both\n",
        "    EQ_MARGIN = MARGIN *100  # percentagaes!#0.45  # WITHIN 10 % MEANS EQ# adjustd for v91\n",
        "    if  A.casefold()==S.casefold():\n",
        "       arg= \"found equivalents \"+str( AI)+ \"|\"+str( SHAROL)\n",
        "       TK.T(arg)\n",
        "       EQ=0\n",
        "       TK.T(\"\")\n",
        "       return True, EQ\n",
        "    elif  SHAROL == 'Stenosed' and AI==\"Severe\":\n",
        "        arg=\"found Stenosed == Severe\"\n",
        "        TK.T(arg)\n",
        "        return True, EQ\n",
        "    elif  SHAROL == 'Stenosis' and AI==\"Severe\":\n",
        "        arg=\"found Stenosis and Severe\"\n",
        "        TK.T(arg)\n",
        "        return True, EQ\n",
        "    elif SHAROL == \"Prosthetic\" and AI==\"Severe\":\n",
        "        arg=\"found Prosthetic and Severe \"\n",
        "        TK.T(arg)\n",
        "        EQ=0\n",
        "        return True, EQ\n",
        "        # consider AI at 45 and 23  with professional gees 2nd label\n",
        "    else:\n",
        "        if TEST: pdb.set_trace() # exmine data\n",
        "        arg=\"AI: \"+str (AI)+ \" conf: \"+str(CONF)+\" LBL2:\"+str(LBL2)+ \" conf2:\"+str(CONF2)\n",
        "        arg+=\" Ground Truth: \"+str (SHAROL)+ \" at TAG: \"+str(TAG)\n",
        "        TK.T(arg)\n",
        "        B=LBL2.strip()\n",
        "        C=float(CONF.replace(\"%\",\"\"))\n",
        "        C2=float(CONF2.replace(\"%\",\"\"))\n",
        "        TOLERANCE=0  # to avoid probl\n",
        "        arg=\"In second test\"+str(C)+\"|\"+str(C2)\n",
        "        TK.T(arg)\n",
        "        if B.casefold()==S.casefold(): # TRY SECOND labl declare eq\n",
        "            # edge case\n",
        "            # a hit if conf2 within EQ_MARGINE of conf gthen ecalre EQ\n",
        "            #TOLERANCE = CONF-CONF2\n",
        "            TOLERANCE = (C-C2)/100 # normalized leady percentge\n",
        "            TOLERANCE = abs((C-C2)) # just in case\n",
        "            if TOLERANCE <=EQ_MARGIN :\n",
        "                EQ=1\n",
        "            if ECHO: print (\"boundaries : \",TOLERANCE )\n",
        "        if ECHO:\n",
        "            arg= \"Equivocal Case: LBL1, CON1\"+str( AI)+\"|\"+str(CONF)+\"  lbl2/conf2\"+str( LBL2)+\"|\"+str( CONF2)+\" SHAROL: \"+str( SHAROL)\n",
        "            arg+= \" Tolerance: \"+str( TOLERANCE)\n",
        "            TK.T(arg)\n",
        "        if TEST: pdb.set_trace()\n",
        "        if EQ==1:\n",
        "            arg=\"return TRUE \"+str(EQ)\n",
        "            TK.T(arg)\n",
        "            return True, EQ\n",
        "    if ECHO: print (\"No match on first or second for \", SHAROL, \" at \", TAG)\n",
        "    arg =\"No match on first or second for \"+str( SHAROL) + \" at \"+str( TAG)\n",
        "    TK.T(arg)\n",
        "    return False , EQ # no match on first or second\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xvNIhn5YeiyP"
      },
      "outputs": [],
      "source": [
        "# PART THREE M A I N\n",
        "print (\"PART THREE - M A I N\")\n",
        "VERSION = \"0.280\"\n",
        "MISSION = \" ADD AI EVALUATION TO REPORT & TRACKING & YOLOV8 predictions @ v 250\"\n",
        "MISSION+=\"\\n v260 is working!! c v 261 has sharol limit to shorten running\"\n",
        "MISSION+=\"\\n porting to colap and genrealize configurations\"\n",
        "MISSION+=\"\\n release 270 includes Z_Flag\"\n",
        "NEW_MISSION= \" Read list of tag + ai + sharol as CSV  add Equivocal NOW SELEECT LIST\"\n",
        "\n",
        "def main (CONFIG):\n",
        "    global MARGIN\n",
        "    global TK\n",
        "    YOLO_FORMAT = True\n",
        "    print (\"using yolo format: \", YOLO_FORMAT)\n",
        "    print (\"set breakpoints now\")\n",
        "    pdb.set_trace()\n",
        "    CTEST=False  # conv\n",
        "    DPTH=os.path.join (os.getcwd())# default\n",
        "    # note VID_DIR in a config is root echos, my not work here\n",
        "    ROOT, TRIAGE_DIR, VID_DIR, LIBS,WEIGHTS, STORE, REPORTS, CHECK_POINT, BLIND_STUDY = UNPACK_CONFIG(CONFIG)\n",
        "    print (\"\\n CONFIGURATION:\",ROOT, TRIAGE_DIR, VID_DIR,LIBS, WEIGHTS, STORE, REPORTS,CHECK_POINT, BLIND_STUDY)\n",
        "    MARGIN = 0.45  # FROM ANALYSIS\n",
        "    if CTEST: pdb.set_trace()\n",
        "    TEST=False\n",
        "    CHECK=True  # CHEOCN AGREEMENT\n",
        "    MODULE = \"Main\"\n",
        "    print (\"\\n ENTERING M A I N with \", ROOT)\n",
        "    MISSING_TAGS=[] # list of missing TAGS\n",
        "    SPELL_DICT = SPELL_UP(\"SPELL_DICT\")\n",
        "    print (\"spelling corrections: \\n ITEM CORRECTION\\n\")\n",
        "    for k,v in SPELL_DICT.items():\n",
        "        print (k,\"\\t\",v)\n",
        "\n",
        "    xx=input (\"generated score report from email cr=no\")\n",
        "    if xx==\"\":\n",
        "        READ_DATA = False # check data to read\n",
        "    else:\n",
        "        READ_DATA = True\n",
        "    today = date.today()\n",
        "    # CHECK ON Q SCORE\n",
        "    print (\"\\nEqui-val Margin is \",MARGIN, \" \\n\" )\n",
        "    if READ_DATA:\n",
        "        SRPT_DIR = os.path.join (os.getcwd())\n",
        "        SNAME    = \"Cardiac_Patterns_Blind_ECHOS_\"+str(VERSION)+\"_\"+str(today)+\".txt\"\n",
        "        SHD = \" Evaluation Score Card_v\"+str(VERSION)\n",
        "        TT=\"\\t\"\n",
        "        SFLDS = \"NO\"+TT+\"TAG\"+TT+\"SHAROL\"+TT+\"FILE NAME\"+TT+\"DATE\\n\"\n",
        "        short_rpt= SRPT = Report(SRPT_DIR, SNAME,SHD, SFLDS)\n",
        "        IP= os.path.join (\"D:\\\\\",\"CP_BLIND_STUDY\",\"PROCESSED_REPORTS\")\n",
        "        IP= os.path.join (\"D:\\\\\",\"CP_BLIND_STUDY\",\"RE-ISSUE\",\"REPORT\")\n",
        "        IPN=\"Next_BLIND_study_incement.txt\"\n",
        "        IPN=\"sharol 12-5 _data.txt\"\n",
        "        LST = os.listdir(IP)\n",
        "        np,pick = PICK_ONEX(LST, \".txt\")\n",
        "        if pick != IPN:\n",
        "            print (\"wrong link? \", IPN, \" vs \", pick)\n",
        "            pdb.set_trace()\n",
        "        else:\n",
        "             IPN=pick\n",
        "             print (\"selecting \", pick)\n",
        "        FP_IN = os.path.join (IP, IPN)\n",
        "        IN_LIST = Read_IN (FP_IN)\n",
        "        print (\"\\n Contents of \", IPN)\n",
        "        SPACE = TT+str(today)+\"\\n\\n\"\n",
        "        for i in range (len(IN_LIST)):\n",
        "            print (\"[\",i,\"] \",IN_LIST[i])\n",
        "            LN=IN_LIST[i]\n",
        "            TAG=TAG_FROM_VID(LN)\n",
        "            line = TT+str(TAG)+TT+\"____________\"+TT+str(LN)+SPACE\n",
        "            SRPT.addL(line)\n",
        "        SRPT.endFile(\"End of list Nov 28\")\n",
        "        print (\"look in \", SRPT_DIR)\n",
        "        pdb.set_trace()\n",
        "    today = date.today()\n",
        "    if TEST:pdb.set_trace()  # conv\n",
        "    T_CLASS= T=   GET_TRIAGE (TRIAGE_DIR, VID_DIR)\n",
        "    Triage_np = T._get_Triage_np()\n",
        "    #pdb.set_trace()\n",
        "    TEST_TAGS = False\n",
        "    if TEST_TAGS:\n",
        "        print (\"TESTING TAG RETEAL\")\n",
        "        TEST_TAGS =TT= [('3368B','PROSTETIC'),('7E925','MILD'),('24933','MILD'),('2A231','NORMAL'),\\\n",
        "                     ('DC01C','STENOSED'),('EE3A2','NORMAL'),('5EA5B','NORMAL'), ('EOE45','STENOSED'),\\\n",
        "                         ('8F990','N0RMAL'),('2559F','STENOSED')]\n",
        "        MILD_TAGS=MT=[('D4F5F','Severe'),('FB24F','Mild'),('58F10','Mild'),('ACFE8','Mild'), \\\n",
        "                      ('7CCE4','Mild'),('C5714','Mild'),('541A0','Mild'),('87BA6','Mild'), \\\n",
        "                          ('0D042','Mild'),('27D5C','Omit')]  # (TAG , AI)  THEE Ae HSOL RFS\n",
        "        print (\" from 6/23 MILD study \", MT)\n",
        "        XT=TT+MT\n",
        "        for tl in XT:\n",
        "             TAG=tl[0]\n",
        "             LBL=tl[1]\n",
        "             OK, TPL = _Get_TAG_values (TAG, Triage_np) # use local function\n",
        "             if not OK:\n",
        "                 print ( 'problem at ', TAG)\n",
        "                 pdb.set_trace()\n",
        "             else:\n",
        "                 print (\" at \", TAG, \"sharol: \" , LBL,\"AI:\", TPL)\n",
        "        print (\"end of internal test on TAGS\")\n",
        "    #pdb.set_trace()\n",
        "    today = date.today()\n",
        "    DATE = today\n",
        "    ## dont need this\n",
        "    '''\n",
        "    FP = os.path.join (ROOT,\"videos\",\"28-November\")  # conv\n",
        "    L=list_vid(FP)\n",
        "    '''\n",
        "    STOP=False\n",
        "    if STOP: pdb.set_trace()\n",
        "    #self, DIR, NAME, HEADER, FIELDS,TYPE=0, ADD=False):\n",
        "    RPT_DIR = REPORTS # from config os.path.join (\"D:\\CP_BLIND_STUDY\\PROCESSED_REPORTS\")\n",
        "    NAME=\"Cardiac_Patterns_Consolidatd_Blind_Study_\"+str (DATE)+\"_\"+str(VERSION)+\"_\"+str(RELEASE)+\".txt\"\n",
        "    HD = \"BLIND STUDY VIDEOS for\\t\"+str(VERSION)+\" RELEASE: \"+str(RELEASE)\n",
        "    HD+=\"\\n AI Source:  Yolov8 \\n MODEL: yolov8x\\n\"\n",
        "    TT=\"\\t\"\n",
        "    FLDS = \"No\"+TT+\"TAG\"+TT+\"AI\"+TT+\"CONF\" +TT+\"LABEL2\"+TT+\"CONF2\"+TT\n",
        "    FLDS+=\"SHAROL\"+TT+\"FILE_NAME\"+TT+\"AGREEMENT\"+TT+\"EQUIVOCAL\\n\"\n",
        "    # for YOLO\n",
        "    FLDS =\"No\"+TT+\"TAG\"+TT+\"GND_TRUTH\"+TT+\"AI\"+TT+\"CONF\" +TT+\"LABEL2\"+\" / \"+\"CONF2\"\n",
        "    FLDS+=TT+\"AGREEMENT\"+TT+\"EQUIVOCAL\\n\"\n",
        "    RPT = Report(RPT_DIR, NAME,HD, FLDS)\n",
        "    print (\"report: \", NAME, \" at \", RPT_DIR)\n",
        "    LTEST=False  # local test\n",
        "    if LTEST:\n",
        "        FLIST = list_vid(FP)\n",
        "        FLIST =IN_LIST\n",
        "        print (\"processing \", FP_IN )\n",
        "    CSV_NAME=\"Blind_Study_consolidation_MASTER_112623v03.csv\"\n",
        "    #PATH   = os.path.join (\"C:\\\\\",\"Backup-OFFSITE\",\"0000CardiacPatterns\",\"F1-STUDY\",\"F-1Study\",\"F-1DATA\")\n",
        "    # updagte faor blind reporaat\n",
        "    #PATH  = os.path.join (\"C:\\\\\",\"Backup-OFFSITE\",\"0000CardiacPatterns\",\"BLIND_Study\",\"CONSOLIDATION\")\n",
        "    PATH   = BLIND_STUDY\n",
        "    if LTEST:pdb.set_trace() # temp\n",
        "    CSV_LIST = os.listdir (PATH)\n",
        "    print (\"pick consolidated source from \", PATH)\n",
        "    num, pick = PICK_ONEX(CSV_LIST, \".csv\")\n",
        "    if not isinstance (num, int):\n",
        "        print (\"cant\")\n",
        "        pdb.set_trace()\n",
        "    else:\n",
        "        CSV_NAME = pick\n",
        "    # whre is the READ CSV\n",
        "    SHAROL_LIST, Echo_data = READ_SHROL_EVAL(CSV_NAME, PATH)\n",
        "    # set up tracking\n",
        "    TRACK_FILE = \"Cardiac_Patterns_TRACK_RECORD_\"+str(VERSION)+\"_\"+str(RELEASE)+\".txt\"\n",
        "    TRACK_DIR  = os.path.join (RPT_DIR,\"track\")\n",
        "    TK=_TRACK (TRACK_FILE,TRACK_DIR)\n",
        "    ARGS = \" Track recored from \"+str(today)+\" version: \"+str(VERSION)\n",
        "    TK.L(\"MAIN\", ARGS)\n",
        "\n",
        "    #for f in FLIST :\n",
        "    A_Count = 0# READ_SHROL_EVAL number of agreements\n",
        "    R_Count = 0 # number of records processes\n",
        "    X_Count = 0 # number of disagreements\n",
        "    M_Count = 0 # number of marginal deciions\n",
        "    N_Count = 0 # numer of NO AI\n",
        "    NValid  = 0 # count of valid cases\n",
        "    LTEST = False\n",
        "    TEST=False\n",
        "    #####\n",
        "    print (\"Engaging YOLOV8 with root:\", ROOT)\n",
        "    if TEST: pdb.set_trace()\n",
        "    #A#VI_DIR =VD= os.path.join (\"C:\\\\\", \"AI\", \"videos\"  )\n",
        "    AVI_DIR =VD= VID_DIR  # conv FROM COFIG\n",
        "    #PICKEL_DIR =PD=os.path.join (ROOT, \"STORE\")\n",
        "    PICKEL_DIR = PD=STORE\n",
        "\n",
        "    print (\"initializing video class & pickel dir:\\n\", VD,\"\\n :\", PD)\n",
        "    #VID_CLASS = V=VIDEO (AVI_DIR)\n",
        "    VID_CLASS = V = VIDEO (VID_DIR) # thi is active videos not ROOT vids which may not benecessary\n",
        "    V._set_TEST(False)\n",
        "    OK=V._get_vid_np_status()   #_get_vid_np_status\n",
        "    if OK:\n",
        "     VID_np=V._get_vid_np()\n",
        "    else: print (\"VID_NP Not initilized, creating new array [ may take a while], or request pickel\")\n",
        "    xx=input (\"cr = go with pickel\")\n",
        "    if xx!=\"\":\n",
        "        VID_STAT,VID_np=V._create_vid_np(VD)\n",
        "        if not VID_STAT:\n",
        "            print(\"couldn't create vid_np (empty)\")\n",
        "    ## seg up pickle\n",
        "\n",
        "        if not os.path.exists (PD):\n",
        "            os.makedirs(PD)\n",
        "            print (\"creating \", PD)\n",
        "        print ( \"pickel version of video is at \",PD)\n",
        "        V._set_pickel_dir(PD)  # this is OK\n",
        "        V._set_vid_dir (VID_DIR)  # neessary aftger convert\n",
        "        LAST_PICKEL_PATH = \"unconfigured\"\n",
        "        LAST_PICKEL_NAME = \"unconfigured\"\n",
        "        LAST_PICKEL_DIR  = \"unconfigured\"\n",
        "        Plist = os.listdir(PD)  # list of pickeled vids\n",
        "        # check VID_STAT\n",
        "        #if not VID_STAT:# its neer oin to  be TRue\n",
        "        print (\"Initilizing Video NP array from pickle\")\n",
        "        PICKEL_NAME=\"Cardic_Patterns_Video_Lib_\"  # save fills in gthe rest\n",
        "        xx=input (\"vidstat:\"+\" create new pickenl only,vid np n,= cr=retrieve pickle\")\n",
        "        print (\"NOT IMPLEMEntD\")\n",
        "        pdb.set_trace()\n",
        "    if xx==\"n\":\n",
        "            print (\"FORCE create new pickel?\")\n",
        "            FORCE=True\n",
        "            nx=-1\n",
        "            VID_STAT,VID_np=V._create_video_np(VD)\n",
        "            if not VID_STAT:\n",
        "                print (\"still no vide_np etter quit\")\n",
        "                pdb.set_trace()\n",
        "            OK, FULL_PICKEL_PATH = V._pickel_(PICKEL_NAME, 'save',FORCE)\n",
        "            print (\"Full pickel path is: \", FULL_PICKEL_PATH)\n",
        "            if not OK:\n",
        "                print (\"some error\")\n",
        "                pdb.set_trace()\n",
        "            '''\n",
        "        elif xx==\"S\":\n",
        "            nx,pick = PICK_ONEX(Plist, \"pkl\")\n",
        "        else:\n",
        "            VID_DIR = os.path.join (AVI_DIR)\n",
        "            VID_NP=V._just_np( AVI_DIR)\n",
        "            pdb.set_trace()\n",
        "             '''\n",
        "    elif xx==\"\":\n",
        "    # SELECT EXIXITING PICKLE\n",
        "        Plist=os.listdir(PICKEL_DIR)\n",
        "        if not os.path.exists (PICKEL_DIR):\n",
        "            print (\"doesnt exist: \", PD)\n",
        "            pdb.set_trace()\n",
        "        nx,pick = PICK_ONEX(Plist, \"pkl\")\n",
        "        if nx<0:  # not pick or none\n",
        "            print (\"No saved pickels or force new :create new pickle\")\n",
        "            FORCE=True\n",
        "            PICKEL_NAME=\"Cardic_Patterns_Video_Lib\"\n",
        "            V._set_ECHO(True)\n",
        "            V._set_TEST(True)\n",
        "\n",
        "            #PICKEL_DIR = PD=os.path.join (ROOT,\"STORE\") # alray\n",
        "            #V._set_pickel_dir(PD)\n",
        "            PPP=os.path.join (PD,PICKEL_NAME) # might be  problem if forced\n",
        "            #V._set_pickel_path(PPP)  # full path\n",
        "            '''\n",
        "            #VID_NP = V._create_vid_np(AVI_DIR)\n",
        "            if not V._set_pickel_data(PICKEL_NAME, PD):\n",
        "                print (\"pickel error\")\n",
        "                pdb.set_trace()\n",
        "                '''\n",
        "            OK, FULL_PICKEL_PATH = V._pickel_(PICKEL_NAME, 'load',FORCE)\n",
        "            print (\"Full pickel path is: \", FULL_PICKEL_PATH)\n",
        "            if not OK:\n",
        "                print (\"some error\")\n",
        "                pdb.set_trace()\n",
        "        else: # using existing pickel\n",
        "            print (\" exiting pkl, usng \",pick)\n",
        "            PICKEL_NAME = pick\n",
        "            PICKEL_PATH  =PP=os.path.join (PICKEL_DIR, pick)\n",
        "            V._set_pickel_dir(PICKEL_DIR)\n",
        "            V._set_pickel_path (PICKEL_PATH)  # FULLL PATH\n",
        "            OK, VID_NP=V._pickel_(PICKEL_NAME, \"load\")\n",
        "            #OK,NVID= V._create_vid_np(AVI_DIR)  # hould alredy be there fro m pickle\n",
        "            if not V._get_VID_STATUS():\n",
        "                print (\"bad status after pickel load\")\n",
        "                pdb.set_trace()\n",
        "            XVID=V._just_np(AVI_DIR)\n",
        "            if not OK:\n",
        "                print (\"problem loading video np\") #VID_NP2 = V._get_vid_np()\n",
        "                pdb.set_trace()\n",
        "\n",
        "    print (\"status of vid: \", V._get_vid_np_status())\n",
        "\n",
        "    #VID_np =V._get_vid_np()  # shoul alreaey hqe it\n",
        "    OK,VID_np=V._create_vid_np(AVI_DIR)# conve.  creage vid np in curent en ieomn\n",
        "    if not OK:\n",
        "      print (\"error in re-ceating vid_np\")\n",
        "      pdb.set_trace()  # conv upate\n",
        "    VID_np=V._just_np(AVI_DIR)  # aove doesnt work\n",
        "    LTEST=False\n",
        "    if LTEST: pdb.set_trace()\n",
        "    yolov=Y=YOLOV8(ROOT)\n",
        "    Y._set_vid_dir(AVI_DIR)\n",
        "    Y._set_vid_class(V)\n",
        "    Y._set_TEST(False)\n",
        "    Y._set_ECHO(True)\n",
        "    Y._set_PICKEL_DIR (PD)\n",
        "    MODELS = (\"yolov8x.pt\", \"yolov8m.pt\", \"yolov8l.pt\", \"yolov8n.pt\", \"yolov8n.pt\") # just the size\n",
        "    MODEL_NAME=\"yolov8x.pt\"\n",
        "    #MODEL_NAME=\"yolov8l.pt\"  # try smaller model NO\n",
        "    WEIGHTS_NAME = \"best.pt\"\n",
        "    #W_FP = WEIGHTS_NAME=os.path.join (\"D:\\\\\",\"CP_BLIND_STUDY\",\"PROCESSED_REPORTS\",\"MODEL\", WEIGHTS_NAME)\n",
        "    W_FP = Weights_Full_path = os.path.join (WEIGHTS, WEIGHTS_NAME) # fixed for conv\n",
        "    OK, model= Y._load_yolo(MODEL_NAME, W_FP)\n",
        "    Y._set_TEST(False)\n",
        "    Ok=Y._create_np()\n",
        "    OK=Y._set_vid_dir(AVI_DIR)\n",
        "    XTEST=False\n",
        "    if not OK:\n",
        "        pdb.set_trace()\n",
        "    if XTEST: pdb.set_trace()\n",
        "    Y._set_TEST(False)\n",
        "    Yolo_np,OK=Y._get_yolo_np() # geg entrie arrayhoule be empty at this point\n",
        "    print (Y._config())\n",
        "    if LTEST:pdb.set_trace()\n",
        "    RESULT_PICKEL_PATH = RPD=os.path.join (ROOT, \"RESULT\")\n",
        "    os.makedirs (RPD, exist_ok=True)\n",
        "    Y._set_PICKEL_DIR(RPD)\n",
        "    LATE=False # no late start\n",
        "    xx=input (\"limit ground truth = number or cr = no or s=skip this many  befor starting\")\n",
        "    if xx==\"\":\n",
        "        print (\"dont limit\")\n",
        "        SHAROL_LIMIT = False\n",
        "        NSHAROL      = 10000 # EFECTIELYINFINITE\n",
        "    elif xx==\"s\":\n",
        "      print (\"enter numberer to skip and later how many\")\n",
        "      xx=input (\"how manty to skip?\")\n",
        "      try:\n",
        "        nSkip = int (xx)\n",
        "        NSKIP = nSkip\n",
        "        xx= input (\"then how many to try\")\n",
        "        nshrol= int (xx)\n",
        "        SHAROL_LIMIT = True\n",
        "        NSHAROL = nSkip+nshrol\n",
        "        LATE = True\n",
        "      except Exception  as EX:\n",
        "          print (\"some problem\", EX)\n",
        "          pdb.set_trace()\n",
        "    else:\n",
        "        try:\n",
        "            nshrol= int (xx)\n",
        "            SHAROL_LIMIT = True\n",
        "            NSHAROL=nshrol\n",
        "        except Exception as EX:\n",
        "            print (\"some problem: \", EX)\n",
        "            pdb.set_trace()\n",
        "    Nsharol=0\n",
        "    ####\n",
        "    ## STAGE I of MAIN\n",
        "    ## scn for exiting TAGS in Yolo_Np\n",
        "    ### add and perform  model if not there\n",
        "    ######\n",
        "    ECHO=True\n",
        "    PTEST=False # checking on echo entries\n",
        "    Nscip=0  # cound num r of skipped\n",
        "    V._set_TEST(False) # so not too manuy igerruptions\n",
        "    Q_LIST=[]  # lisgt of tags eliminated due to Quality score\n",
        "    STOP=False\n",
        "    if STOP: pdb.set_trace()  # check poit to exaind yool_np\n",
        "    # sharol list format: (tag,sharol,Qscore)\n",
        "    for S in SHAROL_LIST :\n",
        "        # SHROL LISTtag,sharol,Qscore\n",
        "        if SHAROL_LIMIT :print (\"working on sharol no. \",Nsharol, \" of \",NSHAROL)\n",
        "        if LATE: # o lagte sgart\n",
        "           if  Nsharol > NSKIP:  # then take rest seriously\n",
        "               Nscip+=1\n",
        "           else:\n",
        "              Nsharol+=1 # keep counting\n",
        "              continue\n",
        "        TAG=S[0]\n",
        "        if TAG==\"TESTX\": continue\n",
        "        DIAG=S[1]\n",
        "        Qscore=S[2]\n",
        "        if CHECK and TAG in CHECK_TAGS:\n",
        "            print (\"stop here on TAG: \",TAG)\n",
        "        if Y._exists(TAG):\n",
        "            print (\"adding \", TAG, \" to Yolo_p\")\n",
        "            if ECHO: print ('Ground truth list: ', S)\n",
        "            rec=\"Adding TAG to yolo \"+str(TAG)+ \"whih sharol: \"+ str(S)+ \" and Q_Score: \"+str(Qscore)\n",
        "            TK.T(rec)\n",
        "            if (Qscore!= 0) and(Qscore!=\" \"):\n",
        "              print (\"Qscoe NOT zero, Ommmitting\", TAG, \" is \",Qscore)\n",
        "              QTUPL=(TAG, DIAG,Qscore )\n",
        "              Q_LIST.append ((QTUPL))\n",
        "              continue\n",
        "            #Y._set_TEST(True)\n",
        "            YOLO_NP_ONE_ROW= Y._get_tag_values (TAG) # TAG VALUES =([\" \",\" \",0.1,\"\",0.2,0,\"X\"])\n",
        "        else:\n",
        "            rec=str(TAG)+ \" does not exist in Yolo, runn model and add Gound Truth: \"+str(S)\n",
        "            if ECHO: print (rec)\n",
        "            TK.T(rec)\n",
        "            if OMIT: Y._set_ECHO(True) # to enable Z_Flag\n",
        "            else   : Y._set_ECHO(False)\n",
        "            Y._set_TEST(False)  #check out conversion to colab\n",
        "            OK =Y._add_tag(TAG)  #= DO ONE TAG, il el RUN THE MODEL\n",
        "            if not OK:\n",
        "              rec=\"Error return from add tag for \"+str(TAG)+ \" at echo# \"+str(Nsharol)\n",
        "              TK.T(rec)\n",
        "              print (\"\\n \", rec)\n",
        "            # retuns OK + single copye of Yolo_np\n",
        "            print (\"\\n\\n P A U S E for imwrite\")\n",
        "            if PTEST: pdb.set_trace()\n",
        "            if TAG in Check_Vid:\n",
        "              print (\"Check data for \", TAG)\n",
        "            if CHECK and TAG in CHECK_TAGS:\n",
        "                print (\"stop here on TAG: \",TAG)\n",
        "\n",
        "        Nsharol+=1\n",
        "        if SHAROL_LIMIT:\n",
        "          if Nsharol>=NSHAROL: break\n",
        "\n",
        "        #OK=Y._do_one_tag(TAG)\n",
        "     # what's in YOLOV_NP?\n",
        "    print (\"end of sharol list  saving Results in pickle\")\n",
        "    #print (\"HERE IS ERROR CHECK PICKEL STORE!!\")\n",
        "    # shrol list format: (<TAG>, <GROUND TRUTH>,<QCO.DE))\n",
        "    #                       0        1           2\n",
        "    if LTEST:pdb.set_trace() # TRaCE FROM HERE\n",
        "    #Yolo_np, OK=Y._get_np()\n",
        "    Y._set_TEST(False)  # conv gtesting\n",
        "    Yolo_np, OK =Y._get_yolo_np()\n",
        "    if not OK: pdb.set_trace()\n",
        "\n",
        "        ########################\n",
        "        ### YOLO NP IS now ready\n",
        "        ### with TAG, AI-LABBE , ai_conf1, etc.\n",
        "        #   Set up checkpoint save\n",
        "        #######################\n",
        "    CHECK_DIR = CHECK_POINT  # set by config really CHECKPOINTS\n",
        "    TEST=False\n",
        "    print (Y._config() )\n",
        "    if TEST: pdb.set_trace()\n",
        "    Y._set_TEST(False)  # after working\n",
        "    #YOLO_PICKEL_DIR = YPD=os.path.join (ROOT, \"STORE\")\n",
        "    YOLO_PICKEL_DIR = YPD=os.path.join (CHECK_POINT)\n",
        "    print (\"Setting check point dir to \", YPD)\n",
        "    Y._set_PICKEL_DIR ( YPD)\n",
        "    PICKLE_NAME = \"CP_YOLOV8 \"+str(VERSION)  # module adds time stmp\n",
        "    Y._pickel_result (Yolo_np, PICKLE_NAME, MODE=\"save\")  #NOT NOWbYES\n",
        "    if LTEST:pdb.set_trace()\n",
        "    Nsharol=0\n",
        "    # SHAROL LIST FORMAT:\n",
        "    #  TAG gROUN_trUTH, q-SCORE\n",
        "    rec=\"\\nStarting STAGE II process and write report\\n\"\n",
        "    print (rec)\n",
        "    TK.T(rec)\n",
        "    SPT=True\n",
        "    STOP=False\n",
        "    if STOP: pdb.set_trace()\n",
        "    for S in SHAROL_LIST:\n",
        "        # get fp from TRIAGE\n",
        "        #fp=os.path.join (FP,f)\n",
        "        #TAG=TAG_FROM_VID (fp)\n",
        "        rec=\"working on sharol no. \"+str(Nsharol) + \" of \"+str(NSHAROL)\n",
        "        TK.T(rec)\n",
        "        if SHAROL_LIMIT :print (rec)\n",
        "        if LATE: # o lagte sgart\n",
        "           if  Nsharol > NSKIP:  # then take rest seriously\n",
        "               Nscip+=1\n",
        "           else:\n",
        "              Nsharol+=1 # keep counting\n",
        "              continue\n",
        "        Nsharol+=1\n",
        "        TAG = S[0]\n",
        "        GTruth= S[1]\n",
        "        rec=\"processing Sharol [\"+str(Nsharol)+\"] \"+str(S)\n",
        "        TK.T(rec)\n",
        "        if SPT: print (rec)\n",
        "        if LTEST: pdb.set_trace()\n",
        "        Qscore = S[2] ##from zerro\n",
        "        if '\"' in TAG:\n",
        "            if LTEST: print ('removing quote from ', TAG)\n",
        "            TAG.replace('\"','')\n",
        "        line = TT+TAG\n",
        "        # get AI diagnosis\n",
        "        STOP=False\n",
        "        #OK, TPL = Y._get_tag_values (TAG) # do we need this?\n",
        "        if TAG ==\"TESTX\" : continue\n",
        "        if STOP: pdb.set_trace()\n",
        "        OK, YPL =Y._Get_YOLO_Values( TAG)  # returns AILABEL, AICONF, AI2LABEL, AI2ONF\n",
        "        if not OK:\n",
        "          rec=str(TAG)+ \"does not exist in Yolo_np skipping\"\n",
        "          print (rec)\n",
        "          TK.T(rec)\n",
        "          continue\n",
        "        if STOP: pdb.set_trace()\n",
        "        if len(YPL)==6:\n",
        "            Y_LABEL1, Y_CONF1, Y_LABEL2, Y_CONF2, Y_QSCORE, XY = YPL\n",
        "            XTAG = TAG\n",
        "        else:\n",
        "            XTAG, Y_LABEL1, Y_CONF1, Y_LABEL2, Y_CONF2, Y_QSCORE, XY = YPL\n",
        "            # USE DECODED LABELS FROM THIE POIN\n",
        "        rec=\"\\nYolo vvalues \"+\" for TAG:\"+str( TAG) + \" is \"+str(YPL)\n",
        "        TK.T(rec)\n",
        "        if SPT:print (rec)\n",
        "        #removed x\n",
        "        # NOTE: YPL = ['4BC345' ,'Mild','0.9','Severe' ,'0.0' ,'0', '']\n",
        "        # one row=one_row(TAG, L1, C1, L2, C2, Q, X)\n",
        "        # NOTEE YOLO FORMAT HAs changed from erlier\n",
        "        # NO fILE name in yolo format\n",
        "\n",
        "\n",
        "        if LTEST : pdb.set_trace()\n",
        "        NO_AI = False\n",
        "        if not OK:\n",
        "            if ECHO: print (\"not Ok from get YLO VALUES AT \", TAG)\n",
        "            FILE_NAME = \"unk\"\n",
        "            CONF      = 0\n",
        "        else:\n",
        "          # note in YOLO NO file name.\n",
        "          if YOLO_FORMAT:\n",
        "            ECHO=True\n",
        "            #FILE_NAME = TPL[3]\n",
        "            FILE_NAME  = \"Unspecified\"\n",
        "            #CONF      = TPL[6]\n",
        "            #CONF      = YPL[2] # conv go YOLO\n",
        "            AI= Y_LABEL1\n",
        "            #pyCONF=Y_CONF1.item()\n",
        "            #CONF = f\"{pyCONF:.4f}\"\n",
        "            label2=Y_LABEL2\n",
        "            #pyconf2=Y_CONF2.item()\n",
        "            #conf2= f\"{pyconf2:.4f}\"\n",
        "            CONF=Y_CONF1\n",
        "            conf2=Y_CONF2\n",
        "            SHAROL = GTruth  # s[2]\n",
        "            rec=\"Settint up YOLO FORMAT AI:\"+str(AI)+\" conf: \"+str(CONF)+\"  lbl/conf2:\"+str(label2)+\"/\"+str(conf2)+ \" GT:\"+str(SHAROL)\n",
        "            TK.T(rec)\n",
        "            if ECHO: print (rec)\n",
        "          else:\n",
        "            if ECHO: print (\"none yoluo format\")\n",
        "            CONF      = TPL[6]\n",
        "            FILE_NAME = TPL[3]\n",
        "        if not OK:\n",
        "            print (\"cant get ai for \", TAG)\n",
        "            AI=\"__________\"\n",
        "            NO_AI = True\n",
        "            print (\"ommitting \", TAG, ' no ai')\n",
        "            MISSING_TAGS.append (TAG)\n",
        "            N_Count +=1\n",
        "            rec=\"cant get Ai for \"+str(TAG)+\"ommitting at \"+str(N_Count)\n",
        "            TK.T(rec)\n",
        "            continue\n",
        "        else:\n",
        "          if YOLO_FORMAT:\n",
        "            #AI=YPL[1]  # conv\n",
        "            #CONF=YPL[2] # conv updage\n",
        "            # alrey set up skip\n",
        "            rec=\"Keeping yolo formlt\"\n",
        "            TK.T(rec)\n",
        "          else:\n",
        "            AI = TPL[5]\n",
        "        if CHECK:\n",
        "            #pdb.set_trace()\n",
        "            rec=\" At check for \"+str(TAG)\n",
        "            TK.T(rec)\n",
        "            if YOLO_FORMAT:\n",
        "              label2=Y_LABEL2    #YPL[3]\n",
        "              conf2 =Y_CONF2 # YPL[4]\n",
        "            else: # must be non yolo\n",
        "              label2=TPL[7]\n",
        "              conf2 = TPL[8]\n",
        "            NValid+=1  # total valid cases\n",
        "            SHAROL = S[1]  # FROM SHAROL LIST\n",
        "            # ai SHOULD BE label\n",
        "            AGR, EQ= CHECK_AGREEMENT (AI, CONF,label2, conf2,SHAROL, TAG)\n",
        "            rec=\"CHecking for AI/CONF/L2/onf2/sharol/TAG: \"+str(TAG)+\" / \"+str(AI)+\" / \"+str(CONF)+\" / \"+str(label2)+\" / \"+str(conf2)+\" GT:\"+str(SHAROL)\n",
        "            TK.T(rec)\n",
        "            if EQ==1: M_Count+=1\n",
        "            R_Count +=1  # add up total recoreds\n",
        "            if AGR:\n",
        "                A_Count +=1\n",
        "                CC=\"1\"\n",
        "                if EQ==1:\n",
        "                    CC=\"Equivocal\"\n",
        "            else:\n",
        "                CC=\"0\"\n",
        "                X_Count+=1  # Disagreements\n",
        "\n",
        "        line+=TT+str(AI)+TT+str(CONF)+TT+str(label2)+TT+str(conf2)\n",
        "        line+=TT+str(SHAROL)+TT+str(FILE_NAME)\n",
        "        line+=TT+str(CC)#+\"\\n\"\n",
        "        ## usent YOLO FORMAT\n",
        "        line = TT+TAG ### THI IS THE LINE\n",
        "        XCONF= CONF  #f\"{CONF:.4f}\"\n",
        "        xconf2= conf2  #f\"{CONF2:.4f}\"\n",
        "        line+=TT+ str(SHAROL)\n",
        "        line+=TT+str(AI)+TT+str(XCONF)+TT+str(label2)+\" / \"+str(xconf2)\n",
        "        line+=TT+str(CC) +TT+str(Y_QSCORE)  #\"\\n\"\n",
        "\n",
        "        # add yolo line\n",
        "        Yline=\"YOLOV8_\"+str(TAG)+TT+Y_LABEL1+TT+ Y_CONF1+TT+ Y_LABEL2+TT+ Y_CONF2+TT+Y_QSCORE\n",
        "        TK.T(line)\n",
        "        TK.T(Yline)\n",
        "        # output q list\n",
        "        '''\n",
        "        Qline = \"Excluded TAG due to Q_score\"\n",
        "        for Q in Q_LIST: Qline+=str (Q)+\", \"\n",
        "        RPT.addL(Qline)\n",
        "        '''\n",
        "\n",
        "        RPT.addL(line)\n",
        "        #RPT.addL(Yline)\n",
        "        # chek limit\n",
        "        Nsharol+=1\n",
        "\n",
        "        if SHAROL_LIMIT:\n",
        "            if Nsharol==NSHAROL:\n",
        "                print (\"sharol limit of \", NSHAROL, \" reached\")\n",
        "                break\n",
        "\n",
        "    arg=\"calculating summary,look in\"+str(RPT_DIR)\n",
        "    print (arg)\n",
        "    TK.T(arg)\n",
        "    XTEST=False\n",
        "    if XTEST: pdb.set_trace()\n",
        "    sumL=\"SUMMARY \\n\\t TOTAL RECORDS\"+TT+ \"VALID CASES\"+TT+\"TOTAL AGREEMENTS \"+TT+\"DISAGREE\"+TT+\"RATIO\"+TT+\"EQUIVOCAl\"+TT+\"NO AI \\n\"\n",
        "    sumL+=TT+str(R_Count)+ TT+str(NValid)+TT+str(A_Count)+TT+str(X_Count)+TT\n",
        "    if NValid==0:\n",
        "      NValid = 1\n",
        "      print (\"cant calculate percentae [DIV zero]\")\n",
        "      R=0\n",
        "    else:\n",
        "      R=f\"{int(A_Count)/int(NValid):.2%}\"\n",
        "    sumL+=str (R)+TT\n",
        "    sumL+=str(M_Count)+TT+str(N_Count)\n",
        "    TK.T (sumL)\n",
        "    RPT.addL(sumL)\n",
        "    marginL =\"\\n\\n \"+\"Equivocal Margine is \"+str(MARGIN)\n",
        "    RPT.addL(marginL)\n",
        "    TK.T(marginL)\n",
        "    print (\"\\n\\n MISSING TAGS: \", MISSING_TAGS)\n",
        "    mline =\"\\n Missing \"+str (len(MISSING_TAGS))+\" TAGs  for v\"+str(VERSION)+ \" as of \"+ str(today)    +\"\\n\"\n",
        "    RPT.addL(mline)\n",
        "    TK.T(mline)\n",
        "    ETEST = False # check numbers f or v129\n",
        "    if ETEST: pdb.set_trace()\n",
        "    line = \"\"\n",
        "    for i in range (len(MISSING_TAGS)) :    line+=str(MISSING_TAGS[i])  +\",  \"\n",
        "    RPT.addL(line)\n",
        "    TK.T(line)\n",
        "    arg=\"end of report at \"+str(RPT_DIR)\n",
        "    print (arg)\n",
        "    TK.T(arg)\n",
        "    # output q list\n",
        "    Qline = str(len(Q_LIST)) +\"  Excluded TAGs due to Q_score \"\n",
        "    for Q in Q_LIST: Qline+=str (Q)+\", \"\n",
        "    RPT.addL(Qline)\n",
        "    RPT.endFile(\"END OF BLIND LIST\")\n",
        "    TK.E()\n",
        "    if LTEST: pdb.set_trace()\n",
        "    return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EXCAFPfyv_Ze"
      },
      "outputs": [],
      "source": [
        "print (\"settting up configurations\")\n",
        "C_CONFIG={\"ROOT\":os.path.join (\"/content/\")}\n",
        "C_CONFIG[\"LIBS\"]=os.path.join (\"/content/LIBS\")\n",
        "C_CONFIG[\"WEIGHTS\"]=os.path.join (\"/content/WEIGHTS\")\n",
        "C_CONFIG[\"STORE\"]=os.path.join (\"/content/STORE\")\n",
        "C_CONFIG[\"VIDEOS\"]=os.path.join (\"/content/VIDEOS\")\n",
        "C_CONFIG[\"REPORTS\"]=os.path.join (\"/content/REPORTS\")\n",
        "C_CONFIG[\"TRIAGE\"]=os.path.join (\"/content/TRIAGE\")\n",
        "C_CONFIG[\"CHECK_POINT\"]=os.path.join (\"/content/CHECK_POINTS\")\n",
        "C_CONFIG[\"BLIND_STUDY\"]=os.path.join (\"/content/BLIND_STUDY\")\n",
        "if USE_MASTER:\n",
        "  C_CONFIG[\"VIDEOS\"]=os.path.join (\"/content/AI/Videos\")\n",
        "  print (\"\\nUsing Master Video source: \", \"/content/AI/Videos\")\n",
        "#pdb.set_trace()\n",
        "'''\n",
        "print (C_CONFIG)\n",
        "ROOT=C_CONFIG[\"ROOT\"]\n",
        "LIBS=C_CONFIG[\"LIBS\"]\n",
        "VIDEOS=C_CONFIG[\"VIDEOS\"]\n",
        "print (ROOT,\"\\n\", LIBS, VIDEOS)\n",
        "'''\n",
        "ROOT=os.path.join (\"D:\\\\\",\"CP_BLIND_STUDY\",'PROCESSED_REPORTS')\n",
        "A_CONFIG={\"ROOT\":ROOT}\n",
        "A_CONFIG[\"LIBS\"]=os.path.join (ROOT,\"LIBS\")\n",
        "A_CONFIG[\"WEIGHTS\"]=os.path.join (ROOT,\"WEIGHTS\")\n",
        "A_CONFIG[\"STORE\"]=os.path.join (ROOT,\"STORE\")\n",
        "A_CONFIG[\"VIDEOS\"]=os.path.join (\"C:\\\\\",\"AI\")# NOT OFF OF ROOT\n",
        "A_CONFIG['REPORTS']=os.path.join (ROOT,'report' )\n",
        "A_CONFIG['TRIAGE']=os.path.join (\"D:\\\\\",\"MASTER_RUN\" )# FROM DIFFERENT PROJECT\n",
        "A_CONFIG['CHECK_POINT']=os.path.join (ROOT,\"CHECK_POINTS\" )\n",
        "A_CONFIG['BLIND_STUDY']=os.path.join (ROOT,\"BLIND_STUDY\" )\n",
        "BROOT=os.path.join (\"E:\\\\\",\"BLIND_STUDY\")\n",
        "B_CONFIG={\"ROOT\":BROOT}\n",
        "B_CONFIG[\"LIBS\"]=os.path.join (BROOT,\"LIBS\")\n",
        "B_CONFIG[\"WEIGHTS\"]=os.path.join (BROOT,\"WEIGHTS\")\n",
        "B_CONFIG[\"STORE\"]=os.path.join (BROOT,\"STORE\")\n",
        "B_CONFIG[\"VIDEOS\"]=os.path.join (BROOT,\"VIDEOS\")\n",
        "B_CONFIG[\"VIDEOS\"]=os.path.join (BROOT,\"VIDEOS\")\n",
        "B_CONFIG[\"CHECK_POINT\"]=os.path.join (BROOT,\"CHECK_POINTS\")\n",
        "B_CONFIG[\"BLIND_STUDY\"]=os.path.join (BROOT,\"BLIND_STUDY\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D0YjYqMB05ZD"
      },
      "outputs": [],
      "source": [
        "SYSTEM_A='a'\n",
        "SYSTEM_B='b'\n",
        "SYSTEM_C='c' # colab\n",
        "PLATFORM=\"unknown\"\n",
        "def SELECT_PLATFORM():\n",
        "  xx=input (\"select platform a, b, or c =colab\")\n",
        "  O=xx.lower()\n",
        "  if O=='a':\n",
        "    PLATFORM = SYSTEM_A\n",
        "    return A_CONFIG\n",
        "  elif O=='b':\n",
        "    PLATFORM=SYSTEM_B\n",
        "    return PLATFORM\n",
        "  elif O=='c':\n",
        "   PLATFORM=SYSTEM_C\n",
        "   PLATFORM=\"Colab\"\n",
        "   print (\"P L A T F O R M=\",PLATFORM)\n",
        "   return C_CONFIG\n",
        "  else:\n",
        "    print (\"unknown configuration, you typed\", xx)\n",
        "  return None\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kzJY-j1R-IJ-"
      },
      "outputs": [],
      "source": [
        "print (\"STARTING\")\n",
        "CONFIG=SELECT_PLATFORM()\n",
        "print (\"you selected for\",PLATFORM, \" with \", CONFIG)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W_wVSkmRBT_t"
      },
      "outputs": [],
      "source": [
        "def UNPACK_CONFIG(CONFIG):\n",
        "  #pdb.set_trace()\n",
        "  ROOT=CONFIG[\"ROOT\"]\n",
        "  VID_DIR=CONFIG[\"VIDEOS\"]\n",
        "  LIB_DIR=CONFIG[\"LIBS\"]\n",
        "  BEST_DIR=CONFIG[\"WEIGHTS\"] # =  best.pt\n",
        "  STORE   =CONFIG[\"STORE\"]\n",
        "  RPT_DIR =CONFIG[\"REPORTS\"]\n",
        "  TRIAGE_DIR=CONFIG[\"TRIAGE\"]\n",
        "  CHECK_POINT=CONFIG[\"CHECK_POINT\"]\n",
        "  BLIND_STUDY=CONFIG[\"BLIND_STUDY\"]\n",
        "  return ROOT, TRIAGE_DIR, VID_DIR, LIB_DIR,BEST_DIR, STORE, RPT_DIR,CHECK_POINT,BLIND_STUDY"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Check_Vid ={'114DB':'Mild','B8670':'Severe', '3F91D':'Normal'}\n",
        "print  (\"check on these videos\", Check_Vid)"
      ],
      "metadata": {
        "id": "Vpt237CvCCG5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_IXHx7Uxfq83"
      },
      "outputs": [],
      "source": [
        "# parT four start\n",
        "if __name__=='__main__':\n",
        "          print (\" from \", os.getcwd(), \" VERSION\", VERSION, \" \\n MISSION: \", MISSION)\n",
        "          #pdb.set_trace()\n",
        "          PROJ=  os.getcwd()  # We are here\n",
        "          #CONFIG=ROOT, VID_DIR, LIB_DIR,BEST_DIR, STORE =SELECT_PLATFORM\n",
        "          print (\"ECHO CONFIG\")\n",
        "          print (CONFIG)\n",
        "          main (CONFIG)\n",
        "          print (\"END of PROCESSING\")\n",
        "          pdb.set_trace()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eWdRvphAEoul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PfQoU0aAR8FZ"
      },
      "outputs": [],
      "source": [
        "print (\"clean RESULT DIR\")\n",
        "RDIR=os.path.join (\"/content/RESULT/\")\n",
        "LRD=os.listdir (RDIR)\n",
        "print (len (LRD), \" files found\")\n",
        "xx=input (\"Delete =cr\")\n",
        "if xx==\"\":\n",
        "  print (\"deleting\")\n",
        "  nd=0\n",
        "  for fl in LRD:\n",
        "    fp=os.path.join (RDIR, fl)\n",
        "    os.remove(fp)\n",
        "    nd+=1\n",
        "  print (\"removed \", nd, \"files\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s-QkYqub6YOL"
      },
      "outputs": [],
      "source": [
        "print (\"zip results\")\n",
        "RP=os.path.join (\"/content/RESULT\")\n",
        "RL=os.listdir(RP)\n",
        "print (len(RL), \" rsults found in\", RP)\n",
        "xx=input (\"compress to STORE cr=yes\")\n",
        "if xx==\"\":\n",
        "  zip_name = \"CP_RESULTS_r12_v77.zip\"\n",
        "  !zip -r /content/STORE/CP_RESULTS__r12_v80.zip /content/RESULT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P1uRm9slq6bH"
      },
      "outputs": [],
      "source": [
        "print (\" move to docs\")\n",
        "xx= input (\"move to mydrive-colab_data=RESULTS_YOLO y=cr\")\n",
        "if xx==\"\":\n",
        "  print (\"go\")\n",
        "else:\n",
        "    print (\"no\")\n",
        "    pdb.set_trace()\n",
        "DOC_P=os.path.join (\"/content/drive/MyDrive/Colab_Data/RESULTS_YOLO\")\n",
        "!cp  /content/STORE/CP_RESULTS__r13_v80.zip    /content/drive/MyDrive/Colab_Data/RESULTS_YOLO\n",
        "print (\"CP_RESULTS__r13_v80.zip\" , \" moved to google docs at\", DOC_P)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLE3tpvVNS6o"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# eXTRA SESION\n",
        "import os,pdb\n",
        "xx=input (\" Do this?  cr = yes\")\n",
        "if xx==\"\":\n",
        "  print (\"k\")\n",
        "else:\n",
        "    print (\"NO\")\n",
        "    pdb.set_trace()\n",
        "# cycl\n",
        "##########################################\n",
        "##  CARDIAC PATTERNS,INC.               ##\n",
        "##                                      ##\n",
        "## COUNT CARDIC CYCLES                  ##\n",
        "##\n",
        "##  p petronelli                        ##c\n",
        "##  01/31/24                            ##\n",
        "##                                      ##\n",
        "##  Contents:                           ##\n",
        "#      Monitors frame metrices to       ##\n",
        "##     identfy cardiac cycles           ##\n",
        "##                                      ##\n",
        "#######(c) Crdiac Patterns , Inc.   #######\n",
        "########2020-2024  All rightes reserved.###\n",
        "##########################################\n",
        "##  UPDATES\n",
        "##  Ver   Date   Isseue                Eng\n",
        "## 00  01/31/24  initil                plp\n",
        "##\n",
        "###\n",
        "### PLRFROM OPRIONAl (GLOBAL)\n",
        "###\n",
        "SYSTEM_A =\"A\"\n",
        "SYSTEM_B =\"B\"\n",
        "SYSTEM_C = \"C\"  # cOLAB\n",
        "\n",
        "PLATFORM = SYSTEM_A  # DEFAULT\n",
        "##\n",
        "VERSION = \"0.3\"\n",
        "MISSION = \" \\n Vlidate cycle assumptions\"\n",
        "\n",
        "from CardiacUtilLIB import CHECK_UP, PATH_UP, PICK_ONE, PICK_ONEX, _C,_clean_spaces,_clean_LABEL\n",
        "from CardiacValues  import cm_plot_labels\n",
        "#from CardiacYOLOlib import YOLOV8\n",
        "#from CardiacVIDlib  import VIDEO\n",
        "import pickle\n",
        "import  torch\n",
        "\n",
        "\n",
        "COLAB = True\n",
        "class RESULTS :\n",
        "    def __init__(self, RESULT_DIR):\n",
        "        RD=RESULT_DIR\n",
        "        if not os.path.exists (RD):\n",
        "            print (RD, \" does not exist\")\n",
        "\n",
        "        print (\"result clas with \", RD)\n",
        "        self.PKL_DIR = RD\n",
        "        self.TEST=False\n",
        "\n",
        "    def _set_TEST(self, VALUE):\n",
        "        if not isinstance (VALUE, bool):\n",
        "            print (\"not a bool: \", VALUE)\n",
        "            return\n",
        "        self.TEST = VALUE\n",
        "        return\n",
        "\n",
        "\n",
        "\n",
        "    def _load_result_pkl (self, PKL_PATH):\n",
        "        PP=PKL_PATH\n",
        "        print (\"load pkl\", PP)\n",
        "        #fid = open(os.path.join(PN, '.pkl'))\n",
        "        if self.TEST: pdb.set_trace()\n",
        "        #PP=FULL_PATH=os.path.join (PKL_DIR, PN)\n",
        "        #torch.load\n",
        "        if not os.path.isfile(PP):\n",
        "            print (PP, \" not a file\")\n",
        "            return False, []\n",
        "\n",
        "\n",
        "        torch.load (PP,map_location=torch.device('cpu'))\n",
        "\n",
        "\n",
        "        objects=[] # emty\n",
        "        with (open(PP, \"rb\")) as openfile:\n",
        "            while True:\n",
        "                try:\n",
        "                    objects.append(pickle.load(openfile))\n",
        "                except EOFError:\n",
        "                    break\n",
        "        RESULTS = objects\n",
        "        return True, RESULTS\n",
        "        pdb.set_trace()\n",
        "\n",
        "def main(PROJ):\n",
        "    ROOT=os.path.join (os.getcwd())\n",
        "    print (\"initializin YOLOV8 class with \", ROOT)\n",
        "    Y=YOLOV8(ROOT)\n",
        "\n",
        "    print (\"select a pkl for Results\")\n",
        "    if COLAB:\n",
        "        RP=os.path.join (\"/content/RESULT/\")\n",
        "    else:\n",
        "        RESULT_PATH =RP= os.path.join (\"D:\\CP_BLIND_STUDY\\PROCESSED_REPORTS\\RESULT_PKL\")\n",
        "    RL=os.listdir(RP)\n",
        "    nx,pick = PICK_ONEX (RL, \"pkl\")\n",
        "    print (\"pickf file: \", pick)\n",
        "    PP=os.path.join (RP,pick)\n",
        "    R = RESULTS (RP )\n",
        "    R._set_TEST (True)\n",
        "    OK, RESULT =R._load_result_pkl(PP)\n",
        "    pdb.set_trace()\n",
        "    print(\"done with Miain\")\n",
        "    return\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__=='__main__':\n",
        "          print (\" from \", os.getcwd(), \" VERSION\", VERSION, \" \\n MISSION: \", MISSION)\n",
        "          pdb.set_trace()\n",
        "          PROJ=  os.getcwd()  # We are here\n",
        "          main (PROJ)\n",
        "          print (\"end of processing\")\n",
        "          pdb.set_trace()"
      ],
      "metadata": {
        "id": "fQzuSSEOF6wK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "pf=\"B29CB_Result21_04-February.pkl\"\n",
        "pp = os.path.join (\"/content/RESULT\", pf)\n",
        "#results =load.pickel(pp)\n",
        "with open (pp, 'rb') as f:\n",
        "  results=pickle.load(f)\n",
        "print (\"loaded \", pf)\n",
        "#print (results)\n",
        "nr=0\n",
        "RF=\"Bc\"\n",
        "FN=\"Results4\"+\"B29CB\"+\".txt\"\n",
        "FO=os.path.join (\"/content/STORE/\", FN)\n",
        "f=open(FO,\"w\")\n",
        "f.write(str(results))\n",
        "for r in results:\n",
        "  sp=r.speed\n",
        "  na=r.names\n",
        "  line=\"speed: \",sp, \"names: \"+str(na)+ ' at '+str(nr)\n",
        "  print (line)\n",
        "  f.write (str(line))\n",
        "  nr+=1\n",
        "f.close()\n",
        "pdb.set_trace()"
      ],
      "metadata": {
        "id": "uom_nsM8GcMp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dwLzWe-IQXkr"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}